[["index.html", "Ciência com R Perguntas e respostas para pesquisadores e analistas de dados Sobre o livro", " Ciência com R Perguntas e respostas para pesquisadores e analistas de dados © 2023 by Arthur de Sá Ferreira https://orcid.org/0000-0001-7014-2002 Atualizado em 07/10/2023 Sobre o livro .boxBorder { border: 2px solid black; padding: 5px } Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, 2023. 127p. doi: 10.5281/zenodo.8320233 A versão online desta obra está licenciada com uma Licença Creative Commons Atribuição-NãoComercial 4.0 Internacional. "],["sobre-o-autor.html", "Sobre o autor", " Sobre o autor Arthur de Sá Ferreira, DSc Obtive minha Graduação em Fisioterapia pela Universidade Federal do Rio de Janeiro (UFRJ, 1999), Formação em Acupuntura pela Academia Brasileira de Arte e Ciência Oriental (ABACO, 2001), Mestrado em Engenharia Biomédica pela Universidade Federal do Rio de Janeiro (UFRJ, 2002) e Doutorado em Engenharia Biomédica pela Universidade Federal do Rio de Janeiro (UFRJ, 2006). Tenho experiência em docência no ensino superior, atuando com professor da graduação em cursos de Fisioterapia, Enfermagem e Odontologia, entre outros (2001-atual); pós-graduação lato sensu em Fisioterapia (2001-atual) e stricto sensu em Ciências da Reabilitação (2010-atual). Sou professor adjunto do Centro Universitário Augusto Motta (UNISUAM), pesquisador dos Programas de Pós-graduação em Ciências da Reabilitação (PPGCR) e Desenvolvimento Local (PPGDL) e Coordenador do Comitê de Ética em Pesquisa (CEP) (2020-atual). Leciono as disciplinas Bioestatística I e II desde 2010 nesses Programas. Fundei o Laboratório de Simulação Computacional e Modelagem em Reabilitação (LSCMR) em 2012, onde desenvolvo projetos de pesquisa principalmente nos seguintes temas: Bioestatística, Modelagem e simulação computacional, Processamento de sinais biomédicos, Movimento funcional humano, Medicina tradicional (chinesa), Distúrbios musculoesqueléticos, Doenças cardiovasculares e Doenças respiratórias. Sou membro efetivo da Associação Brasileira de Pesquisa e Pós-Graduação em Fisioterapia (ABRAPG-FT) (2007-atual), Consórcio Acadêmico Brasileiro de Saúde Integrativa (CABSIN) (2019-atual), Committee on Publication Ethics (COPE) (2018-atual) e Royal Statistical Society (RSS) (2021-atual). Componho o corpo editorial e de revisores de periódicos nacionais e internacionais como Scientific Reports, Frontiers in Rehabilitation Sciences, Evidence-Based Complementary and Alternative Medicine, Chinese Journal of Integrative Medicine, Journal of Integrative Medicine, Fisioterapia e Pesquisa. Currículos externos  5432142731317894 0000-0001-7014-2002  F-6831-2012 "],["dedicatória.html", "Dedicatória", " Dedicatória Esta obra é dedicada a todos que, em princípio, buscam conhecimento para melhorar a qualidade da pesquisa científica - seja a sua própria, a de colegas ou a de desconhecidos - mas, em última análise, desejam mesmo prover melhores condições de saúde e desenvolvimento da sociedade. Dedico também ao leitor eventual que chegou aqui por acaso. "],["prefácio.html", "Prefácio", " Prefácio No âmbito da análise estatística de dados, os processos envolvidos são marcados por uma série de escolhas críticas. Estas decisões abrangem considerações metodológicas e ações operacionais que moldam toda a jornada analítica. Deve-se selecionar, cuidadosamente, um delineamento de estudo para enfrentar os desafios únicos colocados por um projeto de pesquisa. Além disso, a escolha de métodos estatísticos adequados para lidar com os dados gerados pelo delineamento escolhido tem um peso importante. Estas decisões necessitam de uma base construída sobre as evidências mais convincentes da literatura existente e na adesão a práticas sólidas de investigação. Interpretar os resultados destas análises não é uma tarefa simples. Confiar apenas na formação educacional convencional, no bom senso e na intuição para decifrar tabelas e gráficos pode revelar-se inadequado. Interpretações errôneas podem gerar consequências indesejáveis, incluindo a utilização de testes diagnósticos imprecisos ou o endosso de tratamentos ineficazes. Este livro emerge do reconhecimento desses desafios. A proposta gira em torno da organização de um compêndio abrangente de métodos e técnicas de ponta, para análise estatística de dados em pesquisa científica, apresentados em formato de perguntas e respostas. Esse formato promove um diálogo direto e objetivo com o leitor, respondendo a dúvidas comumente colocadas por alunos de graduação, pós-graduação, mestrado e doutorado, bem como por pesquisadores. O objetivo geral de cada capítulo é elucidar as questões metodológicas fundamentais: “O que é?”, “Por que usar?”, “Quando usar?”, “Quando não usar?” e “Como fazer?”. Em cada capítulo, diversas questões específicas são propostas e respondidas sistematicamente, permitindo ao leitor uma melhor elaboração do conteúdo e resultado do seu trabalho. Os capítulos foram organizados para seguir uma progressão de conceitos e aplicações. Embora sejam fragmentados para maior clareza instrucional, as referências cruzadas ajudam a mitigar a fragmentação do conteúdo e reforçar a interconexão dos tópicos. O público-alvo compreende pesquisadores, professores, analistas de dados, profissionais e estudantes que regularmente lidam com a tomada de decisões em pesquisa. Os estudantes de pós-graduação encontrarão aqui uma obra repleta de exemplos para adaptar na análise dos dados de seus projetos de pesquisa. Professores de graduação e pós-graduação terão acesso a uma obra didática de referência, direcionada para seus alunos. Pesquisadores e analistas de dados iniciantes descobrirão um valioso acervo de informações e referências para a construção de projetos e manuscritos. Pesquisadores e os cientistas mais experientes podem recorrer às referências e esclarecimentos mais atuais sobre vieses, paradoxos, mitos e mal práticas em pesquisa. E mesmo os leitores não familiarizados ainda com as técnicas de análise de dados em pesquisa terão a oportunidade de apreciar o papel fundamental de colocar e responder suas perguntas na busca do conhecimento científico. Arthur de Sá Ferreira, DSc "],["agradecimentos.html", "Agradecimentos", " Agradecimentos Este trabalho não seria possível sem o apoio e suporte da minha esposa Daniele, minha irmâ Mônica, meu pai José Victorino e meus filhos Giovanna, Victor e Lucas. "],["parte-1---estatística-aplicada.html", "PARTE 1 - Estatística Aplicada", " PARTE 1 - Estatística Aplicada "],["pensamento-estatistico.html", "Capítulo 1 Pensamento estatístico 1.1 Espaços amostrais e eventos 1.2 Probabilidade condicional 1.3 Leis dos grandes números 1.4 Teorema central do limite 1.5 Regressão para a média 1.6 Reamostragem 1.7 Falácia do jogador", " Capítulo 1 Pensamento estatístico 1.1 Espaços amostrais e eventos 1.1.1 O que é espaço amostral? .[REF] 1.1.2 O que é evento? .[REF] 1.1.3 O que é espaço de eventos? .[REF] 1.2 Probabilidade condicional 1.2.1 O que é probabilidade condicional? .[REF] 1.3 Leis dos grandes números 1.3.1 O que é a lei fraca dos grandes números? .[REF] 1.3.2 O que é a lei forte dos grandes números? .[REF] 1.4 Teorema central do limite 1.4.1 O que é teorema central do limite? .[REF] 1.5 Regressão para a média 1.5.1 O que é regressão para a média? .[REF] 1.6 Reamostragem 1.6.1 O que é reamostragem? Reamostragem é um procedimento que cria vários conjuntos de dados sorteados a partir de um conjunto de dados real - a amostra da população - sem a necessidade de fazer suposições sobre os dados e suas distribuições .1 O procedimento é repetido várias vezes para usar a variabilidade dos resultados para obter um intervalo de confiança do parâmetro.1 1.6.2 Por que utilizar reamostragem? Quando se dispõe de dados de apenas 1 amostra, as diversas suposições que são feitas podem não ser atingidas.1 Procedimentos de reamostragem produzem um conjunto de observações escolhidas aleatoriamente da amostra, igualmente representativo da população original.1 Procedimentos de reamostragem permitem estimar o erro-padrão e intervalos de confiança sem a necessidade de tais suposições, sendo portanto um conjunto de procedimentos não-paramétricos.1 1.6.3 Quais procedimentos de reamostragem podem ser realizados? Bootstrap: Cada iteração gera uma amostra bootstrap do mesmo tamanho do conjunto de dados original escolhendo aleatoriamente observações reais, uma de cada vez. Cada observação tem chances iguais de ser escolhida a cada vez, portanto, algumas observações serão escolhidas mais de uma vez e outras nem serão escolhidas.1 1.7 Falácia do jogador 1.7.1 O que é falácia do jogador? .[REF] Referências "],["paradoxos-estatisticos.html", "Capítulo 2 Paradoxos e falácias 2.1 Paradoxos estatísticos 2.2 Paradoxo de Abelson 2.3 Paradoxo de Berkson 2.4 Paradoxo de Ellsberg 2.5 Paradoxo de Freedman 2.6 Paradoxo de Hand 2.7 Paradoxo de Lindley 2.8 Paradoxo de Lord 2.9 Paradoxo de Proebsting 2.10 Paradoxo de Simpson 2.11 Paradoxo de Stein 2.12 Paradoxo de Okie 2.13 Paradoxo da acurácia 2.14 Paradoxo do elevador 2.15 Paradoxo do falso positivo 2.16 Paradoxo da amizade", " Capítulo 2 Paradoxos e falácias 2.1 Paradoxos estatísticos 2.1.1 O que são paradoxos estatísticos? .[REF] 2.2 Paradoxo de Abelson .2 2.3 Paradoxo de Berkson .3 2.4 Paradoxo de Ellsberg .4 2.5 Paradoxo de Freedman .5,6 2.6 Paradoxo de Hand .7 2.7 Paradoxo de Lindley .8 2.8 Paradoxo de Lord .9,10 2.9 Paradoxo de Proebsting .[REF] 2.10 Paradoxo de Simpson .11,12 2.11 Paradoxo de Stein .13 2.12 Paradoxo de Okie .[REF] 2.13 Paradoxo da acurácia .[REF] 2.14 Paradoxo do elevador .14 2.15 Paradoxo do falso positivo .[REF] 2.16 Paradoxo da amizade .15 Referências "],["unidade-analise.html", "Capítulo 3 Unidade de análise 3.1 Definição 3.2 Medidas únicas ou múltiplas", " Capítulo 3 Unidade de análise 3.1 Definição 3.1.1 O que é unidade de análise? A unidade de análise (ou unidade experimental) de pesquisas na área de saúde geralmente é o indivíduo.16 A unidade de análise também pode ser a instituição em estudos multicêntricos (ex.: hospitais, clínicas) ou um estudo publicado em meta-análise (ex.: ensaios clínicos).16 É fundamental identificar corretamente a unidade de análise para evitar inflação do tamanho da amostra (ex.: medidas bilaterais resultando em o dobro de participantes), violações de suposições dos testes de hipótese (ex.: independência entre medidas e/ou unidade de análise) e resultados espúrios em testes de hipótese (ex.: p-valores menores que aqueles observados se a amostra não estivesse inflada).16,17 3.2 Medidas únicas ou múltiplas 3.2.1 Como podem ser coletadas as informações da unidade de análise? Da unidade de análise podem ser coletadas informações em medidas únicas, repetidas, seriadas ou múltiplas. 3.2.1.1 Medidas únicas A medida única da pressão arterial sistólica no braço esquerdo resulta em um valor pontual. O valor pontual será considerado representativo da variável para a unidade de análise (ex.: 120 mmHg para o participante #9). Medidas únicas obtidas de diferentes unidades de análise podem ser consideradas independentes se observadas outras condições na coleta de dados. Tabela 3.1: Tabela de dados bruto com medidas únicas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) 1 118 2 113 3 116 4 110 5 111 6 116 7 120 8 111 9 120 10 112 3.2.1.2 Medidas repetidas A medida repetida da pressão arterial no braço esquerdo, resultando em um conjunto de valores pontuais (ex.: 110 mmHg, 118 mmHg e 116 mmHg para o participante #5). As medidas repetidas podem ser tabuladas separadamente, por exemplo para análise da confiabilidade de obtenção dessa medida. Tabela 3.2: Tabela de dados bruto com medidas repetidas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) #1 Pressão arterial, braço esquerdo (mmHg) #2 Pressão arterial, braço esquerdo (mmHg) #3 1 114 112 112 2 115 120 113 3 115 110 120 4 117 116 114 5 110 118 116 6 110 120 113 7 118 114 117 8 111 112 119 9 120 112 117 10 110 115 115 As medidas repetidas podem ser agregadas por algum parâmetro — ex.: média, mediana, máximo, mínimo, entre outros—, observando-se a relevância biológica, clínica e/ou metodológica desta escolha. O valor agregado será considerado representativo da variável para a unidade de análise (ex.: média = 115 mmHg para o participante #5). Medidas agregadas obtidas de diferentes unidades de análise podem ser consideradas independentes se observadas outras condições na coleta de dados. Tabela 3.3: Tabela de dados bruto com medidas repetidas agregadas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) média 1 112.6667 2 116.0000 3 115.0000 4 115.6667 5 114.6667 6 114.3333 7 116.3333 8 114.0000 9 116.3333 10 113.3333 O pacote stats18 fornece a função aggregate para agregar medidas repetidas utilizando uma função personalizada. 3.2.1.3 Medidas seriadas Medidas seriadas são possivelmente relacionadas e, portanto, dependentes na mesma unidade de análise. Por exemplo, a medida seriada da pressão arterial no braço esquerdo, em intervalos tipicamente regulares (ex.: 114 mmHg, 120 mmHg e 110 mmHg em 1 min, 2 min e 3 min, respectivamente, para o participante #1). Tabela 3.4: Tabela de dados bruto com medidas seriadas não agregadas. Unidade de análise Tempo (min) Pressão arterial, braço esquerdo (mmHg) 1 1 114 1 2 120 1 3 110 2 1 119 2 2 120 2 3 114 3 1 116 3 2 114 3 3 116 4 1 113 Medidas seriadas também agregadas por parâmetros — ex.: máximo, mínimo, amplitude — são consideradas representativas da variação temporal ou de uma característica de interesse (ex.: amplitude = 10 mmHg para o participante #1). Tabela 3.5: Tabela de dados bruto com medidas seriadas não agregadas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) amplitude 1 10 2 6 3 2 4 6 5 1 6 8 7 9 8 10 9 7 10 5 O pacote stats18 fornece a função aggregate para agregar medidas repetidas utilizando uma função personalizada. 3.2.1.4 Medidas múltiplas A medida de pressão arterial bilateral resulta em um conjunto de valores pontuais (ex.: braço esquerdo = 114 mmHg, braço direito = 118 mmHg para o participante #8). Neste caso, ambos os valores pontuais são considerados representativos daquela unidade de análise. Medidas múltiplas também são possivelmente relacionadas e, portanto, são dependentes na mesma unidade de análise. Medidas múltiplas podem ser obtidas de modo repetido para análise agregada ou seriada. Tabela 3.6: Tabela de dados bruto com medidas múltiplas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) Pressão arterial, braço direito (mmHg) 1 117 115 2 120 118 3 112 118 4 112 112 5 116 112 6 112 118 7 115 113 8 114 118 9 119 114 10 112 116 O pacote stats18 fornece a função aggregate para agregar medidas repetidas utilizando uma função personalizada. Referências "],["dados-metadados.html", "Capítulo 4 Dados e metadados 4.1 Dados 4.2 Dados perdidos 4.3 Metadados", " Capítulo 4 Dados e metadados 4.1 Dados 4.1.1 O que são dados? “Tudo são dados”.19 4.1.2 O que são dados primários e secundários? Dados primários são dados originais coletados intencionalmente para uma determinada análise exploratória ou inferencial planejada a priori.20 Dados secundários compreendem dados coletados inicialmente para análises de um estudo, e são subsequentemente utilizados para outras análises.20 4.2 Dados perdidos 4.2.1 O que são dados perdidos? Dados perdidos são dados não coletados de um ou mais participantes, para uma ou mais variáveis.21 4.2.2 Qual o problema de um estudo ter dados perdidos? Uma grande quantidade de dados perdidos pode comprometer a integridade científica do estudo, considerando-se que o tamanho da amostra foi estimado para observar um determinado tamanho de efeito mínimo.21 Perda de participantes no estudo por dados perdidos pode reduzir o poder estatístico (erro tipo II).21 Não existe solução globalmente satisfatória para o problema de dados perdidos.21 4.2.3 Quais os mecanismos geradores de dados perdidos? Dados perdidos completamente ao acaso (missing completely at random, MCAR), em que os dados perdidos estão distribuídos aleatoriamente nos dados da amostra.22,23 Dados perdidos ao acaso (missing at random, MAR), em que a probabilidade de ocorrência de dados perdidos é relacionada a outras variáveis medidas.22,23 Dados perdidos não ao acaso (missing not at random, MNAR), em que a probabilidade da ocorrência de dados perdidos é relacionada com a própria variável.22,23 4.2.4 Como identificar o mecanismo gerador de dados perdidos em um banco de dados? Por definição, não é possível avaliar se os dados foram perdidos ao acaso (MAR) ou não (MNAR).22 Testes t e regressões logísticas podem ser aplicados para identificar relações entre variáveis com e sem dados perdidos, criando um fator de análise (‘dado perdido’ = 1, ‘dado observado’ = 0).22 O pacote misty24 fornece a função na.test para executar o Little’s Missing Completely at Random (MCAR) test25. 4.2.5 Que estratégias podem ser utilizadas na coleta de dados quando há expectativa de perda amostral? Na expectativa de ocorrência de perda amostral, com consequente ocorrência de dados perdidos, recomenda-se ampliar o tamanho da amostra com um % correspondente à tal estimativa - embora ainda não corrija potenciais vieses pela perda.21 4.2.6 Que estratégias podem ser utilizadas na análise quando há dados perdidos? Na ocorrência de dados perdidos, a análise mais comum compreende apenas os ‘casos completos’, com exclusão de participantes com algum dado perdido nas variáveis do estudo. Em casos de grande quantidade de dados perdidos, pode-se perder muito poder estatístico (erro tipo II elevado).21 A análise de dados completos é válida quando pode se argumentar que que a probabilidade de o participante ter dados completos depende apenas das covariáveis e não dos desfechos.23 A análise de dados completos é eficiente quando todos os dados perdidos estão no desfecho, ou quando cada participante com dados perdidos nas covariáveis também possui dados perdidos nos desfechos.23 O pacote stats26 fornece a função complete.cases para identificar os casos completos - isto é, sem dados perdidos - em um banco de dados. Na ocorrência de dados perdidos, a imputação de dados (substituição por dados simulados plausíveis preditos pelos dados presentes) pode ser uma alternativa para manter o erro tipo II estipulado no plano de análise.21 A análise com imputação de dados pode ser útil quando pode-se argumentar que os dados foram perdidos ao acaso (MAR); quando o desfecho foi observado e os dados perdidos estão nas covariáveis; e variáveis auxiliares - preditoras do desfecho e não dos dados perdidos - estão disponíveis.23 Em dados longitudinais com um pequeno número de ‘ondas’ (medidas repetidas) e poucas variáveis, para análise com modelos de regressão univariados, a imputação via especificação condicional completa - também conhecido como imputação multivariada por equações encadeadas (multivaraite imputation by chained equations, MICE) - é eficiente do ponto de vista computacional e possui acurácia e precisão para estimação de parâmetros.22,27 Os pacotes mice28 e miceadds29 fornecem funções mice e mi.anova para imputação multivariada por equações encadeadas, respectivamente, para imputação de dados. 4.2.7 Que estratégias podem ser utilizadas na redação de estudos em que há dados perdidos? Informar: o número de participantes com dados perdidos; diferenças nas taxas de dados perdidos entre os braços do estudo; os motivos dos dados perdidos; o fluxo de participantes; quaisquer diferenças entre os participantes com e sem dados perdidos; o padrão de ausência (por exemplo, se é aleatória); os métodos para tratamento de dados perdidos das variáveis em análise; os resultados de quaisquer análises de sensibilidade; as implicações dos dados perdidos na interpretação do resultados.30 4.3 Metadados 4.3.1 O que são metadados? Metadados são informações técnicas relacionadas às variáveis do estudo, tais como rótulos, limites de valores plausíveis, códigos para dados perdidos e unidades de medida.31 Metadados também são informações relacionadas ao delineamento e/ou protocolo do estudo, recrutamento dos participantes, e métodos para realização das medidas.31 Referências "],["variaveis-fatores.html", "Capítulo 5 Variáveis e fatores 5.1 Variáveis 5.2 Transformação de variáveis contínuas 5.3 Categorização de variáveis contínuas 5.4 Dicotomização de variáveis contínuas 5.5 Fatores", " Capítulo 5 Variáveis e fatores 5.1 Variáveis 5.1.1 O que são variáveis? Variáveis são informações que podem variar entre medidas em diferentes indivíduos e/ou repetições.32 Variáveis definem características de uma amostra extraída da população, tipicamente observados por aplicação de métodos de amostragem (isto é, seleção) da população de interesse.20 5.1.2 Como são classificadas as variáveis? Quanto à informação:20,33–35 Quantitativa Qualitativa Quanto ao conteúdo:20,33–35 Contínua (intervalo ou razão; discreta ou contínua) Categórica ordinal (numérica discreta ou nominal) Categórica nominal (multinominal ou dicotômica) Quanto à interpretação:20,33–35 Dependente (desfecho) Independente (preditora, covariável, confundidora, controle) Mediadora Moderadora Modificadora Auxiliar Indicadora 5.1.3 Por que é importante classificar as variáveis? Identificar corretamente os tipos de variáveis da pesquisa é uma das etapas da escolha dos métodos estatísticos adequados para as análises e representações no texto, tabelas e gráficos.34 5.2 Transformação de variáveis contínuas 5.2.1 O que é transformação de variáveis contínuas? Transformação significa aplicar uma função matemática à variável medida em sua unidade original.36 A transformação visa atender aos pressupostos dos modelos estatísticos quanto à distribuição da variável, em geral a distribuição gaussiana.20,36 A dicotomização pode ser interpretada como um caso particular de agrupamento.37 5.2.2 Por que transformar variáveis? Muitos procedimentos estatísticos supõem que as variáveis - ou seus termos de erro, mais especificamente - são normalmente distribuídas. A violação dessa suposição pode aumentar suas chances de cometer um erro do tipo I ou II.38 Mesmo quando se está usando análises consideradas robustas para violações dessas suposições ou testes não paramétricos (que não assumem explicitamente termos de erro normalmente distribuídos), atender a essas questões pode melhorar os resultados das análises (por exemplo, Zimmerman, 1995).38 5.2.3 Quais transformações podem ser aplicadas? Distribuições com assimetria à direita:38 Raiz quadrada Logaritmo natural Logaritmo base 10 Transformação inversa Distribuições com assimetria à esquerda:38 Reflexão e raiz quadrada Reflexão e logaritmo natural Reflexão e logaritmo base 10 Reflexão e transformação inversa Transformação arco-seno.38 Transformação de Box-Cox.39 Dicotomização. O pacote MASS40 fornece a função boxcox para executar a transformação de Box-Cox.39 5.3 Categorização de variáveis contínuas 5.3.1 O que é catogorização de uma variável? .[REF] 5.3.2 Por que não é recomendado categorizar variáveis contínuas? Nenhum dos argumentos usados para defender a categorização de variáveis se sustenta sob uma análise técnica rigorosa.41 Categorizar variáveis não é necessário para conduzir análises estatísticas. Ao invés de categorizar, priorize as variáveis contínuas.42–44 Em geral, não existe uma justificativa racional (plausibilidade biológica) para assumir que as categorias artificiais subjacentes existam.42–44 Caso exista um ponto de corte ou limiar verdadeiro que discrimine três ou mais grupos independentes, identificar tal ponto de corte ainda é um desafio.45 Categorização de variáveis contínuas aumenta a quantidade de testes de hipótese para comparações pareadas entre os quantis, inflando portanto o erro tipo I.46 Categorização de variáveis contínuas requer uma função teórica que pressupõe a homogeneidade da varia’vel dentro dos grupos, levando tanto a uma perda de poder como a uma estimativa imprecisa.46 Categorização de variáveis contínuas pode dificultar a comparação d resultados entre estudos devido aos pontos de corte baseados em dados de um banco usados para definir as categorias.46 5.3.3 Quais são as alternativas à categorização de variáveis contínuas? Análise com os dados das variável na escala de medida original .41 Análise com modelos de regressão com pesos locais (lowess) tais como splines e polinômios fracionais.41 5.4 Dicotomização de variáveis contínuas 5.4.1 O que são variáveis dicotômicas? Variáveis dicotômicas (ou binárias) podem representar categorias naturais tipo “presente/ausente”, “sim/não”.[REF] Variáveis dicotômicas podem representar categorias fictícias, criadas a partir de variáveis multinominais, em que cada nível é convertido em uma variável dicotômica dummy.[REF] Geralmente são representadas por “1” e “0”.[REF] 5.4.2 Quais argumentos são usados para defender a categorização ou dicotomização de variáveis contínuas? O argumento principal para dicotomização de variáveis é que tal procedimento facilita e simplifica a apresentação dos resultados, principalmente para o público em geral.37 Os pesquisadores não conhecem as consequências estatísticas da dicotomização.41 Os pesquisadores não conhecem os métodos adequados de análise não-paramétrica, não-linear e robusta.41 As categorias representam características existentes dos participantes da pesquisa, de modo que as análises devam ser feitas por grupos e não por indivíduos.41 A confiabilidade da(s) variável(eis) medida(s) é baixa e, portanto, categorizar os participantes resultaria em uma medida mais confiável.41 5.4.3 Por que não é recomendado dicotomizar variáveis contínuas? Nenhum dos argumentos usados para defender a dicotomização de variáveis se sustenta sob uma análise técnica rigorosa.41 Dicotomizar variáveis não é necessário para conduzir análises estatísticas. Ao invés de dicotomizar, priorize as variáveis contínuas.42–44 Em geral, não existe uma justificativa racional (plausibilidade biológica) para assumir que as categorias artificiais subjacentes existam.42–44 Dicotomização causa perda de informação e consequentemente perda de poder estatístico para detectar efeitos.41,42 Dicotomização também classifica indivíduos com valores próximos na variável contínua como indivíduos em pontos opostos e extremos, artificialmente sugerindo que são muito diferentes.42 Dicotomização pode diminuir a variabilidade das variáveis.42 Dicotomização pode ocultar não-linearidades presentes na variável contínua.41,42 A média ou a mediana, embora amplamente utilizadas, não são bons parâmetros para dicotomizar variáveis.37,42 Caso exista um ponto de corte ou limiar verdadeiro que discrimine dois grupos independentes, identificar tal ponto de corte ainda é um desafio.45 5.4.4 Quais cenários legitimam a dicotomização das variáveis contínuas? Quando existem dados e/ou análises que suportem a existência - não apenas a suposição ou teorização - de categorias com um ponto de corte claro e com significado entre elas.41 Quando a distribuição da variável contínua é muito assimétrica, de modo que uma grande quantidade de observações está em um dos extremos da escala.41 5.4.5 Quais métodos são usados para dicotomizar variáveis contínuas? Em termos de tabelas de contingência 2x2, os seguintes métodos permitem45 a identificação do limiar verdadeiro: Youden.47 Gini Index.48 Estatística qui-quadrado (\\(\\chi^2\\)).49 Risco relativo (\\(RR\\)).50 Kappa (\\(\\kappa\\)).51. 5.5 Fatores 5.5.1 O que são fatores? Fator é um sinônimo de variável categórica.[REF] Na modelagem, fator é sinônimo de variável preditora, em particular quando se refere à modelagem de efeitos fixos e aleatórios – os fatores (variáveis) são fatores fixos ou fatores aleatórios.[REF] 5.5.2 O que são níveis de um fator? Níveis de um fator são as possíveis categorias que descrevem um fator.[REF] O pacote forcats52 fornece a função as_factor para converter uma variável em fator. Referências "],["distribuicoes-parametros.html", "Capítulo 6 Distribuições e parâmetros 6.1 Distribuições de probabilidade 6.2 Parâmetros 6.3 Valores esperados 6.4 Valores discrepantes", " Capítulo 6 Distribuições e parâmetros 6.1 Distribuições de probabilidade 6.1.1 O que são distribuições de probabilidade? Uma distribuição estatística é uma função que descreve os valores possíveis ou o intervalo de valores de uma variável (eixo horizontal) e a frequência com que cada valor é observado (eixo vertical).20 6.1.2 Quais características definem uma distribuição? Uma distribuição pode ser definida por modelos matemáticos e caracterizada por sua tendência central, dispersão, simetria, curtose. 6.1.3 O que é a distribuição normal? A distribuição normal (ou gaussiana) é uma distribuição com desvios simétricos positivos e negativos em torno de um valor central.33 Em uma distribuição normal, o intervalo de 1 desvio-padrão (±1DP) inclui cerca de 68% dos dados; de 2 desvios-padrão (±2DP) cerca de 95% dos dados; e no intervalo de 3 desvios-padrão (±3DP) cerca de 99% dos dados.33 6.1.4 O que são distribuições não-normais? .[REF] 6.1.5 Que métodos podem ser utilizados para identificar a normalidade da distribuição? Histogramas.20 Gráficos Q-Q.20 Testes de hipótese nula:20 Kolmogorov-Smirnov Shapiro-Wilk Anderson-Darling 6.2 Parâmetros 6.2.1 O que são parâmetros? Parâmetros são informações que definem um modelo teórico, como propriedades de uma coleção de indivíduos.32 Parâmetros definem características de uma população inteira, tipicamente não observados por ser inviável ter acesso a todos os indivíduos que constituem tal população.20 6.2.2 Que parâmetros podem ser estimados? Parâmetros de tendência central.33,53 Parâmetros de dispersão.33,53,54 Parâmetros de proporção.33,53,55,55 Parâmetros de distribuição.53 Parâmetros de extremos.33 6.3 Valores esperados 6.3.1 Que parâmetros de tendência central podem ser estimados? Média.33,53 Mediana.33,53 Moda.33,53 6.3.2 Que parâmetros de dispersão podem ser estimados? Variância.33,53 Desvio-padrão: Estima a variabilidade entre as observações e a média amostra, e estima a variabilidade na população.54 Erro-padrão: Estima a variabilidade teórica entre médias amostrais.54 Amplitude.33,53 Intervalo interquartil.33,53 Intervalo de confiança.33,53 6.3.3 Que parâmetros de proporção podem ser estimados? Frequência absoluta.33,53,55 Frequência relativa.33,53,55 Percentil.33,53,55 Quantil: é o ponto de corte que define a divisão da amostra em grupos de tamanhos iguais. Portanto, não se referem aos grupos em si, mas aos valores que os dividem.55 O pacote stats56 fornece a função quantile para executar análise de percentis. 6.3.4 Que parâmetros de distribuição podem ser estimados? Assimetria.53 Curtose.53 6.3.5 Que parâmetros extremos podem ser estimados? Mínimo.33 Máximo.33 O pacote stats56 fornece a função quantile para executar análise de percentis. 6.4 Valores discrepantes 6.4.1 O que são valores discrepantes? Em termos gerais, um valor discrepante - “fora da curva” ou outlier - é uma observação que possui um valor relativamente grande ou pequeno em comparação com a maioria das observações.57 Mais especificamente, um valor discrepante é uma observação incomun que exerce influencia indevida em uma análise.57 6.4.2 Como conduzir análises com valores discrepantes? Erros de observação e de medição são uma justificativa válida para descartar observações discrepantes.57 Valores discrepantes na variável de desfecho podem exigir uma abordagem mais refinada, especialmente quando representam uma variação real na variável que está sendo medida.57 Valores discrepantes em uma (co)variável podem surgir devido a um projeto experimental inadequado; nesse caso, abandonar a observação ou transformar a covariável são opções adequadas.57 É importante reportar se existem valores discrepantes e como foram tratados.57 Referências "],["tabulacao-dados.html", "Capítulo 7 Tabulação de dados 7.1 Planilhas eletrônicas", " Capítulo 7 Tabulação de dados 7.1 Planilhas eletrônicas 7.1.1 Qual a organização de uma tabela de dados? Cada variável possui sua própria coluna (vertical).58 Cada observação possui sua própria linha (horizontal).58 Cada valor possui sua própria célula especificada em um par (linha, coluna).58 Cada célula possui seu próprio dado.58 7.1.2 Qual a estrutura básica de uma tabela para análise estatística? Use apenas 1 (uma) planilha eletrônica para conter todas as informações coletadas. Evite múltiplas abas no mesmo arquivo, assim como múltiplos arquivos quando possível.59 Use apenas 1 (uma) linha de cabeçalho para nomear os fatores e variáveis do seu estudo.59 Tipicamente, cada linha representa um participante e cada coluna representa uma variável ou fator do estudo. Estudos com medidas repetidas dos participantes podem conter múltiplas linhas para o mesmo participante (repetindo os dados na mesma coluna, conhecido como formato curto) ou só uma linha para o participante (repetindo os dados em colunas separadas, conhecido como formato longo ).60 Tabela 7.1: Estrutura básica de uma tabela de dados. V1 V2 V3 V4 \\(x_{1,1}\\) \\(x_{1,2}\\) \\(x_{1,3}\\) \\(x_{1,4}\\) \\(x_{2,1}\\) \\(x_{2,2}\\) \\(x_{2,3}\\) \\(x_{2,4}\\) \\(x_{3,1}\\) \\(x_{3,2}\\) \\(x_{3,3}\\) \\(x_{3,4}\\) \\(x_{4,1}\\) \\(x_{4,2}\\) \\(x_{4,3}\\) \\(x_{4,4}\\) \\(x_{5,1}\\) \\(x_{5,2}\\) \\(x_{5,3}\\) \\(x_{5,4}\\) 7.1.3 O que usar para organizar tabelas para análise computadorizada? Seja consistente em: códigos para as variáveis categóricas; códigos para dados perdidos; nomes das variáveis; identificadores de participantes; nome dos arquivos; formato de datas; uso de caracteres de espaço.59,60 Crie um dicionário de dados (metadados) em um arquivo separado contendo: nome da variável, descrição da variável, unidades de medida e valores extremos possíveis.59 Use recursos para validação de dados antes e durante a digitação de dados.59,60 O pacote data.table61 fornece a função melt.data.table para reorganizar a tabela em diferentes formatos. 7.1.4 O que não usar para organizar tabelas para análise computadorizada? Não deixe células em branco: substitua dados perdidos por um código sistemático (ex.: NA [not available]).59 Não inclua análises estatísticas ou gráficos nas tabelas de dados brutos.59 Não utilize cores como informação. Se necessário, crie colunas adicionais - variáveis instrumentais ou auxiliares - para identificar a informação de modo que possa ser analisada.59 Não use células mescladas. Delete linhas e/ou colunas totalmente em branco (sem unidades de análise e/ou sem variáveis). 7.1.5 O que é recomendado e o que deve ser evitado na organização das tabelas para análise? Tabela 7.2: Formatação recomendada para tabela de dados. ID Data.Coleta Estado.Civil Numero.Filhos 1 08-10-2023 casado NA 2 09-10-2023 casado 1 3 10-10-2023 casado NA 4 11-10-2023 solteiro NA 5 12-10-2023 casado NA 6 13-10-2023 solteiro 0 7 14-10-2023 solteiro NA 8 15-10-2023 solteiro NA 9 16-10-2023 casado NA 10 17-10-2023 solteiro NA Tabela 7.3: Formatação não recomendada para tabela de dados. ID Data de Coleta Estado Civil Número de Filhos 1 08-10-2023 casado NA 2 09-10-2023 Casado 1 3 10-10-2023 casado NaN 4 11-10-2023 Solteiro N/A 5 12-10-2023 Casado N.A. 6 13-10-2023 solteiro 0 7 14-10-2023 solteiro 8 15-10-2023 Solteiro na 9 16-10-2023 casado n.a. 10 17-10-2023 Solteiro 999 Referências "],["analise-inicial-dados.html", "Capítulo 8 Análise inicial de dados 8.1 Análise inicial de dados", " Capítulo 8 Análise inicial de dados 8.1 Análise inicial de dados 8.1.1 O que é análise inicial de dados? Análise inicial de dados é uma sequência de procedimentos que visam principalmente a transparência e integridade das pré-condições do estudo para conduzir a análise estatística apropriada de modo responsável para responder aos problemas da pesquisa.31 O objetivo da análise inicial de dados é propiciar dados prontos para análise estatística, incluindo informações confiáveis sobre as propriedades dos dados.31 A análise inicial de dados pode ser dividida nas seguintes etapas:31 Configuração dos metadados Limpeza dos dados Verificação dos dados R elatório inicial dos dados Refinamento e atualização do plano de análise estatística Documentação e relatório da análise inicial de dados A análise inicial de dados não deve ser confundida com análise exploratória62, nem deve ser utilizada para hipotetizar após os dados serem coletados (conhecido como Hypothesizing After Results are Known, HARKing)63. 8.1.2 Como conduzir uma análise inicial de dados? Desenvolva um plano de análise inicial de dados consistente com os objetivos da pesquisa. Por exemplo, verifique a distribuição e escala das variáveis, procure por observações não-usuais ou improváveis, avalie possíveis padrões de dados perdidos.31 Não altere diretamente os dados de uma tabela obtida de uma fonte. Use scripts para implementar eventuais alterações, de modo a manter o registro de todas as modificações realizadas no banco de dados.31 Use os metadados do estudo para guiar a análise inicial dos dados e compartilhe com os dados para maior transparência e reprodutibilidade.31 Representação gráfica dos dados pode ajudar a identificar características e padrões no banco de dados, tais como suposições e tendências.31 Verifique a frequência e proporção de dados perdidos em cada variável, e depois examine por padrões de dados perdidos simultaneamente por duas ou mais variáveis.31 Verifique a frequência e proporção de dados perdidos em cada variável, e depois examine por padrões de dados perdidos simultaneamente por duas ou mais variáveis.31 8.1.3 Quais problemas podem ser detectados na análise inicial de dados? Registros duplicados, que devem ser excluídos para não inflar a amostra.64 Codificação 0 ou 1 para variáveis dicotômicas para representar a direção esperada da associação entre elas.64 Ordenação cronológica de variáveis com registros temporais (retrospectivos ou prospectivos).64 A distribuição das variáveis para verificação das suposições das análises planejadas.64 Ocorrência de efeitos teto e piso nas variáveis.64 Referências "],["parte-2---epidemiologia-aplicada.html", "PARTE 2 - Epidemiologia Aplicada", " PARTE 2 - Epidemiologia Aplicada "],["pensamento-metodologico.html", "Capítulo 9 Pensamento metodológico 9.1 População 9.2 Amostragem 9.3 Tamanho da amostra 9.4 Validade do estudo 9.5 Pareamento 9.6 Alocação 9.7 Aleatorização", " Capítulo 9 Pensamento metodológico 9.1 População 9.1.1 O que é população? .[REF] 9.1.2 Qual é a relação entre população e amostra? Em pesquisa científica, utilizam-se dados de uma amostra de participantes (ou outras unidades de análise) para realizar inferências sobre a população.1 9.2 Amostragem 9.2.1 O que é amostragem? .[REF] 9.3 Tamanho da amostra 9.3.1 O que é tamanho da amostra? .[REF] 9.3.2 Como é determinado o tamanho da amostra de um estudo? .[REF] 9.3.3 Quais aspectos éticos estão envolvidos no tamanho da amostra? O tratamento ético dos participantes do estudo, portanto, não exige que se considere se o poder do estudo é inferior à meta convencional de 80% ou 90%.65 Estudos com poder &lt;80% não são necessariamente antiéticos.65 Grandes estudos podem ser desejáveis por outras razões que não as éticas.65 9.4 Validade do estudo 9.4.1 O que é validade interna? .66 9.4.2 O que é validade externa? .66 9.5 Pareamento 9.5.1 O que é pareamento? Pareamento significa que para cada participante de um grupo (por exemplo, com alguma condição clínica), existe um (ou mais) participantes (por exemplo, grupo controle) que possui características iguais ou similares relativas a algumas variáveis de interesse.67 As variáveis escolhidas para pareamento devem ter relação com as variáveis de desfecho, mas não são de interesse elas mesmas.67 O ajuste por pareamento deve ser incluído nas análises estatísticas mesmo que as variáveis de pareamento não sejam consideradas prognósticas ou confundidores na amostra estudada.67 A ausência de evidência estatística de diferença entre grupos não é considerada pareamento.67 9.6 Alocação 9.6.1 O que é alocação? .[REF] 9.7 Aleatorização .[REF] 9.7.1 O que é aleatorização? Referências "],["vieses-metodologicos.html", "Capítulo 10 Vieses metodológicos 10.1 Vieses", " Capítulo 10 Vieses metodológicos 10.1 Vieses 10.1.1 O que são vieses? .[REF] "],["delineamento-estudos.html", "Capítulo 11 Delineamento de estudos 11.1 Classificação", " Capítulo 11 Delineamento de estudos 11.1 Classificação 11.1.1 Como podem ser classificados os estudos científicos? Estudos científicos podem ser classificados em básicos, observacionais, experimentais, acurácia diagnóstica, propriedades psicométricas, avaliação econômica e revisões de literatura:68–77 Estudos básicos69,74 Genética Celular Experimentos com animais Desenvolvimento de métodos Estudos de simulação computacional75,77 Estudos observacionais69,74 Descritivo Estudo de caso Série de casos Transversal Analítico Transversal Caso-Controle Caso-Controle aninhado Caso-Coorte Coorte prospectiva ou retrospectiva Estudos de acurácia diagnóstica73,76 Transversal Caso-Controle Comparativo Totalmente pareado Parcialmente pareado com subgrupo aleatório Parcialmente pareado com subgrupo não aleatório Não pareado aleatório Não pareado não aleatório Estudos de propriedades psicométricas70,72 Validade Confiabilidade Concordância Estudos quase-experimentais71 Quase-aleatorizado controlado Estimação de variável instrumental Descontinuidade de regressão Série temporal interrompida controlada Série temporal interrompida Diferença Estudos experimentais69,74 Fases I a IV Aleatorizado controlado Não-aleatorizado controlado Autocontrolado Cruzado Fatorial Campo Comunitário Estudos de avaliação econômica69 Análise de custo Análise de minimização de custo Análise de custo-utilidade Análise de custo-efetividade Análise de custo-benefício Estudos de revisão68 Estado-da-arte Narrativa Crítica Mapeamento Escopo Busca e revisão sistemática Sistematizada Sistemática Meta-análise Bibliométrica.78,79 Sistemática qualitativa Mista Visão geral Rápida Guarda-chuva Referências "],["ensaios-clínicos-aleatorizados.html", "Capítulo 12 Ensaios clínicos aleatorizados 12.1 Características 12.2 Modelos de análise de comparação 12.3 Ajuste de covariáveis 12.4 Comparação na linha de base 12.5 Comparação intragrupos 12.6 Comparação entre grupos 12.7 Efeito de interação", " Capítulo 12 Ensaios clínicos aleatorizados 12.1 Características 12.1.1 Quais são as características dos ensaios clínicos aleatorizados? A característica essencial de um ensaio clínico aleatorizado é a comparação entre grupos.80 Quanto à unidade de alocação:81 Individual Agrupado Quanto ao número de braços:81 Único* Múltiplos Quanto ao número de centros:81 Único Múltiplos Quanto ao cegamento:81 Aberto* Simples-cego Duplo-cego Tripo-cego Quádruplo-cego Quanto à alocação:81 Sem sorteio Estratificada (centro apenas) Estratificada Minimizada Estratificada e minimizada 12.2 Modelos de análise de comparação 12.2.1 Que modelos podem ser utilizados para comparações? As abordagens compreendem a comparação da variável de desfecho medida entre os momentos antes e depois ou da sua mudança (pré - pós) entre os momentos.82 Se a média da variável é igual entre grupos no início do acompanhamento, ambas abordagens estimam o mesmo efeito. Caso contrário, o efeito será influenciado pela correlação entre as medidas antes e depois. A análise da mudança não controla para desbalanços no início do estudo.82 Uma abordagem recomendada é a análise de covariância (ANCOVA), pois ajusta os valores pós-intervenção aos valores pré-intervenção para cada participante, e não é afetada pelas diferenças entre grupos no início do estudo.82 A análise de covariância (ANCOVA) modelando seja a mudança (pré - pós) quando o desfecho no pós-tratamento parece ser o método mais efetivo considerando-se o viés de estimação dos parâmetros, a precisão das estimativas, a cobertura nominal (isto é, intervalo de confiança) e o poder do teste.83 Análise de variância (ANOVA) e modelos lineares mistos (MLM) são outras opções de métodos, embora apresentem maior variância, menor poder, e cobertura nominal comparados à ANCOVA.83 12.3 Ajuste de covariáveis 12.3.1 Quais variáveis devem ser utilizadas no ajuste de covariáveis? A escolha das características de linha de base pelas quais uma análise é ajustada deve ser determinada pelo conhecimento prévio de uma possível influência no resultado, em vez da evidência de desequilíbrio entre os grupos de tratamento no estudo.84 12.3.2 Quais os benefícios do ajuste de covariáveis? Ajustar por covariáveis ajuda a estimar os efeitos do tratamento para o indivíduo, assim como aumenta a eficiência dos testes para hipótese nula e a validade externa do estudo.85 Incluir a variável de desfecho medida na linha de base como covariável - independentemente de a análise ser realizada com a medida pós-tratamento da mesma variável ou a diferença para a linha de base - pode aumentar o poder estatístico do estudo.86 Incluir outras variáveis medidas na linha de base, com potencial para serem desbalanceadas entre grupos após a aleatorização, diminui a chance de afetar as estimativas de efeito dos tratamentos.86 12.3.3 Quais os riscos do ajuste de covariáveis? Incluir covariáveis que não são prognósticas do desfecho pode reduzir o poder estatístico do estudo.86 Incluir covariáveis com dados perdidos pode reduzir o tamanho amostral e consequentemente o poder estatístico do estudo (análise de casos completos) ou levar a desvios do plano de análise por exclusão de covariáveis prognósticas.86 12.3.4 Como lidar com os dados perdidos em covariáveis? Imputação de dados perdidos de uma variável pela média dos dados observada permite estimativas não enviesadas dos efeitos do tratamento, preserva o erro tipo I e aumenta o poder estatístico comparado à análise de dados completos.86 12.4 Comparação na linha de base 12.4.1 O que é comparação entre grupos na linha de base em ensaios clínicos aleatorizados? A comparação se refere ao teste de hipótese nula de não haver diferença (‘balanço’ ou ‘equilíbrio’) entre grupos de tratamento nas (co)variáveis na linha de base, geralmente apresentadas apenas de modo descritivo na ‘Tabela 1’.87 A interpretação isolada do p-valor da comparação entre grupos na linha de base não permite identificar as razões para eventuais diferenças.87 12.4.2 Para quê comparar grupos na linha de base em ensaios clínicos aleatorizados? Os p-valores estão relacionados à aleatorização dos participantes em grupos.88 Em ensaios clínicos aleatorizados, a comparação de (co)variáveis na linha de base é usada para avaliar se aleatorização foi ‘bem sucedida’.88 12.4.3 Quais são as razões para diferenças entre grupos de tratamento nas (co)variáveis na linha de base? Acaso.87,89 Viés.87,89 Tamanho da amostra.87,89 Má conduta científica.89 12.4.4 Quais cenários permitem a comparação entre grupos na linha de base em ensaios clínicos aleatorizados? Em ensaios clínicos aleatorizados agregados, os p-valores possuem interpretação diferente de estudos aleatorizados individualmente.88 Em ensaios clínicos com agrupamento, nos quais o recrutamento ocorreu após a aleatorização, os p-valores já não estão inteiramente relacionados ao processo de aleatorização, mas sim ao método de recrutamento, o que pode resultar na comparação de amostras não aleatórias.88 12.4.5 Por que não se deve comparar grupos na linha de base em ensaios clínicos aleatorizados? Quando a aleatorização é bem-sucedida, a hipótese nula de diferença entre grupos na linha de base é verdadeira.84 Testes de significância estatística na linha de base avaliam a probabilidade de que as diferenças observadas possam ter ocorrido por acaso; no entanto, já sabemos - pelo delineamento do experimento - que quaisquer diferenças são causadas pelo acaso.90 12.4.6 Quais estratégias podem ser adotadas para substituir a comparação entre grupos na linha de base em ensaios clínicos aleatorizados? Na fase de projeto: identifique as variáveis prognósticas do desfecho de acordo com a literatura.84 Na fase de análise: inclua as variáveis prognósticas nos modelos para ajuste.84 12.5 Comparação intragrupos 12.5.1 Por que não se deve comparar intragrupos (pré - pós) em ensaios clínicos aleatorizados? Testar por mudanças a partir da linha de base separadamente em cada grupos aleatorizados não permite concluir sobre diferenças entre grupos; não se pode fazer inferências a partir da comparação de p-valores.80 12.6 Comparação entre grupos 12.6.1 O que é comparação entre grupos em ensaios clínicos aleatorizados? A comparação se refere ao teste de hipótese nula de não haver diferença (‘alteração’ ou ‘mudança’) pós-tratamento entre grupos de tratamento.80 12.7 Efeito de interação 12.7.1 Por que analisar o efeito de interação? Em ensaios clínicos aleatorizados, o principal problema de pesquisa é se há uma diferença pré - pós maior em um grupo do que em outro(s).80 A comparação de subgrupos por meio de testes de significância de hipótese nula separados é enganosa por não testar (comparar) diretamente os tamanhos dos efeitos dos tratamentos.91 .92 12.7.2 Quando usar o termo de interação? Análise de efeito de interação pode ser usada para testar se o efeito de um tratamento varia entre dois ou mais subgrupos de indivíduos, ou seja, se um efeito é modificado pelo(s) outros(s) efeito(s).93 A interação entre duas (ou mais) variáveis pode ser utilizada para comparar efeitos do tratamento em subgrupos de ensaios clínicos.94 O poder estatístico para detectar efeitos de interação é limitado.94 Referências "],["analise-desempenho-diagnostico.html", "Capítulo 13 Desempenho diagnóstico 13.1 Tabelas 2x2 13.2 Curvas ROC", " Capítulo 13 Desempenho diagnóstico 13.1 Tabelas 2x2 13.1.1 Como analisar o desempenho diagnóstico em tabelas 2x2? Acurácia.[REF] Sensibilidade.[REF] Especificidade.[REF] Valor preditivo positivo.[REF] Valor preditivo negativo.[REF] 13.2 Curvas ROC 13.2.1 O que é área sob a curva (ROC)? A área sob a curva ROC (AUC ou AUROC) quantifica o poder de discriminação ou desempenho diagnóstico na classificação de uma variável dicotômica.95 O pacote proc96 fornece a função plot.roc para criar uma curva ROC. 13.2.2 Como interpretar a área sob a curva (ROC)? A área sob a curva AUC varia no intervalo \\([0.5; 1]\\), com valores mais elevados indicando melhor discriminação ou desempenho do modelo de classificação.95 As interpretações qualitativas (isto é, pobre/fraca/baixa, moderada/razoável/aceitável, boa ou muito boa/alta/excelebt) dos valores de área sob a curva são arbitrários e não devem ser considerados isoladamente.95 Modelos de classificação com valores altos de área sob a curva podem ser enganosos se os valores preditos por esses modelos não estiverem adequadamente calibrados.95 13.2.3 Como analisar o desempenho diagnóstico em desfechos com distribuição trimodal na população? Limiares duplos podem ser utilizados para análise de desempenho diagnóstico de testes com distribuição trimodal.97 Referências "],["analise-concordancia-confiabilidade.html", "Capítulo 14 Concordância e confiabilidade 14.1 Problemas de pesquisa 14.2 Concordância 14.3 Confiabilidade", " Capítulo 14 Concordância e confiabilidade 14.1 Problemas de pesquisa 14.1.1 Quais problemas de pesquisa são investigados com estudos de concordância e confiabilidade? Quão reprodutíveis são as mensurações?98 Os diferentes métodos medem a mesma coisa em média?98 Existe viés entre as medidas de diferentes métodos (isto é, medem a mesma coisa em média)?98 Um método pode substituir o outro?98 14.1.2 Quais fontes de variabilidade são comumente investigadas? Intra/Entre sujeitos.98 Intra/Entre repetições.98 Intra/Entre observadores.98 14.2 Concordância 14.2.1 O que é concordância? .[REF] 14.2.2 Quais métodos são adequados para análise de concordância? Gráfico de dispersão com a reta de regressão.98 Gráfico de limites de concordância (média dos testes vs. diferença entre testes) com a reta de regressão do viés e respectivo intervalo de confiança.98 14.2.3 Quais métodos não são adequados para análise de concordância? Comparação de médias: dois métodos apresentarem médias similares - isto é, ‘sem diferença estatística’ após um teste inferencial de hipótese nula \\(H_{0}:\\mu_{1} = \\mu_{2}\\) - não informa sobre a concordância deles. Métodos com maior erro de medida tendem a ter menos chance de rejeição da hipótese nula.98 Correlação bivariada: o coeficiente de correlação dependente tanto da variação entre indivíduos (isto é, entre os valores verdadeiros) quanto da variação intraindividual (isto é, erro de medida). Se a variância dos erros de medida de ambos os métodos não for pequena comparadas à variância dos valores verdadeiros, o tamanho do efeito da correlação será pequeno mesmo que os métodos possuam boa concordância.98 Regressão linear: o teste da hipótese nula da inclinação da reta de regressão (\\(H_{0}:\\beta = 0\\)) é equivalente a testar a correlação bivariada (\\(H_{0}:\\rho = 0\\)).98 14.3 Confiabilidade 14.3.1 O que é confiabilidade? .[REF] 14.3.2 Quais métodos são adequados para análise de confiabilidade? .[REF] Referências "],["meta-analises.html", "Capítulo 15 Meta-análises 15.1 Meta-análise 15.2 Interpretação de efeitos em meta-análise", " Capítulo 15 Meta-análises 15.1 Meta-análise 15.1.1 O que é meta-análise? .[] 15.2 Interpretação de efeitos em meta-análise 15.2.1 Como avaliar a variação do tamanho do efeito? O intervalo de predição contém informação sobre a variação do tamanho do efeito.99 Se o intervalo de predição não contém a hipótese nula (\\(H_{0}\\)), podemos concluir que (a) o tratamento funciona igualmente bem em todas as populações, ou que ele funciona melhor em algumas populações do que em outras.99 Se o intervalo de predição contém a hipótese nula (\\(H_{0}\\)), podemos concluir que o tratamento pode ser benéfico em algumas populações, mas prejudicial em outras, de modo que a estimativa pontual (geralmente a média) torna-se amplamente irrelevante. Nesse caso, é recomendado investigar em que populações o tratamento seria benéfico e em quais causaria danos.99 15.2.2 Como avaliar a heterogeneidade entre os estudos? A heterogeneidade - variação não-aleatória - no efeito do tratamento entre os estudos incluídos em uma meta-análise pode ser avaliada pelo \\(I^{2}\\).99,100 \\(I^{2}\\) representa qual proporção da variância observada reflete a variância nos efeitos verdadeiros em vez do erro de amostragem.99 \\(I^{2}\\) não depende da quantidade de estudos incluídos na meta-análise. Entretanto, \\(I^{2}\\) aumenta com a quantidade de participantes incluídos nos estudos meta-analisados.100 A heterogeneidade entre estudos é explicada de modo mais confiável utilizando dados de pacientes individuais, uma vez que a direção verdadeira da modificação de efeito não pode ser observada a partir de dados agregados no estudo.101 O pacote metagear102 fornece funções para condução e análise de revisões sistemáticas O pacote metagear102 fornece a função plot_PRISMA para gerar o fluxograma de uma revisão sistemática de acordo com o Preferred Reporting Items for Systematic Reviews and Meta-Analyses103. O pacote PRISMA2020104,105 fornece a função PRISMA_flowdiagram para elaboração do fluxograma de revisões sistemáticas no formato padrão. Referências "],["simulacao-computacional.html", "Capítulo 16 Simulação computacional 16.1 Simulação computacional de dados", " Capítulo 16 Simulação computacional 16.1 Simulação computacional de dados 16.1.1 O que é simulação computacional de dados? .[REF] "],["parte-3---estatística-epidemiologia.html", "PARTE 3 - Estatística &amp; Epidemiologia", " PARTE 3 - Estatística &amp; Epidemiologia "],["selecao-testes.html", "Capítulo 17 Seleção de testes 17.1 Escolha de testes para análise inferencial", " Capítulo 17 Seleção de testes 17.1 Escolha de testes para análise inferencial 17.1.1 Como selecionar os testes para a análise estatística inferencial? .106 .107 .108 .109 .110 .111 .112 .113 Referências "],["analise-exploratoria-dados.html", "Capítulo 18 Análise exploratória de dados 18.1 Análise exploratória de dados", " Capítulo 18 Análise exploratória de dados 18.1 Análise exploratória de dados 18.1.1 O que é análise exploratória de dados? Análise exploratória deve ser separada da análise inferencial de testes de hipóteses; a decisão sobre os modelos a testar deve ser feita a priori.57 A condução de análise exploratória de dados pode ajudar a identificar padrões e pode prientar trabalhos futuros, mas os resultados não devem ser interpretatos como inferências sobre uma população.57 A análise exploratória não deve ser usada para definir as questões e hipóteses científicas do estudo.57 Cada combinação de problema de pesquisa e delineamento de estudo pode demandar um plano de análise exploratório distinto.57 O pacote explore114 fornece a função explore para análise exploratória de um banco de dados. 18.1.2 Quais etapas constituem a análise exploratória de dados? Verifique a existência e/ou influência de valores discrepantes (“fora da curva” ou outliers):57 Boxplots O pacote graphics115 fornece a função boxplot para construção de gráficos boxplot. Verifique a homocedasticidade (homogeneidade da variância):57 Boxplots condicionais (por fator de análise) Análise dos resíduos do modelo de regressão Gráfico resíduos vs. valores ajustados Verifique a normalidade da distribuição dos dados:57 Histograma das variáveis (por fator de análise) Histograma dos resíduos da regressão Verifique a existência de grande quantidade de valores 0:57 Histograma das variáveis (por fator de análise) Verifique a existência de colinearidade entre variáveis independentes de um modelo de regressão:57 Fator de inflação de variância (variance inflation factor, VIF) Coeficiente de correlação de Pearson (\\(r\\)) Gráfico de dispersão entre variáveis Verifique possíveis relações entre as variáveis dependente(s) e independente(s) de um modelo de regressão:57 Gráfico de dispersão entre variáveis independente e dependente Verifique possíveis interações entre as variáveis dependente(s) de um modelo de regressão:57 Gráfico coplot de dispersão entre variáveis dependentes O pacote graphics115 fornece a função coplot para construção de gráficos boxplot condicionais. Verifique por dependência entre variáveis de um modelo de regressão:57 Gráfico de série temporal das variáveis Gráfico de autocorrelação entre as variáveis Referências "],["analise-descritiva.html", "Capítulo 19 Análise descritiva 19.1 Análise descritiva 19.2 Tabelas 19.3 Tabela 1 19.4 Tabela 2 19.5 Gráficos", " Capítulo 19 Análise descritiva 19.1 Análise descritiva 19.1.1 O que é análise descritiva? A análise descritiva utiliza métodos para calcular, descrever e resumir os dados coletados da(s) amostra(s) de modo que sejam interpretadas adequadamente.20 As análises descritivas geralmente compreendem a apresentação quantitativa (numérica) em tabelas e/ou gráficos.20 O pacote dataExplorer116 fornece a função create_report para executar análise exploratória. 19.2 Tabelas 19.2.1 Por que usar tabelas? Tabelas complementam o texto (e vice-versa), e podem apresentar os dados de modo mais acessível e informativo.117 19.3 Tabela 1 19.3.1 O que é a ‘Tabela 1’? A ‘Tabela 1’ descreve as características da amostra, completa ou agrupada por algum fator, geralmente por meio de parâmetros de tendência central e dispersão.89 19.3.2 Qual a utilidade da ‘Tabela 1’? Descrever (conhecer) as características da amostra e dos grupos sendo comparados, quando aplicável.89 Verificar aderência ao protocolo do estudo, incluindo critérios de inclusão/exclusão, tamanho da amostra e perdas amostrais.89 Permitir a replicação do estudo.89 Meta-analisar os dados junto a estudos similares.89 Avaliar a generalização (validade externa) das conclusões do estudo.89 19.3.3 Como construir a Tabela 1? A Tabela 1 geralmente é utilizada para descrever as características da amostra estudada, possibilitando a análise de ameaças à validade interna e/ou externa ao estudo.118 Inclua na tabela: título ou legenda, uma síntese descritiva (geralmente por meio de parâmetros descritivos), intervalos de confiança e/ou p-valores conforme necessário para adequada interpretação.117,119 O pacote table1120 fornece a função table1 para construção da tabela. O pacote table1121 fornece as funções as_flextable e save_as_docx para salvar tabelas em formato DOCX. 19.4 Tabela 2 19.4.1 O que é a ‘Tabela 2’? .[REF] 19.4.2 Qual a utilidade da ‘Tabela 2’? .[REF] 19.4.3 Como construir a Tabela 2? A Tabela 2 pode ser utilizada para apresentar estimativas de múltiplos efeitos ajustados de um mesmo modelo estatístico.122 O pacote table1120 fornece a função table1 para construção da tabela. O pacote table1121 fornece as funções as_flextable e save_as_docx para salvar tabelas em formato DOCX. 19.5 Gráficos 19.5.1 O que são gráficos? Gráficos são utilizados para apresentar dados (geralmente em grande quantidade) de modo mais intuitivo e fácil de compreender.123 19.5.2 Qual a utilidade dos gráficos? .[REF] 19.5.3 Que elementos incluir em gráficos? Título, eixos horizontal e vertical com respectivas unidades, escalas em intervalos representativos das variáveis, legenda com símbolos, síntese descritiva dos valores e respectiva margem de erro, conforme necessário para adequada interpretação.123 Os pacotes ggplot2124, plotly125 e corrplot126 fornecem diversas funções para construção de gráficos tais como ggplot, plot_ly e corrplot respectivamente. 19.5.4 Para que servem as barras de erro em gráficos? Barras de erro ajudam ao autor a apresentar as informações que descrevem os dados (por exemplo, em uma análise descritiva) ou sobre as inferências ou conclusões tomadas a partir de dados.127 Barras de erro mais longas representam mais imprecisão (maiores erros), enquanto barras mais curtas representam mais precisão na estimativa.127 Barras de erro descritivas geralmente apresentam a amplitude (mínimo-máximo) ou desvio-padrão.127 Barras de erro inferenciais geralmente apresentam o erro-padrão ou intervalo de confiança (por exemplo, de 95%).127 O comprimento das barras de erro sugere graficamente a imprecisão dos dados do estudo, uma vez que o valor verdadeiro da população pode estar em qualquer nível do intervalo da barra.127 19.5.5 Quais são as boas práticas na elaboração de gráficos? O tamanho da amostra total e subgrupos, se houver, deve estar descrito na figura ou na sua legenda.127 Para análise inferencial de figuras, as barras de erro representadas por erro-padrão ou intervalo de confiança são preferíveis à amplitude ou desvio-padrão.127 Evite gráficos de barra e mostre a distribuição dos dados sempre que possível.128 Exiba os pontos de dados em boxplots.128 Use jitter simétrico em gráficos de pontos para permitir a visualização de todos os dados.128 Prefira palhetas de cor adaptadas para daltônicos.128 O pacote ggsci129 fornece palhetas de cores tais como pal_lancet, pal_nejm e pal_npg inspiradas em publicações científicas para uso em gráficos. O pacote tiff130 fornece a função writeTIFF para exportar gráficos em formato TIFF. Referências "],["analise-inferencial.html", "Capítulo 20 Análise inferencial 20.1 Análise inferencial 20.2 Tipos de análises inferenciais 20.3 Ideias e hipóteses científicas 20.4 Testes de hipóteses 20.5 Erros de inferência 20.6 P-valor 20.7 Tamanho do efeito 20.8 Teste paramétrico e não paramétrico", " Capítulo 20 Análise inferencial 20.1 Análise inferencial 20.1.1 O que é análise inferencial? Na análise inferencial são utilizados dados da(s) amostra(s) para fazer uma inferência válida (isto é, estimativa) sobre os parâmetros populacionais desconhecidos.20 No paradigma de Jerzy Neyman e Egon Pearson, um teste de hipótese científica envolve a tomada de decisão sobre hipóteses nulas (\\(H_{0}\\)) e alternativa (\\(H_{1}\\)) concorrentes e mutuamente exclusivas.131 20.1.2 O que é hipótese nula? A hipótese nula (\\(H_{0}\\)) é uma expressão que representa o estado atual do conhecimento (status quo), em geral a não existência de um determinado efeito.53 20.1.3 O que é hipótese alternativa? A hipótese alternativa (\\(H_{1}\\)) é uma expressão que contém as situações que serão testadas, de modo que um resultado positivo indique alguma ação a ser conduzida.53 20.1.4 Qual hipótese está sendo testada? A hipótese nula (\\(H_{0}\\)) é a hipótese sob teste em análises inferenciais.33 Pode-se concluir sobre rejeitar ou não rejeitar a hipótese nula (\\(H_{0}\\)).33 Não se conclui sobre a hipótese alternativa (\\(H_{1}\\)).53 Para testar a hipótese nula, deve-se selecionar o nível de significância crítica (p-valor de corte); a probabilidade de rejeitarmos uma hipótese nula verdadeira (\\(\\alpha\\)); e a probabilidade de não rejeitarmos uma hipótese nula falsa (\\(\\beta\\)).131 20.1.5 O que reportar após um teste de hipótese? P-valores, como estimativa da significância estatística.132 Tamanho do efeito, como estimativa de significância substantiva (clínica).132 20.2 Tipos de análises inferenciais 20.2.1 O que é uma análise ad hoc? .[REF] 20.2.2 O que é uma análise post hoc? .[REF] 20.3 Ideias e hipóteses científicas 20.3.1 O que é hipótese científica? Hipótese científica é uma ideia que pode ser testada.131 20.3.2 Quais são as principais fontes de ideias para gerar hipóteses científicas? Revisão das práticas atuais.133 Desafio a ideias aceitas.133 Conflito entre ideias divergentes.133 Variações regionais, temporais e populacionais.133 Experiências dos próprios pesquisadores.133 Imaginação sem fronteiras ou limites convencionais.133 20.4 Testes de hipóteses 20.4.1 Quais são os tipos de teste de hipóteses? Teste (clássico) de significância da hipótese nula.134 Teste de mínimos efeitos.134 Teste de equivalência.134 Teste de inferioridade.134 Teste de não-inferioridade.[REF] Teste de superioridade.[REF] 20.5 Erros de inferência 20.5.1 O que são erros de inferência estatística? Um erro de inferência é a tomada de decisão incorreta, seja a favor ou contra a hipótese nula.131 20.5.2 O que é erro tipo I? Erro tipo I significa a rejeição de uma hipótese nula (\\(H_{0}\\)) quando esta é verdadeira.131 20.5.3 O que é erro tipo II? Erro tipo II significa a não rejeição de uma hipótese nula (\\(H_{0}\\)) quando esta é falsa.131 20.5.4 O que é poder do teste? Poder do teste é a probabilidade de rejeitar a hipótese nula (\\(H_{0}\\)) quando esta é falsa.131 Poder do teste pode ser calculado como (\\(1 - \\beta\\)).131 20.5.5 Qual a relação entre os erros tipo I e II? .[REF] 20.6 P-valor 20.6.1 O que é o P-valor? .[REF] 20.7 Tamanho do efeito 20.7.1 O que é o tamanho do efeito? Tamanho do efeito quantifica a magnitude de um efeito real da análise, expressando uma importância descritiva dos resultados.135 20.7.2 Como interpretar um tamanho do efeito? Tamanhos de efeito podem ser comparadores entre diferentes estudos.132 20.7.3 Quais são os tipos de tamanho do efeito? Diferenças padronizadas entre grupos:132,135 Cohen’s d Glass’s \\(\\Delta\\) Razão de chances (\\(RC\\) ou \\(OR\\)) Risco relativo ou razão de risco (\\(RR\\)) Medidas de associação:132,135 Coeficiente de correlação de Pearson (\\(r\\)) Coeficiente de determinação (\\(R^2\\)) 20.7.4 Como converter um tamanho de efeito em outro? .135 20.8 Teste paramétrico e não paramétrico 20.8.1 O que é um teste paramétrico? Testes paramétricos possuem suposições sobre as características e/ou parâmetros da distribuição dos dados na população.20 Testes paramétricos assumem que: a variável é quantitativa numérica (contínua); os dados foram amostrados de uma população com distribuição normal; a variância da(S) amostra(s) é igual à da população; as amostras foram selecionadas de modo aleatório na população; os valores de cada amostra são independentes entre si.20,33 20.8.2 O que é um teste não paramétrico? Testes não-paramétricos fazem poucas suposições, ou menos rigorosas, sobre as características e/ou parâmetros da distribuição dos dados na população.20,33 Testes não-paramétricos são úteis quando as suposições de normalidade não podem ser sustentadas.33 20.8.3 Por que os testes paramétricos são preferidos? Em geral, testes paramétricos são mais robustos (isto é, possuem menores erros tipo I e II) que seus testes não-paramétricos correspondentes.20 Testes não-paramétricos apresentam menor poder estatístico (maior erro tipo II) comparados aos testes paramétricos correspondentes.33 Referências "],["analise-comparacao.html", "Capítulo 21 Comparação 21.1 Análise inferencial de comparação", " Capítulo 21 Comparação 21.1 Análise inferencial de comparação 21.1.1 O que é análise de comparação de dados? .[REF] "],["analise-inferencial-correlacao.html", "Capítulo 22 Correlação 22.1 Análise de correlação", " Capítulo 22 Correlação 22.1 Análise de correlação 22.1.1 O que é análise de correlação? .[REF] 22.1.2 Qual é a interpretação das medidas de correlação? Os valores de correlação estão no intervalo \\([-1; 1]\\).136,137 Valores de correlação positivos representam uma relação direta entre as variáveis, tal que valores maiores de uma variável estão associados a valores maiores de outra variável.136,137 Valores de correlação negativos representam uma relação indireta (ou inversa) entre as variáveis, tal que valores maiores (menores) de uma variável estão associados a valores maiores (menores) de outra variável.136,137 Valores de correlação próximos de \\(0\\) representam a inexistência de relação entre as variáveis.136,137 22.1.3 Quais precauções devem ser tomadas na interpretação de medidas de correlação? Tamanhos de efeito grande (ou qualquer outro) não representam necessariamente uma relação causa-efeito entre as variáveis.136 Tamanhos de efeito grande (ou qualquer outro) não representam necessariamente uma relação de concordância ou confiabilidade entre as variáveis.136 22.1.4 Quais testes podem ser usados para análises de correlação? Coeficiente de correlação de Pearson (\\(r\\)).136,137 O coeficiente de correlação de Pearson (\\(r\\)) avalia a força e direção da relação linear entre duas variáveis quantitativas.136,137 Tipo: paramétrico.136,137 Hipóteses:137 Nula (\\(H_{0}\\)): \\(r=0\\) Alternativa (\\(H_{1}\\)): \\(r≠0\\) Tamanho do efeito:136,137 Coeficiente de correlação de Pearson (\\(r\\)) O pacote stats18 fornece a função fornece a função cor.test para calcular o coeficiente de correlação de Pearson (\\(r\\)). Coeficiente de correlação ponto-bisserial (\\(r_{s}\\)).136 O coeficiente de correlação ponto-bisserial (\\(r_{s}\\)) avalia a força e direção da relação linear entre uma variável quantitativa e outra dicotômica.136 Tipo: paramétrico.136 Hipóteses:136 Nula (\\(H_{0}\\)): \\(r_{s}=0\\) Alternativa (\\(H_{1}\\)): \\(r_{s}≠0\\) Tamanho do efeito:136 Coeficiente de correlação ponto-bisserial (\\(r_{s}\\)) O pacote stats18 fornece a função fornece a função cor.test para calcular o coeficiente de correlação ponto-bisserial (\\(r_{s}\\)). Coeficiente de correlação de Spearman (\\(\\rho\\)).136,137 O coeficiente de correlação de Spearman (\\(\\rho\\)) avalia a força e direção da relação monotônica entre duas variáveis quantitativas.136,137 O coeficiente de correlação de Spearman (\\(\\rho\\)) pode ser também definida como a correlação de Pearson (\\(r\\)) entre as classificações (ranks) das duas variáveis quantitativas.136,137 Tipo: não-paramétrico.136,137 Hipóteses:136,137 Nula (\\(H_{0}\\)): \\(\\rho=0\\) Alternativa (\\(H_{1}\\)): \\(\\rho≠0\\) Tamanho do efeito:136,137 Coeficiente de correlação de Spearman (\\(\\rho\\)) O pacote stats18 fornece a função fornece a função cor.test para calcular o coeficiente de correlação de Spearman (\\(\\rho\\)). Referências "],["analise-inferencial-associacao.html", "Capítulo 23 Associação 23.1 Análise de associação 23.2 Associação bivariada", " Capítulo 23 Associação 23.1 Análise de associação 23.1.1 O que é análise de associação? .[REF] 23.2 Associação bivariada 23.2.1 O que são análises de associação bivariada? .[REF] 23.2.2 Quais testes podem ser usados para análises de associação bivariada? Teste Qui-quadrado (\\(\\chi^2\\)).138,139 O teste qui-quadrado (\\(\\chi^2\\)) avalia uma hipótese global se a relação entre duas variáveis e/ou fatores é independente ou associada.139 O teste qui-quadrado é utilizado para comparar a distribuição de uma variável categórica em uma amostra ou grupo com a distribuição em outro. Se a distribuição da variável categórica não for muito diferente nos diferentes grupos, pode-se concluir que a distribuição da variável categórica não está relacionada com a variável dos grupos. Pode-se também concluir que a variável categórica e os grupos são independentes.139 Tipo: não paramétrico.138,139 Suposições:138,139 As variáveis são ordinais ou categóricas nominais, de modo que as células representem frequência. Os níveis dos fatores (variáveis categóricas) são mutuamente exclusivos. Tamanho de amostra grande e adequado porque é baseado em uma abordagem de aproximação. Menos de 20% das células com frequências esperadas &lt; 5 Nenhuma célula com frequência esperada &lt; 1. Hipóteses:139 Nula (\\(H_{0}\\)): independente (sem associação) Alternativa (\\(H_{1}\\)): não independente (associação) Tamanho do efeito:139 Phi (\\(\\phi\\)), para tabelas de contingência 2x2 Razão de chances (\\(RC\\) ou \\(OR\\)), para tabelas de contingência 2x2 Cramer V (\\(V\\)), para tabelas de contingência NxM O pacote gtsummary140 fornece a função tbl_cross para criar uma tabela NxM. Teste Exato de Fisher (\\(\\chi^2\\)).138,139 O teste exato de Fisher avalia a hipótese nula de independência aplicando a distribuição hipergeométrica dos números nas células da tabela.139 Hipóteses:138,139 Nula (\\(H_{0}\\)): independente (sem associação) Alternativa (\\(H_{1}\\)): não independente (associação) Tamanho do efeito:138,139 Phi (\\(\\phi\\)), para tabelas de contingência 2x2 Razão de chances (\\(RC\\) ou \\(OR\\)), para tabelas de contingência 2x2 Cramer V (\\(V\\)), para tabelas de contingência NxM O pacote gtsummary140 fornece a função tbl_cross para criar uma tabela NxM. Kendall \\(\\tau\\).136,137 O coeficiente Kendall \\(\\tau\\) avalia a força e direção da relação monotônica entre duas variáveis quantitativas ou qualitativas.136,137 O coeficiente Kendall \\(\\tau\\) é definido como a porporção de todos os pares concordantes menos a proporção de todos os pares discordantes.136,137 Tipo: não-paramétrico.136,137 Hipóteses:136,137 Nula (\\(H_{0}\\)): \\(\\tau=0\\) Alternativa (\\(H_{1}\\)): \\(\\tau≠0\\) Tamanho do efeito:136,137 Kendall \\(\\tau\\) O pacote stats18 fornece a função cor.test para calcular o coeficiente Kendall \\(\\tau\\). Referências "],["analise-inferencial-regressao.html", "Capítulo 24 Regressão 24.1 Análise de regressão 24.2 Regressão simples, multivariável e multivariada 24.3 Efeito principal 24.4 Efeito de modificação 24.5 Efeito de interação 24.6 Efeito de mediação 24.7 Seleção de variáveis", " Capítulo 24 Regressão 24.1 Análise de regressão 24.1.1 O que é análise de regressão? .[REF] 24.1.2 Como preparar as variáveis categóricas para análise de regressão? Variáveis fictícias (dummy) compreendem variáveis criadas para introduzir, nos modelos de regressão, informações contidas em outras variáveis que não podem ser medidas em escala numérica.141 Variáveis categóricas nominais, com 2 ou mais níveis, devem ser subdivididas em variáveis fictícias dicotômicas para ser usada em modelos de regressão.142 Cada nível da variável categórica nominal será convertido em uma nova variável fictícias dicotômica, tal que a nova variável dicotômica assume valor 1 para a presença do nível correspondente e 0 em qualquer outro caso.142 O pacote fastDummies143 fornece a funçãao dummy_cols para preparar as variáveis categóricas fictícias para análise de regressão. 24.2 Regressão simples, multivariável e multivariada 24.2.1 O que são as análises de regressão simples, multivariável e multivariada? A análise de regressão simples consiste em modelos estatísticos com 1 variável dependente (desfecho) e 1 variável independente (preditor).144 A análise multivariável (ou múltiplo) consiste em modelos estatísticos com 1 variável dependente (desfecho) e duas ou mais variáveis independentes.144 A análise multivariada consiste em modelos estatísticos com 2 ou mais variáveis dependente (desfechos) e duas ou mais variáveis independentes.144 O pacote modelsummary145 fornece as funções modelsummary e modelplot para gerar tabelas e gráficos de coeficientes de regressão. 24.2.2 Quais testes podem ser usados em análise de associação multivariável? .[REF] 24.3 Efeito principal 24.3.1 O que é modificação de efeito? .92 24.3.2 O que é um modificador de efeito? .92 24.4 Efeito de modificação 24.4.1 O que é modificação? .92 24.4.2 O que é um modificador de efeito? .92 24.5 Efeito de interação 24.5.1 O que é interação? A interação - representada pelo símbolo ‘*’ - é o termo estatístico empregado para representar a heterogeneidade de um determinado efeito.93 .92 24.6 Efeito de mediação 24.6.1 O que é mediação? .146 .92 24.6.2 O que é um mediador de efeito? .146 .92 24.6.3 O que é efeito direto? .146 .92 24.6.4 O que é efeito indireto? .146 .92 24.6.5 O que é efeito total? .146 .92 24.7 Seleção de variáveis 24.7.1 Correlação bivariada pode ser usada para seleção de variáveis em modelos de regressão multivariável? Seleção bivariada de variáveis - isto é, aplicação de testes de correlação em pares de variáveis candidatas e variável de desfecho afim de selecionar quais serão incluídas no modelo multivariável - é um dos erros mais comuns na literatura.147,148 A seleção bivariada de variáveis torna o modelo mais suscetível a otimismo no ajuste se as variáveis de confundimento não são adequadamente controladas.147,148 24.7.2 Por que métodos de regressão gradual não são recomendados para seleção de variáveis em modelos de regressão multivariável? Métodos diferentes de regressão gradual podem produzir diferentes seleções de variáveis de um mesmo banco de dados.142 Nenhum método de regressão gradual garante a seleção ótima de variáveis de um banco de dados.142 As regras de término da regressão baseadas em p-valor tendem a ser arbitrárias.142 24.7.3 O que pode ser feito para reduzir o número de variáveis candidatas em modelos de regressão multivariável? Verifique a existência de multicolinearidade entre as variáveis candidatas.148 Em caso de uma proporção baixa entre o número de participantes e de variáveis, use o conhecimento prévio da literatura para selecionar um pequeno conjunto de variáveis candidatas.148 Colapse categorias com contagem nula (células com valor igual a 0) de variáveis candidatas.148 Use simulações de dados para identificar qual(is) variável(is) está(ão) causando problemas de convergência do ajuste do modelo.148 Referências "],["analise-redes.html", "Capítulo 25 Redes 25.1 Análise de redes", " Capítulo 25 Redes 25.1 Análise de redes 25.1.1 O que é análise de rede? .[REF] "],["testes-estatisticos.html", "Capítulo 26 Testes estatísticos 26.1 Teste de Qui-quadrado (\\(\\chi^2\\)) 26.2 Teste exato de Fisher", " Capítulo 26 Testes estatísticos 26.1 Teste de Qui-quadrado (\\(\\chi^2\\)) Code # carrega os pacotes library(&quot;dplyr&quot;) library(&quot;gtsummary&quot;) # tabela 2x2 tbl_cross &lt;- # banco de dados tbl_cross &lt;- # banco de dados trial %&gt;% # cria a tabela de contingência gtsummary::tbl_cross(row = trt, col = response, statistic = &quot;{n}&quot;, digits = 0, percent = &quot;cell&quot;, margin = c(&quot;row&quot;, &quot;column&quot;), missing = &quot;no&quot;, missing_text = &quot;Dados perdidos&quot;, margin_text = &quot;Total&quot;) %&gt;% # calcula o p-valor do teste gtsummary::add_p(test = &quot;chisq.test&quot;, pvalue_fun = function(x) style_pvalue(x, digits = 3)) %&gt;% gtsummary::modify_header(p.value = &quot;**P-valor**&quot;) %&gt;% # calcula o tamanho do efeito gtsummary::modify_table_styling(rows = NULL, footnote = as.character(rstatix::cramer_v(trt, response))) %&gt;% # formata o título em negrito gtsummary::bold_labels() %&gt;% # cria título da tabela gtsummary::modify_caption(&quot;Teste Qui-quadrado (com correção de Yates)&quot;) # exibe a tabela tbl_cross %&gt;% gtsummary::as_hux_table() Tabela 26.1: Teste Qui-quadrado (com correção de Yates) Tumor Response 0 1 Total P-valor Chemotherapy Treatment0.637 Drug A672895 Drug B653398 Total13261193 Pearson's Chi-squared test Code # carrega os pacotes library(&quot;dplyr&quot;) library(&quot;gtsummary&quot;) # tabela 2x2 tbl_cross &lt;- # banco de dados tbl_cross &lt;- # banco de dados trial %&gt;% # cria a tabela de contingência gtsummary::tbl_cross(row = trt, col = response, statistic = &quot;{n}&quot;, digits = 0, percent = &quot;cell&quot;, margin = c(&quot;row&quot;, &quot;column&quot;), missing = &quot;no&quot;, missing_text = &quot;Dados perdidos&quot;, margin_text = &quot;Total&quot;) %&gt;% # calcula o p-valor do teste gtsummary::add_p(test = &quot;chisq.test.no.correct&quot;, pvalue_fun = function(x) style_pvalue(x, digits = 3)) %&gt;% gtsummary::modify_header(p.value = &quot;**P-valor**&quot;) %&gt;% # calcula o tamanho do efeito gtsummary::modify_table_styling(rows = NULL, footnote = as.character(rstatix::cramer_v(trt, response))) %&gt;% # formata o título em negrito gtsummary::bold_labels() %&gt;% # cria título da tabela gtsummary::modify_caption(&quot;Teste Qui-quadrado (sem correção de Yates)&quot;) # exibe a tabela tbl_cross %&gt;% gtsummary::as_hux_table() Tabela 26.2: Teste Qui-quadrado (sem correção de Yates) Tumor Response 0 1 Total P-valor Chemotherapy Treatment0.530 Drug A672895 Drug B653398 Total13261193 Pearson's Chi-squared test 26.2 Teste exato de Fisher Code # carrega os pacotes library(&quot;dplyr&quot;) library(&quot;gtsummary&quot;) # tabela 2x2 tbl_cross &lt;- # banco de dados tbl_cross &lt;- # banco de dados trial %&gt;% # cria a tabela de contingência gtsummary::tbl_cross(row = trt, col = response, statistic = &quot;{n}&quot;, digits = 0, percent = &quot;cell&quot;, margin = c(&quot;row&quot;, &quot;column&quot;), missing = &quot;no&quot;, missing_text = &quot;Dados perdidos&quot;, margin_text = &quot;Total&quot;) %&gt;% # calcula o p-valor do teste gtsummary::add_p(test = &quot;fisher.test&quot;, pvalue_fun = function(x) style_pvalue(x, digits = 3)) %&gt;% gtsummary::modify_header(p.value = &quot;**P-valor**&quot;) %&gt;% # calcula o tamanho do efeito gtsummary::modify_table_styling(rows = NULL, footnote = as.character(rstatix::cramer_v(trt, response))) %&gt;% # formata o título em negrito gtsummary::bold_labels() %&gt;% # cria título da tabela gtsummary::modify_caption(&quot;Teste exato de Fisher&quot;) # exibe a tabela tbl_cross %&gt;% gtsummary::as_hux_table() Tabela 26.3: Teste exato de Fisher Tumor Response 0 1 Total P-valor Chemotherapy Treatment0.540 Drug A672895 Drug B653398 Total13261193 Fisher's exact test "],["parte-4---produção-bibliográfica.html", "PARTE 4 - Produção Bibliográfica", " PARTE 4 - Produção Bibliográfica "],["computacao-estatistica.html", "Capítulo 27 Computação estatística 27.1 Por onde começar", " Capítulo 27 Computação estatística 27.1 Por onde começar 27.1.1 O que é R? R é um programa de computador com linguagem computacional direcionada para análise estatística.149 R version 4.3.1 (2023-06-16).149 27.1.2 O que são scripts? Um script é um arquivo de texto contendo (quase) os mesmos comandos que você digitaria na linha de comando do R. (Quase) refere-se ao fato de que se você estiver usando sink() para enviar a saída para um arquivo, você terá que incluir alguns comandos em print() para obter a mesma saída da linha de comando (CRAN). 27.1.3 Quais práticas são recomendadas na redação de scripts? Use nomes consistentes para as variáveis.150 Defina os tipos de variáveis adequadamente no banco de dados.150 Defina constantes - isto é, variáveis de valor fixo - ao invés de digitar valores.150 Use e cite os pacotes disponíveis para suas análises.150 Controle as versões do script.150,151 Teste o script antes de sua utilização.150 Conduza revisão por pares do código durante a redação (digitação em dupla).150 27.1.4 O que pode ser compartilhado? Idealmente, todos os scripts, pacotes/bibliotecas e dados necessários para outros reproduzirem seus dados.151 Minimamente, partes importantes incluindo implementações de novos algoritmos e dados que permitam reproduzir um resultado importante.151 27.1.5 Como preparar os scripts para compartilhamento? Crie links persistentes para versões do seu script.151 Escolha uma licença apropriada para garantir como outros usarão seus scripts.151 Providencie a documentação sobre seu script (ex.: arquivos README).151 Compartilhar todos os pacotes relacionados à sua análise.152 O pacote formatR153 fornece a função tidy_source para formatar um R script. 27.1.6 Que programas de computador gratuitos podem ser usados para análise estatística com R? RStudio JASP.154 jamovi.155 Referências "],["manuscritos-reprodutiveis.html", "Capítulo 28 Manuscritos reprodutíveis 28.1 Manuscritos reprodutíveis", " Capítulo 28 Manuscritos reprodutíveis 28.1 Manuscritos reprodutíveis 28.1.1 O que são manuscritos reprodutíveis? .[REF] "],["redacao.html", "Capítulo 29 Redação estatística 29.1 Plano de anális estatística 29.2 Diretrizes 29.3 Checklists", " Capítulo 29 Redação estatística 29.1 Plano de anális estatística 29.1.1 O que é plano de análise estatística? .[REF] 29.2 Diretrizes 29.2.1 Por que usar diretrizes? .[REF] 29.2.2 Quais diretrizes estão disponíveis? Review of guidance papers on regression modeling in statistical series of medical journals.156 Principles and recommendations for incorporating estimands into clinical study protocol templates.157 How to write statistical analysis section in medical research.107 Recommendations for Statistical Reporting in Cardiovascular Medicine: A Special Report From the American Heart Association.158 Framework for the treatment and reporting of missing data in observational studies: The Treatment And Reporting of Missing data in Observational Studies framework.159 Guidelines for reporting of figures and tables for clinical research in urology.160 Who is in this study, anyway? Guidelines for a useful Table 1.118 Guidelines for Reporting of Statistics for Clinical Research in Urology.161 Reveal, Don’t Conceal: Transforming Data Visualization to Improve Transparency.128 Guidelines for the Content of Statistical Analysis Plans in Clinical Trials.162 Basic statistical reporting for articles published in Biomedical Journals: The ‘’Statistical Analyses and Methods in the Published Literature’’ or the SAMPL Guidelines.163 Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm.164 STRengthening analytical thinking for observational studies: the STRATOS initiative.165 Research methods and reporting.166 How to ensure your paper is rejected by the statistical reviewer.167 29.3 Checklists 29.3.1 Por que usar checklists? Checklists têm sido recomendados para melhorar o relato das análises realizadas, aumentar a transparência do estudo e reprodutibilidade dos achados.168 Trabalhos acadêmicos que relatam análises de dados devem ser passar por revisão por pares que inclua apreciação da análise estatística, e sua adequação ao delineamento do estudo e instrumentos utilizados.169 Checklists não são suficientes para garantir a qualidade técnica da pesquisa, mas podem contribuir para a revisão por pares.169 29.3.2 Quais checklists estão disponíveis? A CHecklist for statistical Assessment of Medical Papers (the CHAMP statement): explanation and elaboration.170 Checklist for clinical applicability of subgroup analysis.171 Evidence‐based statistical analysis and methods in biomedical research (SAMBR) checklists according to design features.106 Referências "],["bibliografia.html", "BIBLIOGRAFIA", " BIBLIOGRAFIA "],["fontes-externas.html", "Fontes externas Royal Statistical Society American Statistical Association EQUATOR Network British Medicine Journal Journal of the Amercan Medical Association American Heart Association Nature Publishing Group Wiley Online Library American Physiological Society", " Fontes externas Royal Statistical Society Best Practices for Data Visualisation - Royal Statistical Society American Statistical Association Statistical Inference in the 21st Century: A World Beyond p &lt; 0.05 - The American Statistical Association EQUATOR Network Enhancing the Quality and Transparency of health research EQUATOR Network.172 British Medicine Journal Statistics - Latest from The BMJ Statistics notes - Latest from The BMJ Statistics and research methods - Latest from The BMJ Statistics at Square One Research methods &amp; reporting Journal of the Amercan Medical Association JAMA Guide to Statistics and Methods - JAMA American Heart Association Statistical Reporting Recommendations - AHA/ASA journals Nature Publishing Group Statistics for Biologists - Nature Publising Group Wiley Online Library Tutorials in Biostatistics Papers - Wiley Online Library American Physiological Society Statistics Exploration in Statistics General Statistics Reporting Statistics Referências "],["referências.html", "Referências", " Referências "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
