[["index.html", "Ciência com R Perguntas e respostas para pesquisadores e analistas de dados Capa", " Ciência com R Perguntas e respostas para pesquisadores e analistas de dados © 2023–2025 by Arthur de Sá Ferreira https://orcid.org/0000-0001-7014-2002 @cienciacomr Capa A versão online desta obra está licenciada com uma Licença Creative Commons Atribuição-NãoComercial 4.0 Internacional.Ciência com R por Arthur de Sa Ferreira está licenciada sob a \" href=\"https://www.apache.org/licenses/LICENSE-2.0\">Apache License 2.0. Atualizado em 23/09/2025 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, "],["dedicatoria.html", "Dedicatória", " Dedicatória Esta obra é dedicada a todos que, em princípio, buscam conhecimento para melhorar a qualidade da pesquisa científica — seja a sua própria, a de colegas ou a de desconhecidos — mas, em última análise, desejam mesmo prover melhores condições de saúde e desenvolvimento da sociedade. Dedico também ao leitor eventual que chegou aqui por acaso. "],["agradecimentos.html", "Agradecimentos", " Agradecimentos Este trabalho não seria possível sem o apoio e suporte da minha esposa Daniele, minha irmã Mônica, meu pai José Victorino, minha mãe Angela (in memoriam) e meus filhos Giovanna, Victor e Lucas. "],["apresentacao.html", "Apresentação", " Apresentação No âmbito da análise estatística de dados, os processos envolvidos são marcados por uma série de escolhas críticas. Estas decisões abrangem considerações metodológicas e ações operacionais que moldam toda a jornada analítica. Deve-se selecionar, cuidadosamente, um delineamento de estudo para enfrentar os desafios únicos colocados por um projeto de pesquisa. Além disso, a escolha de métodos estatísticos adequados para lidar com os dados gerados pelo delineamento escolhido tem um peso importante. Estas decisões necessitam de uma base construída sobre as evidências mais convincentes da literatura existente e na adesão a práticas sólidas de investigação. Interpretar os resultados destas análises não é uma tarefa simples. Confiar apenas na formação educacional convencional, no bom senso e na intuição para decifrar tabelas e gráficos pode revelar-se inadequado. Interpretações errôneas podem gerar consequências indesejáveis, incluindo a utilização de testes diagnósticos imprecisos ou o endosso de tratamentos ineficazes. Este livro emerge do reconhecimento desses desafios. A proposta gira em torno da organização de um compêndio abrangente de métodos e técnicas de ponta, para análise estatística de dados em pesquisa científica, apresentados em formato de perguntas e respostas. Esse formato promove um diálogo direto e objetivo com o leitor, respondendo a dúvidas comumente colocadas por alunos de graduação, pós-graduação lato sensu, pós-graduação stricto sensu (mestrado e doutorado), bem como por pesquisadores. O objetivo geral de cada capítulo é elucidar as questões metodológicas fundamentais: “O que é?”, “Por que usar?”, “Quando usar?”, “Quando não usar?” e “Como fazer?”. Em cada capítulo, diversas questões específicas são propostas e respondidas sistematicamente, permitindo ao leitor uma melhor elaboração do conteúdo e resultado do seu trabalho. Todos eles com citações de fontes confiáveis referências, que podem ser consultadas para aprofundamento e verificação das informações apresentadas — um total de 484 referências foram incluídas para apoiar as informações e recomendações apresentadas. Os capítulos foram organizados para seguir uma progressão de conceitos e aplicações. Embora sejam fragmentados para maior clareza instrucional, as referências cruzadas ajudam a mitigar a fragmentação do conteúdo e reforçar a interconexão dos tópicos. O público-alvo compreende pesquisadores, professores, analistas de dados, profissionais e estudantes que regularmente lidam com a tomada de decisões em pesquisa. Os estudantes de pós-graduação encontrarão aqui uma obra repleta de exemplos para adaptar na análise dos dados de seus projetos de pesquisa. Professores de graduação e pós-graduação terão acesso a uma obra didática de referência, direcionada para seus alunos. Pesquisadores e analistas de dados iniciantes descobrirão um valioso acervo de informações e referências para a construção de projetos e manuscritos. Pesquisadores e os cientistas mais experientes podem recorrer às referências e esclarecimentos mais atuais sobre vieses, paradoxos, mitos e mal práticas em pesquisa. E mesmo os leitores não familiarizados ainda com as técnicas de análise de dados em pesquisa terão a oportunidade de apreciar o papel fundamental de colocar e responder suas perguntas na busca do conhecimento científico. Arthur de Sá Ferreira "],["author.html", "Sobre o autor", " Sobre o autor Arthur de Sá Ferreira Obtive minha Graduação em Fisioterapia pela Universidade Federal do Rio de Janeiro (1999), Formação em Acupuntura pela Academia Brasileira de Arte e Ciência Oriental (2001), Mestrado em Engenharia Biomédica pela Universidade Federal do Rio de Janeiro (2002) e Doutorado em Engenharia Biomédica pela Universidade Federal do Rio de Janeiro (2006). Tenho experiência em docência no ensino superior, atuei com professor da graduação em cursos de Fisioterapia, Enfermagem e Odontologia, entre outros (2001-2018); pós-graduação lato sensu em Fisioterapia (2001-atual) e stricto sensu níveis mestrado e doutorado (2010-atual). Como pesquisador, sou Professor Adjunto do Centro Universitário Augusto Motta (UNISUAM), atuando nos Programas de Pós-graduação em Ciências da Reabilitação (PPGCR; 2009-atual) e Desenvolvimento Local (PPGDL; 2018-atual). Também sou pesquisador do Instituto D’Or de Pesquisa e Ensino (IDOR; 2024-atual). Fundei o Laboratório de Simulação Computacional e Modelagem em Reabilitação (LSCMR) em 2012, onde desenvolvo projetos de pesquisa principalmente nos seguintes temas: Bioestatística, Modelagem e simulação computacional, Processamento de sinais biomédicos, Movimento funcional humano, Medicina tradicional (chinesa), Distúrbios musculoesqueléticos, Doenças cardiovasculares e Doenças respiratórias. Dentre os editais públicos que obtive financimento, destaco os Programas Jovem Cientista do Nosso Estado (JCNE; 2012-2015; 2015-2017) e Cientista do Nosso Estado (2021-atual) da Fundação Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro (FAPERJ; e Bolsista Produtividade em Pesquisa pelo Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq; 2021-atual). Como gestor, estou na Coordenação do Programa de Pós-Graduação stricto sensu em Ciências da Reabilitação (PPGCR; 2016-atual). Coordeno o Curso Superior de Tecnologia em Radiologia da Faculdade IDOR de Ciências Médicas (IDOR; 2024-atual). Atuei como coordenador do Comitê de Ética em Pesquisa (CEP) do Centro Universitário Augusto Motta (UNISUAM; 2020-2024) e como Coordenador do Curso de Graduação em Fisioterapia da Universidade Salgado de Oliveira (UNIVERSO; 2004-2009). Sou membro da Associação Brasileira de Pesquisa e Pós-Graduação em Fisioterapia (ABRAPG-FT) (2007-atual), Consórcio Acadêmico Brasileiro de Saúde Integrativa (CABSIN) (2019-atual), e Royal Statistical Society (RSS) (2021-atual). Fui membro do Committee on Publication Ethics (COPE) (2018-2024). Componho o corpo editorial e de revisores de periódicos nacionais e internacionais como Scientific Reports, Frontiers in Rehabilitation Sciences, The Journal of Clinical Hypertension, Chinese Journal of Integrative Medicine, Journal of Integrative Medicine, Brazilian Journal of Physical Therapy, Fisioterapia e Pesquisa. Currículos externos 5432142731317894 0000-0001-7014-2002 F-6831-2012 "],["parte-1.html", "PARTE 1: FUNDAMENTOS ESTATÍSTICOS Conceitos essenciais para pensar estatisticamente e evitar armadilhas comuns", " PARTE 1: FUNDAMENTOS ESTATÍSTICOS Conceitos essenciais para pensar estatisticamente e evitar armadilhas comuns "],["pensamento-probabilistico.html", "Capítulo 1 Pensamento probabilístico 1.1 Experimento 1.2 Espaço amostral e eventos discretos 1.3 Espaço amostral e eventos contínuos 1.4 Probabilidade 1.5 Independência e probabilidade 1.6 Leis dos números anômalos 1.7 Leis dos pequenos números 1.8 Leis dos grandes números 1.9 Teorema central do limite 1.10 Regressão para a média", " Capítulo 1 Pensamento probabilístico 1.1 Experimento 1.1.1 O que é um experimento? Um experimento é um processo de simulação ou medição cujo resultado é chamado de desfecho.1 Tentativa se refere a uma repetição de um experimento.1 1.1.2 O que é um experimento aleatório? Em um experimento aleatório, o desfecho de cada tentativa é imprevisível.1 1.2 Espaço amostral e eventos discretos 1.2.1 O que é espaço amostral discreto? O espaço amostral \\(S\\) de um experimento aleatório é definido como o conjunto de todos os desfechos possíveis de um experimento.1 Em probabilidade discreta, o espaço amostral \\(S\\) pode ser enumerado e contato.1 Figura 1.1: Exemplos de espaço amostral discreto. Superior: Todas as faces de uma moeda. Inferior: Todas as faces de um dado. 1.2.2 O que é evento discreto? Um evento \\(E\\) é um único desfecho ou uma coleção de desfechos.1 Um evento \\(E\\) é um subconjunto do espaço amostral \\(S\\) de um experimento.1 Figura 1.2: Exemplos de evento de experimento. Superior: 1 lançamento de 1 moeda. Inferior: 1 lançamento de 1 dado. 1.2.3 O que é espaço de eventos discretos? Um espaço de eventos \\(E_{s}\\) também é um subconjunto do espaço amostral \\(S\\) de um experimento.1 A união de dois eventos \\(E_{1} \\cup E_{2}\\) é o conjunto de todos os desfechos que estão em ambos.1 A intersecção de dois eventos \\(E_{1} \\cap E_{2}\\), ou evento conjunto, é o conjunto de todos os desfechos que estão em ambos os eventos.1 O complemento de um evento \\(E^C\\) consiste em todos os desfechos que não estão incluídos no evento \\(E\\).1 Figura 1.3: Espaço de eventos: União dos eventos face = 3 e face = 4 de um dado. 1.3 Espaço amostral e eventos contínuos 1.3.1 O que é espaço amostral contínuo? .REF? 1.3.2 O que é evento contínuo? .REF? 1.3.3 O que é espaço de eventos contínuo? .REF? 1.4 Probabilidade 1.4.1 O que é probabilidade? Com um espaço amostral \\(S\\) finito e não vazio de desfechos igualmente prováveis, a probabilidade \\(P\\) de um evento \\(E\\) é a razão entre o número de desfechos no evento \\(E\\) e o número de desfechos no espaço amostral \\(S\\).1 Um evento \\(E\\) impossível não contém um desfecho e, portanto, nunca ocorre: \\(P(E)=0\\).1,2 Um evento \\(E\\) é certo consiste em qualquer um dos desfechos possíveis e, portanto, sempre ocorre: \\(P(E)=1\\).1 1.4.2 Quais são os axiomas da probabilidade? A probabilidade de um evento é um número real que satisfaz os seguintes axiomas descritos por Andrei Nikolaevich Kolmogorov em 1950:1,2 Axioma I. Probabilidades de um evento \\(E\\) são números não-negativos: \\(P(E) \\geq 0\\). Axioma II. Probabilidade de todos os eventos do espaço amostral \\(A\\) ocorrerem é 100%: \\(P(S)=1\\). Axioma III. A probabilidade de um conjunto k de eventos mutuamente exclusivos é igual a soma da probabilidade de cada evento: \\(P(E_{1} \\cup E_{2} \\cup ... E_{k}) = P(E_{1}) + P(E_{2}) + ... + P(E_{k})\\). Os axiomas possuem as seguintes consequências:1 A soma da probabilidade de dois eventos que dividem o espaço amostral é 100%: \\(P(E)+P(E)^C=1\\). O valor máximo de probabilidade de um evento é 100%: \\(P(S)≤1\\). A probabilidade é uma função não decrescente do número de desfechos de um evento. 1.5 Independência e probabilidade 1.5.1 O que é independência em estatística? Em experimentos aleatórios, é comum assumir que os eventos de tentativas separadas são independentes devido a independência física de eventos e experimentos.1 Se a ocorrência do evento \\(E_{1}\\) não tiver efeito na ocorrência do evento \\(E_{2}\\), os eventos \\(E_{1}\\) e \\(E_{2}\\) são considerados estatisticamente independentes.1 Eventos são mutuamente exclusivos, ou disjuntos, se a ocorrência de um exclui a ocorrência dos outros.1 Se dois eventos \\(E_{1}\\) e \\(E_{2}\\) são mutuamente exclusivos, então os eventos \\(E_{1}\\) e \\(E_{2}\\) não podem ocorrer ao mesmo tempo e, portanto, são eventos independentes.1 Figura 1.4: Superior: Eventos independentes. Inferior: Eventos dependentes. Em experimentos independentes, o desfecho de uma tentativa é independente dos desfechos de outras tentativas, passadas e/ou futuras. Uma tentativa em um experimento aleatório é independente se a probabilidade de cada desfecho possível não mudar de tentativa para tentativa.1 Figura 1.5: Esquerda: Evento (face = 4). Direita: Experimentos de 1 lançamento de 1 dado (superior), 3 lançamentos de 1 dado (central), 10 lançamentos de 1 dado (inferior). 1.5.2 O que é probabilidade marginal? Probabilidade marginal é a probabilidade de ocorrência de um evento \\(E\\) independentemente da(s) probabilidade(s) de outro(s) evento(s).1 1.5.3 O que é probabilidade conjunta? Probabilidade conjunta é a probabilidade de ocorrência de dois ou mais eventos independentes \\(E_{1}\\), \\(E_{2}\\), …, \\(E_{k}\\), independentemente da(s) probabilidade(s) de outro(s) evento(s).1 Se a probabilidade conjunta dos eventos é nula (\\(E_{1} \\cup E_{2} = 0\\)), esses dois eventos \\(E_{1}\\) e \\(E_{2}\\) são mutuamente exclusivos ou disjuntos.1 1.5.4 O que é probabilidade condicional? Probabilidade condicional é a probabilidade de ocorrência do evento \\(E_{2}\\) quando se sabe que o evento \\(E_{1}\\) já ocorreu \\(P(E_{2} | E_{1})\\).1 A probabilidade condicional \\(P(E_{2} | E_{1})\\) representa que a ocorrência do evento \\(E_{1}\\) fornece informação sobre a ocorrência do evento \\(E_{2}\\).1 Se a ocorrência do evento \\(E_{1}\\) tiver alguma influência na ocorrência do evento \\(E_{2}\\), então a probabilidade condicional do evento \\(E_{2}\\) dado o evento \\(E_{1}\\) pode ser maior ou menor do que a probabilidade marginal.1 1.6 Leis dos números anômalos 1.6.1 O que é a lei dos números anômalos? A lei dos números anômalos - lei de Benford - é uma distribuição de probabilidade que descreve a frequência de ocorrência do primeiro dígito em muitos conjuntos de dados do mundo real.3 1.7 Leis dos pequenos números 1.7.1 O que é a lei dos pequenos números? A crença exagerada na probabilidade de replicar com sucesso os achados de um estudo, pela tendência de se considerar uma amostra como representativa da população.4 A crença na lei dos pequenos números se refere à tendência de superestimar a estabilidade das estimativas provenientes de estudos com amostras pequenas.5 Quando se percebe um padrão, pode não ser possível identificar se tal padrão é real.6 1.7.2 Quais são as versões da lei dos pequenos números? 1a Lei Forte dos Pequenos Números: “Não há pequenos números suficientes para atender às muitas demandas que lhes são feitas”.6 2a Lei Forte dos Pequenos Números: “Quando dois números parecem iguais, não são necessariamente assim”.7 1.8 Leis dos grandes números 1.8.1 O que é a lei dos grandes números? A lei dos grandes números descreve que, ao realizar o mesmo experimento \\(E\\) um grande número de vezes (\\(n\\)), a média \\(\\mu\\) dos resultados obtidos tende a se aproximar do valor esperado \\(E[\\bar{X}]\\) à medida que mais experimentos forem realizados (\\(n \\to \\infty\\)).REF? De acordo com a lei dos grandes números, a média amostral converge para a média populacional à medida que o tamanho da amostra aumenta.REF? 1.8.2 Quais são as versões da lei dos grandes números? Lei Fraca dos Grandes Números (de Poisson): ““.REF? Lei Fraca dos Grandes Números (de Bernoulli): ““.REF? Lei Forte dos Grandes Números: ““.REF? 1.9 Teorema central do limite 1.9.1 O que é teorema central do limite? O teorema central do limite (1.1) afirma que, para uma amostra aleatória de tamanho \\(n\\) de uma população com valor esperado igual à média \\(E[\\bar{X_{i}}] = \\mu\\) e variância \\(Var[\\bar{X_{i}}]\\) igual a \\(\\sigma^{2}\\), a distribuição amostral da média de uma variável \\(\\bar{X}\\) se aproxima de uma distribuição normal \\(N\\) com média \\(\\mu\\) e variância \\(\\sigma^{2}/n\\) à medida que \\(n\\) aumenta (\\(n \\to \\infty\\)):8 \\[\\begin{equation} \\tag{1.1} \\sqrt{n}(\\bar{X} - \\mu) \\xrightarrow{n \\to \\infty} N(0, \\sigma^2) \\end{equation}\\] O teorema central do limite demonstra que se o tamanho da amostra \\(n\\) for suficientemente grande, a distribuição amostral das médias obtidas utilizando reamostragem com substituição será aproximadamente normal, com média \\(\\mu\\) e variância \\(\\sigma^{2}/n\\), independentemente da distribuição da população.8 No exemplo abaixo, uma variável aleatória numérica com distribuição uniforme no espaço amostral \\(S=[18;65]\\) tem média \\(\\mu\\) = 38.53 e variância \\(\\sigma^{2}\\) = 172.433. A distribuição amostral da média de 100 amostras de tamanho 5, 50, 500 e 5000 tomadas da população com reposição e igual probabilidade se aproxima de uma distribuição normal com média \\(\\mu\\) = 38.493 e variância \\(\\sigma^{2}\\) = 0.038, independentemente da distribuição da população: Em outro exemplo, o lançamento de um dado com distribuição uniforme no espaço amostral \\(S=\\{1,2,3,4,5,6\\}\\) tem média \\(\\mu\\) = 3.77 e variância \\(\\sigma^{2}\\) = 3.169. A distribuição amostral da média de 100 amostras de tamanho 5, 50, 500 e 5000 tomadas da população com reposição e igual probabilidade se aproxima de uma distribuição normal com média \\(\\mu\\) = 3.767 e variância \\(\\sigma^{2}\\) = 0.001, independentemente da distribuição da população: Figura 1.6: Esquerda: Histogramas de lançament de 1 dado com distribuição uniforme (N = 100). Direita: Histogramas da média de 100 amostras de tamanhos 5, 50, 500 e 5000 tomadas da população com reposição e igual probabilidade. Mais um exemplo, o lançamento de uma moeda com distribuição uniforme no espaço amostral \\(S=\\{0,1\\}\\) — codificado para \\(sucesso = 1\\) e \\(insucesso = 0\\) — tem média \\(\\mu\\) = 0.48 e variância \\(\\sigma^{2}\\) = 0.252. A distribuição amostral da média de 100 amostras de tamanho 5, 50, 500 e 5000 tomadas da população com reposição e igual probabilidade se aproxima de uma distribuição normal com média \\(\\mu\\) = 0.48 e variância \\(\\sigma^{2}\\) = 0, independentemente da distribuição da população: Figura 1.7: Esquerda: Histogramas de lançament de 1 moeda com distribuição uniforme (N = 100). Direita: Histogramas da média de 100 amostras de tamanhos 5, 50, 500 e 5000 tomadas da população com reposição e igual probabilidade. 1.9.2 Quais as condições de validade do teorema central do limite? As condições de validade do teorema central do limite são:8 As variáveis aleatórias devem ser independentes e identicamente distribuídas (independent and identically distributed ou i.i.d.); As variáveis aleatórias devem ter média \\(\\mu\\) e variância \\(\\sigma^{2}\\) finitas; O tamanho da amostra deve ser suficientemente grande (geralmente, \\(n \\geq 30\\)). 1.9.3 Qual a relação entre a lei dos grandes números e o teorema central do limite? A lei dos grandes números é um precursor do teorema central do limite, pois estabelece que a média da amostra se torna cada vez mais próxima da média populacional (isto é, mais representativa) à medida que o tamanho da amostra aumenta, e o teorema central do limite demonstra que o a distribuição da soma das variáveis aleatórias se aproxima de uma distribuição normal também à medida que o tamanho da amostra aumenta.REF? 1.9.4 Qual a relevância do teorema central do limite para a análise estatística? O teorema central do limite explica porque os testes paramétricos têm maior poder estatístico do que os testes não paramétricos, os quais não requerem suposições de distribuição de probabilidade.8 O teorema central do limite implica que os métodos estatísticos que se aplicam a distibuições normais podem ser aplicados a outras distribuições quando suas suposições são satisfeitas.8 Como o teorema central do limite determina a distribuição amostral \\(Z\\) (1.2) das médias com tamanho amostral suficientemente grande, a média pode ser padronizada para uma distribuição normal com média 0 e variância 1, \\(N(0,1)\\):8 \\[\\begin{equation} \\tag{1.2} Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\end{equation}\\] Para amostras com \\(n \\geq 30\\), a distribuição amostral Student-t se aproxima da distribuição normal padrão \\(Z\\) e, portanto, as suposições sobre a distribuição populacional não são mais necessárias de acordo com o teorema central do limite. Neste cenário, a suposição de distribuição normal pode ser usada para a distribuição de probabilidade.8 1.10 Regressão para a média 1.10.1 O que é regressão para a média? Regressão para a média9 é um fenômeno estatístico que ocorre quando uma variável aleatória \\(X\\) é medida na mesma unidade de análise em dois ou mais momentos diferentes, \\(X_{1}\\), \\(X_{2}\\), …, \\(X_{t}\\) e \\(X_{t}\\) é mais próximo da média populacional do que \\(X_{1}\\), ou seja, \\(E(X_{t})\\) é mais próxima de \\(E(X)\\) do que \\(E(X_{1})\\) é de \\(E(X)\\).10 O valor real - sem erros aleatório ou sistemático - em geral não é conhecido, mas pode ser estimado pela média de várias observações.10 Regressão para a média pode ocorrer em qualquer pesquisa cujo delineamento envolva medidas repetidas.11 Em medidas repetidas, a média de várias observações é mais próxima da média verdadeira do que qualquer observação individual, pois o erro aleatório é reduzido pela média.10 Valores extremos - em direção ao mínimo ou máximo - em uma medição inicial tendem a ser seguidos por valores mais próximos da média (valor real) na medição subsequente.10 No exemplo abaixo, a 2a medida (dado 2 = 121) é mais próxima da média (valor real = 120) do que a 1a medida (dado 1 = 118): Figura 1.8: Representação gráfica da regressão para a média em medidas repetidas. A segunda medida (dado 2) é mais próxima da média (valor real) do que a primeira medida (dado 1). 1.10.2 Qual a causa da regressão para a média? A regressão para a média pode ser atribuída ao erro aleatório, que é a variação não sistemática nos valores observados em torno de uma média verdadeira (por exemplo, erro de medição aleatório ou variações aleatórias em um participante).10 Regrssão para a média é uma consequência da observação de que dados extremos não se repetem com frequência.11 Deve-se assumir que a regressão para a média ocorreu até que os dados mostrem o contrário.10 1.10.3 Por que detectar o fenômeno de regressão para a média? A regressão para a média pode levar a conclusões errôneas sobre a eficácia de uma intervenção, pois a mudança observada pode ser devida ao erro aleatório e não ao tratamento.11 1.10.4 Com detectar o fenômeno de regressão para a média? O fenômeno de regressão para a média pode ser detectado por meio de gráfico de dispersão da diferença (estudos transversais) ou mudança (estudos longitudinais) versus os valores da 1a medida.10 O pacote regtomean12 fornece as funções cordata para calcular a correlação entre medidas tipo antes–e-depois e meechua_reg para ajustar modelos lineares de regressão. 1.10.5 Como o fenômeno de regressão para a média pode ser evitado? Aloque os participantes de modo aleatório nos grupos de tratamento e controle pode reduzir o fenômeno de regressão para a média.10 Selecione participantes com base em medidas repetidas ao invés de medidas únicas.10 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["pensamento-estatistico.html", "Capítulo 2 Pensamento estatístico 2.1 Unidade de análise 2.2 População 2.3 Amostra 2.4 Amostragem 2.5 Reamostragem 2.6 Subamostragem 2.7 Superamostragem", " Capítulo 2 Pensamento estatístico 2.1 Unidade de análise 2.1.1 O que é unidade de análise? A unidade de análise (ou unidade experimental) de pesquisas na área de saúde geralmente é o indivíduo.13 A unidade de análise também pode ser a instituição em estudos multicêntricos (ex.: hospitais, clínicas) ou um estudo publicado em meta-análise (ex.: ensaios clínicos).13 2.1.2 Por que identificar a unidade de análise de um estudo? É fundamental identificar corretamente a unidade de análise para evitar inflação do tamanho da amostra (ex.: medidas bilaterais resultando em o dobro de participantes), violações de suposições dos testes de hipótese (ex.: independência entre medidas e/ou unidade de análise) e resultados espúrios em testes de hipótese (ex.: P-valores menores que aqueles observados se a amostra não estivesse inflada).13,14 2.1.3 Que medidas podem ser obtidas da unidade de análise de um estudo? Da unidade de análise podem ser coletadas informações em medidas únicas, repetidas, seriadas ou múltiplas. 2.2 População 2.2.1 O que é população? População — ou população-alvo — refere-se ao conjunto completo sobre o qual se pretende obter informações.15,16 População é metodologicamente delimitada pelos critérios de inclusão e exclusão do estudo.15 Em estudos observacionais, inicialmente as características geográficas e/ou demográficas, por exemplo, definem a população a ser estudada.15 Em estudos analíticos, a população é inicialmente definida pelos objetivos da pesquisa e, posteriormente, as observações são realizadas na amostra.15 2.2.2 O que é representatividade e por que ela importa? Representatividade refere-se ao grau em que uma amostra reflete com fidelidade as características da população de referência.16 Quando a amostra contém menos indivíduos do que o número mínimo necessário, mas mantém a representatividade, a inferência estatística ainda é possível, embora possa haver redução da precisão e/ou do poder estatístico para detectar os efeitos.16 Amostras não representativas comprometem a validade da inferência estatística, mesmo quando o tamanho da amostra atende aos requisitos de poder da análise.16 2.3 Amostra 2.3.1 O que é amostra? Amostra é uma parte finita da população do estudo.15,16 Em pesquisa científica, utilizam-se dados de uma amostra de participantes (ou outras unidades de análise) para realizar inferências sobre a população.17 2.3.2 Por que usar dados de amostras? Estudos com amostras, em vez de censos, são preferíveis por diversas razões, dentre elas: questões éticas; limitações orçamentárias; desafios logísticos; restrição de tempo; e tamanho populacional desconhecido.16 Dados de uma amostra de tamanho suficiente e características representativas podem ser utilizados para inferência sobre uma população.8 Em geral, amostras de tamanhos maiores possuem médias mais próximas da média populacional e menores variâncias.8 2.4 Amostragem 2.4.1 O que é amostragem? Amostragem é o processo pelo qual se seleciona uma parte de uma população para constituir a amostra que será efetivamente estudada.16 Figura 2.1: Representação esquemática da amostragem: seleção de uma população para a amostra. 2.4.2 Quais métodos de amostragem são usados para obter uma amostra da população? O método de amostragem é geralmente definido pelas condições de viabilidade do estudo, no que diz respeito a acesso aos participantes, ao tempo de execução e aos custos envolvidos, entre outras.15 Não-probabilísticas ou intencionais:15,16 Bola de neve. Conveniência. Participantes encaminhados. Proposital. Probabilísticas:15,16 Simples. Sistemática. Multiestágio. Estratificada. Agregada. 2.4.3 O que é erro de amostragem? Erro de amostragem é a variação natural entre os resultados obtidos a partir de uma amostra e os resultados que seriam obtidos caso toda a população fosse examinada. Reflete o grau de incerteza inerente à generalização de uma amostra para a população.16 Figura 2.2: Representação esquemática do erro de amostragem: seleção de várias amostras independentes de uma população. Figura 2.3: Representação esquemática da amostragem de uma população para a amostra. 2.5 Reamostragem 2.5.1 O que é reamostragem? Reamostragem é um procedimento que cria vários conjuntos de dados sorteados a partir de um conjunto de dados real - a amostra da população - sem a necessidade de fazer suposições sobre os dados e suas distribuições.17 O procedimento é repetido várias vezes para usar a variabilidade dos resultados para obter um intervalo de confiança do parâmetro no nível de significância \\(\\alpha\\) pré-estabelecido.17 2.5.2 Por que utilizar reamostragem? Quando se dispõe de dados de apenas 1 amostra, as diversas suposições que são feitas podem não ser atingidas.17 Procedimentos de reamostragem produzem um conjunto de observações escolhidas aleatoriamente da amostra, igualmente representativo da população original.17 Procedimentos de reamostragem permitem estimar o erro-padrão e intervalos de confiança sem a necessidade de tais suposições, sendo, portanto, um conjunto de procedimentos não-paramétricos.17 2.5.3 Quais procedimentos de reamostragem podem ser realizados? Bootstrap: Cada iteração gera uma amostra bootstrap do mesmo tamanho do conjunto de dados original escolhendo aleatoriamente observações reais, uma de cada vez. Cada observação tem chances iguais de ser escolhida a cada vez, portanto, algumas observações serão escolhidas mais de uma vez e outras nem serão escolhidas.17 Figura 2.4: Representação esquemática da reamostragem de uma amostra. 2.6 Subamostragem 2.6.1 O que é subamostragem? .REF? Figura 2.5: Representação esquemática da subamostragem de uma amostra. 2.7 Superamostragem 2.7.1 O que é superamostragem? .REF? Figura 2.6: Representação esquemática da superamostragem de uma população. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["falacias-estatisticas.html", "Capítulo 3 Falácias estatísticas 3.1 Falácias", " Capítulo 3 Falácias estatísticas 3.1 Falácias 3.1.1 O que são falácias estatísticas? Falácias estatísticas são erros de raciocínio que ocorrem em situações que envolvem dados e estatísticas. Elas podem ocorrer em qualquer etapa do processo de análise de dados, desde a coleta até a interpretação dos resultados.REF? Falácias podem ser intencionais ou não intencionais, e podem ser usadas para manipular, enganar ou confundir as pessoas.REF? As falácias estatísticas podem ser difíceis de detectar, pois muitas vezes são sutis e podem parecer plausíveis à primeira vista. No entanto, é importante estar ciente delas e saber como identificá-las para evitar erros de interpretação e tomada de decisão.REF? 3.1.2 O que é a falácia do jogador? A falácia do jogador é a crença de que eventos independentes têm uma influência sobre eventos futuros. Por exemplo, se uma moeda é lançada várias vezes e cai cara em todas as vezes, a falácia do jogador sugere que a próxima jogada será coroa, pois a moeda “deve” se equilibrar. No entanto, cada lançamento da moeda é independente e não afeta o resultado do próximo lançamento.18 3.1.3 O que é a falácia da mão quente? A falácia da mão quente é a crença de que um jogador que teve sucesso em um jogo de azar terá mais chances de sucesso no futuro. Por exemplo, se uma moeda é lançada várias vezes e cai cara em todas as vezes, a falácia da mão quente sugere que a próxima jogada será cara, pois o jogador está “quente”. No entanto, cada lançamento da moeda é independente e não afeta o resultado do próximo lançamento.18 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["paradoxos-estatisticos.html", "Capítulo 4 Paradoxos estatísticos 4.1 Paradoxos", " Capítulo 4 Paradoxos estatísticos 4.1 Paradoxos 4.1.1 O que são paradoxos estatísticos? Paradoxos podem originar da incompreensão ou mal informação da nossa intuição a respeito do fenômeno.19 4.1.2 O que é o paradoxo de Abelson? .20 4.1.3 O que é o paradoxo de Berkson? .21 4.1.4 O que é o paradoxo de Big Data? “Quanto maior a quantidade de dados, maior a certeza de que vamos nos enganar”.19 4.1.5 O que é o paradoxo de Ellsberg? .22 4.1.6 O que é o paradoxo de Freedman? .23,24 4.1.7 O que é o paradoxo de Hand? .25 4.1.8 O que é o paradoxo de Lindley? .26 4.1.9 O que é o paradoxo de Lord? .27,28 4.1.10 O que é o paradoxo de Proebsting? .REF? 4.1.11 O que é o paradoxo de Simpson? O paradoxo de Simpson ocorre quando a associação entre duas variáveis \\(X\\) e \\(Y\\) desaparece ou mesmo reverte sua direção quando condicionadas em uma terceira variável \\(Z\\).29,30 Para decisão do paradoxo de Simpson pode-se utilizar o conceito de ‘back-door’, o qual considera os ‘caminhos’ (isto é, associações) no gráfico acíclio direcionado e assegura que todos as associações espúrias do tratamento \\(X\\) para o desfecho \\(Y\\) nesse diagrama causal sejam interceptados pela variável \\(Z\\).31 Dependendo do contexto em que os dados foram obtidos — delineamento do estudo, escolha dos instrumentos e dos tipos de variáveis — a melhor escolha para a análise pode variar entre a análise da população agregada ou da subpopulação desagregada.31 É possivel que em alguns contextos nem a análise agregada ou a desagregada podem oferecer a resposta correta, sendo necessário o uso de outras (mais) covariáveis.31 Figura 4.1: Paradoxo de Simpson representado com dados simulados. Os pontos no gráfico representam observações individuais e as linhas de tendência representam as regressões lineares ajustadas para os dados desagregados da população e agregados por subpopulação. 4.1.12 O que é o paradoxo de Stein? .32 4.1.13 O que é o paradoxo de Okie? .REF? 4.1.14 O que é o paradoxo da acurácia? .REF? 4.1.15 O que é o paradoxo do falso positivo? .REF? 4.1.16 O que é o paradoxo da caixa de Bertrand? .REF? 4.1.17 O que é o paradoxo do elevador? .33 4.1.18 O que é o paradoxo da amizade? .34 4.1.19 O que é o paradoxo do menino ou menina? .33 4.1.20 O que é o paradoxo do teste surpresa? .REF? 4.1.21 O que é o paradoxo do nó da gravata? .REF? 4.1.22 O que é o paradoxo da Bela Adormecida? .REF? /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["letramento-estatistico.html", "Capítulo 5 Letramento estatístico 5.1 Elementos centrais do letramento estatístico 5.2 Hierarquia de letramento estatístico 5.3 Habilidades de letramento estatístico baseadas no pensamento crítico", " Capítulo 5 Letramento estatístico 5.0.1 O que é letramento estatístico? Letramento em informação: Capacidade de reconhecer quando a informação é necessária e de localizá-la, avaliá-la criticamente (qualidade, validade, relevância, completude, imparcialidade) e usá-la de forma eficaz e ética. Abrange qualquer tipo de informação, em texto ou números.35 Letramento em dados: Competência técnica para acessar, manipular, resumir e apresentar dados, utilizando ferramentas e métodos (SQL, planilhas, softwares estatísticos), com foco na preparação e organização de conjuntos de dados para análise e comunicação.35 Letramento estatístico é a competência para compreender, interpretar e avaliar informações baseadas em dados, integrando conhecimentos técnicos (linguagem, estatística, matemática) e contextuais com postura crítica, crenças e atitudes que sustentem o uso ético e fundamentado da estatística.36–38 Letramento estatístico é parte essencial do letramento informacional (fornece a capacidade de reconhecer, acessar e avaliar informações) e do letramento em dados (envolve acessar, manipular e apresentar dados de forma adequada).35 5.0.2 Por que o letramento estatístico é importante? A presença dos dados no cotidiano deixou de ser restrita a decisões políticas ou relatórios técnicos: hoje, todos estamos expostos e interagimos com dados de forma constante, seja por dispositivos móveis, redes sociais ou sistemas automatizados de recomendação.39 Ferramentas para coletar e analisar dados estão mais acessíveis e baratas, o que amplia a possibilidade de qualquer pessoa atuar não só como consumidora, mas também como produtora de informações.39 5.0.3 Quais são exemplos de “armadilhas” comuns na interpretação de estatísticas? Escolha do indicador: usar média ou mediana pode levar a conclusões muito diferentes sobre o mesmo fenômeno (por exemplo, renda média vs. mediana antes e depois de impostos).35 Confusão entre taxas e contagens: comparar números absolutos sem considerar proporções populacionais pode distorcer a realidade.35 Fatores de confusão: diferenças observadas podem ser explicadas por variáveis não consideradas, como idade média da população ao comparar taxas de mortalidade.35 5.1 Elementos centrais do letramento estatístico 5.1.1 Quais são os elementos de conhecimento que sustentam o letramento estatístico? O modelo de letramento estatístico é composto por cinco elementos de conhecimento e dois elementos disposicionais.36–38 5.1.2 Quais são os cinco elementos de conhecimento que sustentam o letramento estatístico? Competências de letramento, incluindo leitura de textos, gráficos e tabelas.36 Conhecimento estatístico básico, incluindo conceitos, métodos, interpretação de dados e probabilidade.36 Conhecimento matemático sobre percentagens, médias e raciocínio numérico.36 Conhecimento de contexto/mundo, com entendimento do cenário e origem dos dados.36 Questões críticas (lista de worry questions para avaliar a validade da informação.36 5.1.3 Quais são os dois elementos de disposição que facilitam a ação estatisticamente letrada? Postura crítica: propensão para questionar e analisar mensagens quantitativas.36 Crenças e atitudes: visão positiva sobre a capacidade de pensar estatisticamente; valorização de dados bem produzidos.36 5.1.4 Que tipo de perguntas críticas (worry questions) devemos fazer ao interpretar informação estatística? De onde vêm os dados? Que tipo de estudo foi feito?36 A amostra é representativa e suficientemente grande?36 Os instrumentos de medição são confiáveis?36 As estatísticas e gráficos são apropriados e não distorcem?36 Há relação causal ou apenas correlação? Há informação em falta?36 Existem interpretações alternativas plausíveis?36 5.2 Hierarquia de letramento estatístico 5.2.1 Quais são os níveis da hierarquia de letramento estatístico? Nível 6 – Crítico Matemático: É o nível mais alto. A pessoa questiona e analisa as informações de forma profunda, usando cálculos e raciocínio proporcional (como comparar porcentagens e proporções). Reconhece que previsões sempre envolvem algum grau de incerteza e percebe detalhes sutis na forma como os dados são apresentados.40 Nível 5 – Crítico: Também envolve uma postura questionadora, mas sem exigir cálculos complexos de proporção. Usa corretamente a linguagem estatística, entende o significado de termos ligados à probabilidade e percebe que os resultados podem variar.40 Nível 4 – Consistente, mas Não Crítico: Consegue interpretar dados e usar termos estatísticos corretamente, mas não chega a questionar a forma como as informações são apresentadas. Reconhece a variação apenas em situações que envolvem sorte ou acaso, e sabe lidar com conceitos como média, probabilidades simples e leitura de gráficos.40 Nível 3 – Inconsistente: Analisa partes do problema, mas de forma irregular. Pode identificar conclusões corretas, mas sem explicá-las. Usa ideias estatísticas de maneira mais descritiva do que numérica.40 Nível 2 – Informal: A interpretação é mais baseada no senso comum do que em conceitos estatísticos. Utiliza apenas alguns termos corretos e consegue fazer cálculos muito simples com tabelas, gráficos ou situações de probabilidade.40 Nível 1 – Idiossincrático: Responde de forma muito pessoal ou confusa, usando termos de maneira incorreta ou limitada. Realiza apenas contagens diretas e leituras simples de dados.40 5.2.2 Quais são os componentes centrais do letramento estatístico com literacia de dados? Compreender quem coleta dados, por que e como essa coleta é feita.39 Saber interpretar dados de amostras aleatórias e não aleatórias, avaliando limitações e potencial.39 Conhecer e aplicar práticas de proteção de dados e direitos de propriedade sobre informações coletadas.39 Produzir representações descritivas (tabelas, gráficos, mapas, dashboards) para responder perguntas sobre fenômenos reais.39 Reconhecer a importância da proveniência e do armazenamento dos dados, bem como a necessidade de pré-processamento antes da análise.39 Entender fundamentos de modelagem preditiva e algoritmos, como árvores de classificação e regressão, especialmente no contexto de dados massivos (big data).39 5.3 Habilidades de letramento estatístico baseadas no pensamento crítico 5.3.1 Quais são as habilidades de letramento estatístico? Identificar: Descobrir qual é a principal afirmação de um texto ou relatório e separar o que é opinião do que é realmente evidência ou dado.41 Questionar: Fazer perguntas sobre os dados: de onde vieram, como foram coletados, qual o tamanho da amostra, se houve erros, se os gráficos estão claros e se o questionário foi bem feito.41 Julgar: Avaliar se a afirmação é bem sustentada pelos dados ou se está exagerando, por exemplo, dizendo que algo causa quando só foi encontrada uma relação.41 Esclarecer: Entender e explicar palavras técnicas e expressões que podem confundir, além de saber como foi feita a pesquisa e a análise.41 Avaliar: Decidir se a afirmação é confiável comparando com outras informações disponíveis e verificando se faz sentido.41 Investigar mais: Procurar informações que não foram mostradas, como quem fez a pesquisa, por que foi feita, detalhes do processo ou fatores escondidos que podem influenciar os resultados.41 Considerar alternativas: Pensar em outras explicações possíveis ou diferentes interpretações para os mesmos dados.41 Concluir: Chegar à sua própria conclusão sobre o assunto, usando as informações e o raciocínio de forma clara e bem fundamentada.41 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["parte-2.html", "PARTE 2: FUNDAMENTOS METODOLÓGICOS Como a metodologia sólida sustenta análises estatísticas confiáveis", " PARTE 2: FUNDAMENTOS METODOLÓGICOS Como a metodologia sólida sustenta análises estatísticas confiáveis "],["pensamento-metodologico.html", "Capítulo 6 Pensamento metodológico 6.1 Metodologia da pesquisa 6.2 Relação Estatística-Metodologia 6.3 Pesquisa quantitativa vs. qualitativa 6.4 Pesquisa de métodos mistos 6.5 Pesquisa exploratória vs. confirmatória 6.6 Pesquisa exploratória vs. confirmatória 6.7 Pré-registro 6.8 Reprodutibilidade 6.9 Robustez 6.10 Replicabilidade 6.11 Generalização", " Capítulo 6 Pensamento metodológico 6.1 Metodologia da pesquisa 6.1.1 O que é metodologia da pesquisa? A utilização de um vocabulário próprio — incluindo termos frequentemente usados em metodologia, epidemiologia e estatística — facilita a discussão na comunidade científica e melhora a compreensão das publicações.42,43 6.2 Relação Estatística-Metodologia 6.2.1 Qual a relação entre estatística e metodologia da pesquisa? .44 Figura 6.1: Mapa mental da relação entre o pensamento estatístico e o pensamento metodológico. 6.3 Pesquisa quantitativa vs. qualitativa 6.3.1 O que significa a distinção entre pesquisa qualitativa e quantitativa? A divisão entre quantitativo e qualitativo é amplamente usada, mas é considerada por muitos autores como superficial ou imprecisa. Em geral, associa-se o qualitativo à exploração detalhada de casos e significados, e o quantitativo ao uso de estatística e amostras maiores.45 Tais associações ocultam múltiplas dimensões — por exemplo, análise estatística vs. não estatística e teste de hipóteses vs. indução — que não coincidem perfeitamente.45 6.3.2 Por que essa dicotomia pode ser problemática? Ao assumir apenas duas categorias, deixamos de lado possibilidades metodológicas úteis, como indução estatística (uso de estatística para construir teorias a partir dos dados) e teste de hipóteses não estatístico (avaliação de hipóteses em estudos de caso ou comparações conceituais).45 A consequência é restringir artificialmente a variedade de métodos possíveis e criar mal-entendidos sobre o que cada termo implica.45 6.3.3 Qual é uma alternativa para pensar o debate? Usar termos mais específicos como “dados ricos” (rich data), “abordagem estatística”, “ilustração de possibilidades”, “teste de hipóteses”, “seguimento de paradigma”.45 Descrever com clareza como os dados foram coletados, analisados e interpretados, sem recorrer a rótulos amplos que podem confundir ou carregar preconceitos metodológicos.45 6.4 Pesquisa de métodos mistos 6.4.1 O que é pesquisa de métodos mistos? Método misto é uma metodologia que integra de forma sistemática abordagens quantitativas e qualitativas em um único estudo, com o objetivo de responder a perguntas de pesquisa de maneira mais completa.46 Essa integração não é apenas a justaposição de duas técnicas; trata-se de um processo intencional de “mistura” de dados e interpretações em etapas como coleta, análise e interpretação, criando uma compreensão mais robusta.46 6.4.2 Quais são as principais dimensões do desenho de métodos mistos? O desenho de pesquisa em métodos mistos deve considerar dimensões como propósito do estudo, orientação teórica, tempo (simultâneo ou sequencial), pontos de integração entre componentes, complexidade e se o desenho é planejado ou emergente.47 Entre as razões clássicas para combinar métodos estão: triangulação, complementaridade, desenvolvimento (um método orienta o outro), iniciação (explorar contradições) e expansão (ampliar o alcance da pesquisa).47 6.4.3 Quais são os delineamentos centrais em pesquisa de métodos mistos? Três delineamentos principais são descritos como centrais: convergente, sequencial explanatório e sequencial exploratório.46 Convergente: coleta e análise de dados quantitativos e qualitativos em paralelo, com integração na interpretação.46 Sequencial explanatório: inicia com dados quantitativos, seguidos por qualitativos para explicar ou expandir os achados.46 Sequencial exploratório: inicia com dados qualitativos, seguidos por quantitativos que testam ou generalizam os resultados iniciais.46 Tipologias adicionais incluem delineamentos incorporados (embedded), transformativos (inspirados em perspectivas críticas, feministas ou de justiça social) e multifásicos, que combinam várias fases ao longo do tempo.47 6.5 Pesquisa exploratória vs. confirmatória 6.6 Pesquisa exploratória vs. confirmatória 6.6.1 O que são pesquisas exploratórias e confirmatórias? Confirmatória: teste planejado a priori de hipóteses com plano analítico predefinido (variáveis, modelos, critérios de exclusão, correções para múltiplos testes). Favorece controle de erro tipo I e interpretações diretas.48 Exploratória: testes pós-hoc motivados pelos dados, voltados a descoberta de padrões, geração/refinamento de hipóteses e checagens de plausibilidade. Pode revelar relações não antecipadas e orientar estudos futuros.48 6.6.2 Por que a dicotomia é limitada Em prática, há um continuum entre exploração e confirmação; muitos estudos combinam elementos de ambos em momentos distintos (p.ex., análises principais confirmatórias + análises de sensibilidade/descoberta).48 Análises exploratórias não são inerentemente inferiores: quando bem justificadas e comparando explicações alternativas, podem aumentar a rigorosidade do teste e produzir inferências informativas.48 6.6.3 Boas práticas de transparência Rotular claramente quais análises são confirmatórias e quais são exploratórias.48 Pré-registrar hipóteses e plano confirmatório; documentar desvios e justificá-los.48 Relatar análises de sensibilidade (modelos alternativos, decisões analíticas razoáveis) para avaliar robustez.48 Disponibilizar dados e código sempre que eticamente possível, distinguindo scripts confirmatórios de scripts exploratórios.48 6.7 Pré-registro 6.7.1 O que é pré-registro? .REF? 6.8 Reprodutibilidade 6.8.1 O que é reprodutibilidade? Reprodutibilidade é a habilidade de se obter resultados iguais ou similares quando uma análise ou teste estatístico é repetido.49–51 6.8.2 Por que reprodutibilidade é importante? Analisar a reprodutibilidade pode fornecer evidências a respeito da objetividade e confiabilidade dos achados, em detrimento de terem sido obtidos devido a vieses ou ao acaso.49 A reprodutibilidade não é apenas uma questão metodológica, mas também ética, uma vez que pode envolver mal práticas científicas como fabricação e/ou falsificação de dados.49 Reprodutibilidade pode ser considerada um padrão mínimo em pesquisa científica.50 6.8.3 Como contribuir para a reprodutibilidade? Disponibilize publicamente os bancos de dados, respeitando as considerações éticas vigentes (ex.: autorização dos participantes e do Comitê de Ética em Pesquisa) e internacionalmente.51 Produza manuscritos reprodutíveis - manuscritos executáveis ou relatórios dinâmicos - que permitem a integração do banco de dados da(s) amostra(s), do(s) script(s) de análise estatística (incluindo comentários para sua interpretação), dos pacotes ou bibliotecas utilizados, das fontes e referências bibliográficas citadas, além dos demais elementos textuais (tabelas, gráficos) - todos gerados dinamicamente.52 6.9 Robustez 6.9.1 O que é robustez? .REF? 6.10 Replicabilidade 6.10.1 O que é replicabilidade? Replicabilidade é a habilidade de se obter conclusões iguais ou similares quando um experimento é repetido.50,51 6.11 Generalização 6.11.1 O que é generalização? Generalização refere-se à extrapolação das conclusões do estudo, observados na amostra, para a população.15 Figura 6.2: Representação esquemática da generalização de uma amostra para a população. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["vieses-metodologicos.html", "Capítulo 7 Vieses metodológicos 7.1 Vieses metodológicos 7.2 Tipos de vieses metodológicos 7.3 Efeitos relacionados aos vieses metodológicos 7.4 Diretrizes para redação", " Capítulo 7 Vieses metodológicos 7.1 Vieses metodológicos 7.1.1 O que são vieses metodológicos? .REF? 7.2 Tipos de vieses metodológicos 7.2.1 Quais são os tipos de vieses metodológicos? .REF? 7.3 Efeitos relacionados aos vieses metodológicos 7.3.1 Quais são os efeitos relacionados aos vieses metodológicos? .REF? 7.3.2 O que é efeito placebo? .REF? 7.3.3 O que é efeito nocebo? .REF? 7.3.4 O que é efeito Hawthorne? .REF? 7.3.5 O que é efeito Rosenthal? .REF? 7.4 Diretrizes para redação 7.4.1 Quais são as diretrizes para redação de análises de vieses metodológicos? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. PROBAST: A Tool to Assess the Risk of Bias and Applicability of Prediction Model Studies.53 RoB 2: A Revised Tool for Assessing Risk of Bias in Randomized Trials.54 AMSTAR 2: A Critical Appraisal Tool for Systematic Reviews that Include Randomised or Non-Randomised Studies of Healthcare Interventions55 ROBINS-I: A Tool for Assessing Risk of Bias in Non-randomized Studies of Interventions.56 ROBIS: A New Tool to Assess Risk of Bias in Systematic Reviews57 QUADAS-2: A Revised Tool for the Quality Assessment of Diagnostic Accuracy Studies58 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["praticas-questionaveis.html", "Capítulo 8 Práticas questionáveis em pesquisa 8.1 Práticas Questionáveis em Pesquisa 8.2 Prática não intencional e má conduta 8.3 Prevenindo práticas questionáveis em pesquisa 8.4 Reações éticas e institucionais práticas questionáveis em pesquisa", " Capítulo 8 Práticas questionáveis em pesquisa 8.1 Práticas Questionáveis em Pesquisa 8.1.1 O que são práticas questionáveis em pesquisa? Práticas questionáveis em pesquisa são más condutas ou comportamentos impróprios, realizados desde o planejamento até a publicação dos resultados.59,60 8.1.2 Por que práticas questionáveis em pesquisa devem ser combatidas? Práticas questionáveis em pesquisa são prevalentes.61 Práticas questionáveis em pesquisa comprometem a integridade científica, a confiabilidade dos resultados e a confiança do público na ciência.59,60 Práticas questionáveis em pesquisa inflam articialmente o tamanho do efeito e poder estatístico.60 Práticas questionáveis em pesquisa parecem contribuir para a crise da replicação na ciência, onde muitos estudos não conseguem ser replicados ou reproduzidos.60 8.2 Prática não intencional e má conduta Práticas questionáveis podem ser classificadas em más condutas e não intencionais.62 Más condutas são aquelas que são deliberadamente realizadas com o objetivo de enganar ou manipular os resultados, enquanto práticas não intencionais são aquelas que ocorrem devido a falta de conhecimento, treinamento inadequado ou outras razões.REF? Práticas na zona cinzenta são aquelas que podem ser interpretadas de diferentes maneiras, dependendo do contexto e da intenção do pesquisador.REF? Tabela 8.1: Classificação das práticas questionáveis em pesquisa segundo sua intencionalidade. Prática Intencionalidade Definição Data fabrication Má conduta Inventar dados inexistentes Data falsification Má conduta Alterar ou manipular dados reais Fake authorship Má conduta Inserir autores fictícios ou inexistentes Fake peer review Má conduta Criar revisões falsas para facilitar publicação Honorary authorship Má conduta Incluir autores sem contribuição real Gold authorship Má conduta Atribuir autoria como forma de prestígio ou recompensa Ghost authorship Má conduta Omitir autores que participaram do estudo Duplicate publication Má conduta Publicar o mesmo estudo em mais de uma revista Spin (doloso) Má conduta Apresentar os resultados de forma a exagerar efeitos positivos Data distortion Má conduta Modificar dados ou gráficos para torná-los mais convincentes SPARKing Má conduta Ajustar o tamanho da amostra após a coleta dos dados para obter significância estatística HARKing Zona cinzenta Criar hipóteses após ver os dados (sem pré-registro) Storytelling Zona cinzenta Construir uma narrativa forçada para justificar os achados Selective reporting Zona cinzenta Relatar apenas os resultados favoráveis ou positivos P-hacking Zona cinzenta Testar múltiplas análises até encontrar p Data peeking Zona cinzenta Analisar dados antes do término da coleta, parando quando um efeito aparece Cherry picking Zona cinzenta Selecionar apenas os resultados que apoiam a hipótese Salami slicing Zona cinzenta Dividir artificialmente um estudo em vários artigos para inflar publicações Beautification Zona cinzenta Embelezar tabelas, gráficos ou resultados para torná-los mais atraentes P-hacking reverso Não intencional Forçar análises para que não haja significância estatística Fishing expedition Não intencional Procurar achados sem plano prévio Data dredging Não intencional Explorar excessivamente os dados para encontrar associações irrelevantes File drawer problem Não intencional Não publicar estudos com resultados negativos ou nulos Publication bias Não intencional Tendência geral das revistas em favorecer publicações com resultados positivos 8.2.1 Quais práticas questionáveis podem ocorrer durante o planejamento do estudo? Hypothesizing After Results are Known (HARKing) consiste em formular hipóteses após a análise dos dados, o que pode levar a resultados enviesados e não replicáveis.63 Storytelling é a prática de criar narrativas convincentes para justificar os resultados, mesmo que não sejam suportados pelos dados.REF? 8.2.2 Quais práticas questionáveis podem ocorrer durante a coleta de dados? Data falsification é a prática de manipular ou inventar dados para obter resultados desejados.REF? Data fabrication é a prática de inventar dados ou resultados que nunca foram coletados.REF? 8.2.3 Quais práticas questionáveis podem ocorrer durante a análise dos dados? P-hacking é a prática de manipular os dados ou análises para obter resultados estatisticamente significativos, como realizar múltiplos testes sem correção adequada.64–66 P-hacking reverso é a prática de manipular os dados ou análises para obter resultados não estatisticamente significativos, como realizar múltiplos testes sem correção adequada, o que pode levar a conclusões enviesadas e enganosas.67 SPARKing (Sample size Planning After the Results are Known) é uma mal prática que envolve o ajuste do tamanho da amostra após a coleta dos dados, com o objetivo de obter resultados estatisticamente significativos.68 Data peeking é a prática de analisar os dados repetidamente antes de completar a coleta, visando interromper a coleta quando um resultado desejado é alcançado.69 Fishing expedition refere-se à exploração dos dados sem uma hipótese pré-definida, o que pode levar a conclusões enganosas e enviesadas, uma vez que os resultados podem ser meramente acidentais.@ 65 Data dredging refere-se à exploração excessiva dos dados para encontrar padrões ou relações que não são teoricamente fundamentados, o que pode resultar em conclusões enganosas e enviesadas.65 Selective reporting é a prática de relatar apenas os resultados que suportam uma hipótese específica, ignorando aqueles que não a apoiam, o que pode levar a conclusões enganosas e enviesadas.70 8.2.4 Quais práticas questionáveis podem ocorrer durante a apresentação dos resultados? Cherry picking consiste em selecionar apenas os resultados que suportam uma hipótese específica, ignorando aqueles que não a apoiam, o que pode levar a conclusões enganosas e enviesadas.65 Spin é a prática de apresentar os resultados de forma a enfatizar aspectos positivos ou minimizar aspectos negativos, o que pode levar a interpretações enganosas e enviesadas dos dados.71,72 Beautification é a prática de embelezar visualmente gráficos ou tabelas para aumentar impacto visual.REF? Data distortion é a prática de modificar ou omitir informações nos dados para induzir interpretações específicas.REF? 8.2.5 Quais práticas questionáveis podem ocorrer durante a publicação e revisão por pares? Honorary authorship refere-se à inclusão de autores que não contribuíram significativamente para o estudo, o que pode distorcer a atribuição de crédito e responsabilidade.73 Ghost authorship é a prática de não reconhecer autores que contribuíram significativamente para o estudo, o que pode distorcer a atribuição de crédito e responsabilidade.73 Gold authorship é a prática de atribuir autoria em troca de prestígio, recursos ou favorecimento político, independentemente da contribuição acadêmica.73 Fake authorship refere-se à inclusão de autores fictícios ou inexistentes em uma publicação.73 Fake peer review refere-se à prática de criar revisões por pares falsas ou fraudulentas para apoiar a publicação de um estudo, o que compromete a integridade do processo de revisão por pares e pode levar a conclusões enganosas.REF? File drawer problem refere-se à tendência de não publicar estudos com resultados negativos ou não significativos, o que pode levar a uma visão distorcida da literatura científica e dificultar a replicação de estudos.REF? Salami slicing é a prática de dividir os resultados em múltiplas publicações para aumentar o número de publicações, o que pode levar a uma má interpretação dos dados e à fragmentação do conhecimento.REF? Publication bias é a tendência de publicar apenas resultados positivos ou significativos, o que pode levar a uma visão distorcida da literatura científica e dificultar a replicação de estudos.74 Duplicate publication é a prática de publicar o mesmo estudo ou resultados em mais de uma revista, o que pode levar a uma superestimação da importância dos resultados e à confusão na literatura científica.REF? 8.3 Prevenindo práticas questionáveis em pesquisa 8.3.1 Como prevenir práticas questionáveis? Educação formal em integridade científica e estatística.REF? Pré-registro do protocolo do estudo de ensaios clínicos (ex.: ReBEC, ClinicalTrials.gov, revisões sistemáticas (ex.: PROSPERO), ou outras plataformas (ex.: OSF).75,76 Planos de análise detalhados.REF? Compartilhamento de dados/scripts (reprodutibilidade).REF? Dryad Digital Repository figshare Harvard Dataverse Mendeley Data Open Science Framework Zenodo Manuscritos reprodutíveis (RMarkdown, bookdown, etc.).REF? Adoção de diretrizes para redação de manuscritos (CONSORT, STROBE, PRISMA).REF? 8.4 Reações éticas e institucionais práticas questionáveis em pesquisa Post-publication peer review é a prática de revisar e criticar publicações após sua publicação, o que pode levar a uma melhor compreensão dos resultados e à correção de erros, mas também pode ser usada para desacreditar estudos sem justificativa adequada.REF? Corrigendum é uma correção publicada para corrigir erros ou imprecisões em um artigo já publicado, o que pode levar a uma melhor compreensão dos resultados e à correção de erros, mas também pode ser usada para desacreditar estudos sem justificativa adequada.REF? Expression of concern é uma declaração emitida por uma revista científica para alertar os leitores sobre preocupações com a integridade de um estudo, sem necessariamente retirar o artigo.REF? Retraction é a prática de retirar uma publicação devido a erros, fraudes ou práticas questionáveis, o que pode levar a uma melhor compreensão dos resultados e à correção de erros, mas também pode ser usada para desacreditar estudos sem justificativa adequada.REF? Retraction Watch é um blog que monitora e relata casos de retratações e preocupações éticas em publicações científicas, fornecendo informações sobre práticas questionáveis e promovendo a transparência na pesquisa.REF? O pacote retractcheck77 fornece a função retractcheck para verificar se um artigo foi retratado usando a Open Retractions. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["parte-3.html", "PARTE 3: FUNDAMENTOS COMPUTACIONAIS Usando probabilidade, simulação e código para explorar e modelar incertezas", " PARTE 3: FUNDAMENTOS COMPUTACIONAIS Usando probabilidade, simulação e código para explorar e modelar incertezas "],["pensamento-computacional.html", "Capítulo 9 Pensamento computacional 9.1 R 9.2 RStudio 9.3 Scripts 9.4 Pacotes 9.5 Aplicativos 9.6 Manuscritos reproduzíveis 9.7 Compartilhamento", " Capítulo 9 Pensamento computacional 9.1 R 9.1.1 O que é R? R é um programa de computador de código aberto com linguagem computacional direcionada para análise estatística.78,79 R version 4.5.1 (2025-06-13) está disponível gratuitamente em Comprehensive R Archive Network (CRAN).80 9.1.2 Por que usar R? R é o software de maior abrangência de métodos estatísticos, possui sintaxe que permite análises estatísticas reproduzíveis e está disponível gratuitamente no Comprehensive R Archive Network (CRAN).51,80 9.1.3 O que é R Markdown? R Markdown81 é uma ferramenta que permite a integração de texto, código e saída em um único documento.REF? O R Markdown é uma extensão do Markdown, que é uma linguagem de marcação simples e fácil de aprender, que é usada para formatar texto.REF? O R Markdown permite a inclusão de blocos de código R, Python, SQL, C++, entre outros, e a saída desses blocos de código é incorporada ao documento final.REF? O R Markdown é uma ferramenta poderosa para a criação de relatórios dinâmicos, que podem ser facilmente atualizados com novos dados ou análises.REF? O R Markdown é amplamente utilizado na comunidade científica para a criação de relatórios de pesquisa, artigos científicos, apresentações, livros, entre outros.REF? O trabalho com RMarkdown81 permite um fluxo de dados totalmente transparente, desde o conjunto de dados coletados até o manuscrito finalizado. Todos os aspectos do fluxo de dados podem ser incorporados em blocos de R script (chunk), exibindo tanto o R script quando o respectivo texto, tabelas e figuras formatadas no estilo científico de interesse.82 O RMarkdown81 foi projetado especificamente para relatórios dinâmicos onde a análise é realizada em R e oferece uma flexibilidade incrível por meio de uma linguagem de marcação.51 9.1.4 Que programas de computador podem ser usados para análise estatística com R? JASP.83 jamovi.84 Os pacotes jmv85 e jmvconnect86 fornecem funções para análise descritiva e inferencial com interface com jamovi. 9.2 RStudio 9.2.1 O que é RStudio? RStudio é um ambiente de desenvolvimento integrado (integrated development environment, IDE) desenvolvido visando a reprodutibilidade e a simplicidade para a criação e disseminação de conhecimento.79,87 O ambiente do RStudio é dividido em paineis: Source/Script editor: para edição de R scripts.79 Console: para execução de códigos simples.79 Environments: para visualização de objetos criados durante a sessão de trabalho.79 Output: para visualização de gráficos criados durante a sessão de trabalho.79 Figura 9.1: Interface do RStudio. Fonte: https://docs.posit.co/ide/user/ As principais características do RStudio incluem um ambiente de edição com abas para acesso rápido a arquivos, comandos e resultados; histórico de comandos previamente utilizados; ferramentas para visualização de bancos de dados e elaboração de scripts e gráficos e tabelas.79,87 RStudio está disponível gratuitamente em Posit. O pacote learnr88 fornece tutoriais interativos para RStudio. 9.3 Scripts 9.3.1 O que são R scripts? “Scripts são dados”.52 Scripts permitem ao usuário se concentrar nas tarefas mais importantes da computação e utilizar pacotes ou bibliotecas para executar as funções mais básicas com maior eficiência.52 Um script é um arquivo de texto contendo (quase) os mesmos comandos que você digitaria na linha de comando do R. O “quase” refere-se ao fato de que se você estiver usando sink() para enviar a saída para um arquivo, você terá que incluir alguns comandos em print() para obter a mesma saída da linha de comando.REF? Code # Exemplo de R script # Este é um comentário # Esta é uma variável variavel &lt;- 3.14 # Atribui o valor 3.14 à variável # Esta é uma função f &lt;- function(x) { return(x^2) # Retorna o quadrado do valor de x } # Esta é uma chamada de função resultado &lt;- f(variavel) # Chama a função f com a variável como argumento # Exibe o resultado da função print(resultado) # Exibe o resultado na saída padrão # Este é um vetor vetor &lt;- c(1, 2, 3, 4, 5) # Cria um vetor com os valores de 1 a 5 # Exibe o vetor print(vetor) # Exibe o vetor na saída padrão # Esta é uma matrix matriz &lt;- matrix(1:9, nrow=3, ncol=3) # Cria uma matriz 3x3 com os valores de 1 a 9 # Exibe a matriz print(matriz) # Exibe a matriz na saída padrão # Esta é uma lista lista &lt;- list(nome=&quot;João&quot;, idade=30, altura=1.75) # Cria uma lista com nome, idade e altura # Exibe a lista print(lista) # Exibe a lista na saída padrão # Este é um dataframe dataframe &lt;- data.frame(nome=c(&quot;João&quot;, &quot;Maria&quot;, &quot;José&quot;), idade=c(30, 25, 40), altura=c(1.75, 1.60, 1.80)) # Cria um dataframe com nome, idade e altura # Exibe o dataframe print(dataframe) # Exibe o dataframe na saída padrão # Este é um loop for for (i in 1:5) { print(i) # Exibe os valores de 1 a 5 na saída padrão } # Este é um loop while j &lt;- 1 while (j &lt;= 5) { print(j) # Exibe os valores de 1 a 5 na saída padrão j &lt;- j + 1 # Incrementa o valor de j em 1 } # Este é um condicional if-else k &lt;- 3 if (k &gt; 0) { print(&quot;k é positivo&quot;) # Exibe &quot;k é positivo&quot; se k for maior que 0 } else if (k &lt; 0) { print(&quot;k é negativo&quot;) # Exibe &quot;k é negativo&quot; se k for menor que 0 } else { print(&quot;k é zero&quot;) # Exibe &quot;k é zero&quot; se k for igual a 0 } # Fim do exemplo de R script 9.3.2 Quais são as boas práticas na redação de scripts? Use nomes consistentes para as variáveis.89 Defina os tipos de variáveis adequadamente no banco de dados.89 Defina constantes - isto é, variáveis de valor fixo - ao invés de digitar valores.89 Use e cite os pacotes disponíveis para suas análises.89 Controle as versões do script.89,90 Teste o script antes de sua utilização.89 Conduza revisão por pares do código durante a redação (digitação em dupla).89 O pacote formatR91 fornece a função tidy_source para formatar um R script. O pacote styler92 fornece a função style_file para formatar um R script. O pacote lintr93 fornece a função lint para verificar a adesão de um script a um determinado estilo, identificando erros de sintaxe e possíveis problemas semânticos. 9.4 Pacotes 9.4.1 O que são pacotes? Pacotes são conjuntos de scripts programados pela comunidade e compartilhados para uso público.79 Os pacotes ficam armazenados no Comprehensive R Archive Network (CRAN) e podem ser instalados diretamente no RStudio.79,80 Na mais recente atualização deste livro, o [Comprehensive R Archive Network (CRAN) possui 386733 pacotes disponíveis.79,80 Os pacotes disponíveis podem ser encontrados em R PACKAGES DOCUMENTATION.94 O pacote utils95 fornece a função install.packages para instalar os pacotes no computador. O pacote utils95 fornece a função library para carregar os pacotes instalados no computador. O pacote utils95 fornece a função require para indicar se o pacote requisitado está disponível. O pacote utils95 fornece a função installed.packages para listar os pacotes instalados no computador. O pacote utils95 fornece a função update.packages para atualizar os pacotes instalados no computador. O pacote roxygen296 fornece a função roxygenize para criar arquivos .Rd para documentar pacotes. 9.5 Aplicativos 9.5.1 O que são Shiny Apps? Shiny Apps são aplicativos web interativos que permitem a criação de interfaces gráficas para visualização e análise de dados em tempo real, utilizando o R como backend.REF? 9.6 Manuscritos reproduzíveis 9.6.1 O que são manuscritos reproduzíveis? Manuscritos reproduzíveis - manuscritos executáveis ou relatórios dinâmicos - permitem a produção de um manuscrito completo a partir da integração do banco de dados da(s) amostra(s), do(s) script(s) de análise estatística (incluindo comentários para sua interpretação), dos pacotes ou bibliotecas utilizados, das fontes e referências bibliográficas citadas, além dos demais elementos textuais (tabelas, gráficos) - todos gerados dinamicamente.52 9.6.2 Por que usar manuscritos reproduzíveis? No processo tradicional de redação científica há muitas etapas de copiar e colar não reproduzíveis envolvidas. Documentos dinâmicos combinam uma ferramenta de processamento de texto com o R script que produz o texto/tabela/figura a ser incorporado no manuscrito.51 Ao trabalhar com relatórios dinâmicos, é possível extrair o mesmo script usado para análise estatística. Os documentos podem ser compilados em vários formatos de saída e salvos como DOCX, PPTX e PDF.51 Muitos erros de análise poderiam ser evitados com a adoção de boas práticas de programação em manuscritos reproduzíveis.97 O pacote rmarkdown81 fornece as funções render para criar manuscritos reprodutíveis a partir de arquivos .Rmd. O pacote officedown98 fornece as funções rdocx_document e rpptx_document para criar arquivos DOCX e PPTX, respectivamente, com o conteúdo criado no manuscrito reprodutível. O pacote bookdown99 fornece as funções gitbook, pdf_book, epub_book e html_document2 para criar documentos reprodutíveis em diversos formatos (Git, PDF, EPUB e HTML, respectivamente). 9.6.3 Como manuscritos reprodutíveis contribuem para a ciência? O compartilhamento de bancos de dados e seus scripts de análise estatística permitem a adoção de práticas reprodutíveis, tais como a reanálise dos dados.100 O pacote projects101 fornece a função setup_projects para criar um projeto com arquivos organizados em diretórios. O pacote rmarkdown81 fornece a função render para criar manuscritos reprodutíveis a partir de arquivos .Rmd. O pacote bookdown99 fornece as funções gitbook, pdf_book, epub_book e html_document2 para criar documentos reprodutíveis em diversos formatos (Git, PDF, EPUB e HTML, respectivamente). 9.7 Compartilhamento 9.7.1 Por que compartilhar scripts? Compartilhar o script — principalmente junto aos dados — pode facilitar a replicação direta do estudo, a detecção de eventuais erros de análise, a detecção de pesquisas fraudulentas.102 9.7.2 O que pode ser compartilhado? Idealmente, todos os scripts, pacotes/bibliotecas e dados necessários para outros reproduzirem seus dados.90 Minimamente, partes importantes incluindo implementações de novos algoritmos e dados que permitam reproduzir um resultado importante.90 9.7.3 Como preparar dados para compartilhamento? .REF? 9.7.4 Como preparar scripts para compartilhamento? Providencie a documentação sobre seu script (ex.: arquivo README).90 Inclua a versão dos pacotes usados no seu script por meio de um script inicial para instalação de pacotes (ex.: ‘instalar.R’).97 Documente em um arquivo README os arquivos disponíveis e os pré-requisitos necessários para executar o código (ex.: pacotes e respectivas versões). Uma lista de configurações (hardware e software) que foram usadas para rodar o código pode ajudar na reprodução dos resultados.50 Use endereços de arquivos relativos.97 Crie links persistentes para versões do seu script.90 Defina uma semente para o gerador de números aleatórios em scripts com métodos computacionais que dependem da geração de números pseudoaleatórios.50 O pacote base103 fornece a função set.seed para especificar uma semente para reprodutibilidade de computações que envolvem números aleatórios. Escolha uma licença apropriada para garantir os direitos de criação e como outros poderão usar seus scripts.90 Teste o script em uma nova sessão antes de compartilhar.97 Cite todos os pacotes relacionados à sua análise.104 O pacote utils95 fornece a função citation para citar o programa R e os pacotes da sessão atual. O pacote grateful105 fornece a função cite_packages para citar os pacotes utilizados em um projeto R. Inclua a informação da sessão em que os scripts foram rodados.97 O pacote utils95 fornece a função sessionInfo para descrever as características do programa, pacotes e plataforma da sessão atual. 9.7.5 O que incluir no arquivo README? Título do trabalho.50 Autores do trabalho.50 Principais responsáveis pela escrita do script e quaisquer outras pessoas que fizeram contribuições substanciais para o desenvolvimento do script.50 Endereço de e-mail do autor ou contribuidor a quem devem ser direcionadas dúvidas, comentários, sugestões e bugs sobre o script.50 Lista de configurações nas quais o script foi testado, tais com nome e versão do programa, pacotes e plataforma.50 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["parte-4.html", "PARTE 4: DO MUNDO REAL À TABELA Da coleta à organização: estruturando dados para análises", " PARTE 4: DO MUNDO REAL À TABELA Da coleta à organização: estruturando dados para análises "],["variaveis-fatores.html", "Capítulo 10 Variáveis e fatores 10.1 Variáveis 10.2 Transformação de variáveis 10.3 Centralização de variáveis (centering) 10.4 Padronização de variáveis 10.5 Categorização de variáveis contínuas 10.6 Dicotomização de variáveis contínuas 10.7 Fatores", " Capítulo 10 Variáveis e fatores 10.1 Variáveis 10.1.1 O que são variáveis? Variáveis são informações que podem variar entre medidas em diferentes indivíduos e/ou repetições.106 Variáveis definem características de uma amostra extraída da população, tipicamente observados por aplicação de métodos de amostragem (isto é, seleção) da população de interesse.107 10.1.2 Como são classificadas as variáveis? Quanto à informação:107–110 Quantitativa Qualitativa Quanto ao conteúdo:107–111 Contínua: representam ordem e magnitude entre valores. Contínua (números inteiros) vs. Discreta (números racionais). Intervalo (valor ‘0’ é arbitrário) vs. Razão (valor ‘0’ verdadeiro). Categórica ordinal (numérica ou nominal): representam ordem, mas não magnitude entre valores. Categórica nominal (multinominal ou dicotômica): não representam ordem ou magnitude, apenas categorias. Quanto à interpretação:107–110 Dependente (desfecho) Independente (preditora, covariável, confundidora, controle) Mediadora Moderadora Modificadora Auxiliar Indicadora O pacote base103 fornece a função class para identificar qual é o tipo do objeto. O pacote base103 fornece as funções as.numeric e as.character para criar objetos numéricos e categóricos, respectivamente. O pacote base103 fornece as funções as.Date e as.logical para criar objetos em formato de data e lógicos (VERDADEIRO, FALSO), respectivamente. 10.1.3 Por que é importante classificar as variáveis? Identificar corretamente os tipos de variáveis da pesquisa é uma das etapas da escolha dos métodos estatísticos adequados para as análises e representações no texto, tabelas e gráficos.109 10.2 Transformação de variáveis 10.2.1 O que é transformação de variáveis? Transformação significa aplicar uma função matemática à variável medida em sua unidade original.112 A transformação visa atender aos pressupostos dos modelos estatísticos quanto à distribuição da variável, em geral a distribuição gaussiana.107,112 A dicotomização pode ser interpretada como um caso particular de agrupamento.113 10.2.2 Por que transformar variáveis? Muitos procedimentos estatísticos supõem que as variáveis - ou seus termos de erro, mais especificamente - são normalmente distribuídas. A violação dessa suposição pode aumentar suas chances de cometer um erro do tipo I ou II.114 Mesmo quando se está usando análises consideradas robustas para violações dessas suposições ou testes não paramétricos (que não assumem explicitamente termos de erro normalmente distribuídos), atender a essas questões pode melhorar os resultados das análises (por exemplo, Zimmerman, 1995).114 10.2.3 Quais transformações de variáveis podem ser aplicadas? Distribuições com assimetria à direita:114 Raiz quadrada Logaritmo natural Logaritmo base 10 Transformação inversa Figura 10.1: Transformações de variáveis com assimetria à direita (Original, Raiz quadrada, Log natural, Log10, Inversa). Distribuições com assimetria à esquerda:114 Reflexão e raiz quadrada Reflexão e logaritmo natural Reflexão e logaritmo base 10 Reflexão e transformação inversa Figura 10.2: Transformações de variáveis com assimetria à esquerda (Original, Reflexão + Raiz quadrada, Reflexão + Log natural, Reflexão + Log10, Reflexão + Inversa). Transformação arco-seno.114 Transformação de Box-Cox.115 Transformação de escore padrão (Z-score ou padronização). Escala Mínimo-Máximo (0,1). Normalização (normas L1, L2). Diferenciação. Categorização. Dicotomização. O pacote MASS116 fornece a função boxcox para executar a transformação de Box-Cox.115 10.3 Centralização de variáveis (centering) 10.3.1 O que é centralização? É uma transformação linear em que se subtrai a média da variável de cada observação. O objetivo é recentrar a variável em torno de zero, sem alterar a sua variabilidade.REF? 10.3.2 Por que centralizar? Facilita a interpretação dos coeficientes de regressão, especialmente em modelos com termos de interação.REF? Reduz a multicolinearidade entre variáveis e seus termos de interação ou polinomiais.REF? Mantém a escala original (apenas desloca a média).REF? 10.4 Padronização de variáveis 10.4.1 O que é padronização? Padronização é a transformação de uma variável contínua para uma escala comum, permitindo comparações entre variáveis medidas em diferentes unidades ou magnitudes.REF? 10.4.2 Por que padronizar? Facilita a interpretação em análises multivariadas.REF? Evita que variáveis em escalas maiores dominem os resultados de algoritmos que dependem de distância.REF? Melhora a comparabilidade entre estudos e bases de dados diferentes..REF? 10.4.3 Quais são os métodos de padronização mais comuns? Escore-Z (Z-score): subtrair a média e dividir pelo desvio-padrão.REF? Escala Min-Max: transformar para o intervalo [0,1].REF? Normalização (L1 ou L2): usada em aprendizado de máquina para vetores de características.REF? Transformações específicas de área: padronização por peso corporal, por superfície corporal, por tempo etc.REF? 10.4.4 Quais são as boas práticas de nomenclatura ao padronizar variáveis? Usar sufixos como _z ou _std para indicar padronização (altura_z, peso_std).REF? Documentar no dicionário de dados como cada variável foi transformada.REF? Evitar substituir a variável original: manter sempre a versão bruta e a padronizada.REF? O pacote base103 fornece a função scale para calcular automaticamente a padronização (média = 0, desvio padrão = 1). 10.5 Categorização de variáveis contínuas 10.5.1 O que é categorização de uma variável? .REF? 10.5.2 Por que não é recomendado categorizar variáveis contínuas? Nenhum dos argumentos usados para defender a categorização de variáveis se sustenta sob uma análise técnica rigorosa.117 Categorizar variáveis não é necessário para conduzir análises estatísticas. Ao invés de categorizar, priorize as variáveis contínuas.118–120 Em geral, não existe uma justificativa racional (plausibilidade biológica) para assumir que as categorias artificiais subjacentes existam.118–120 Caso exista um ponto de corte ou limiar verdadeiro que discrimine três ou mais grupos independentes, identificar tal ponto de corte ainda é um desafio.121 Categorização de variáveis contínuas aumenta a quantidade de testes de hipótese para comparações pareadas entre os quantis, inflando, portanto, o erro tipo I.122 Categorização de variáveis contínuas requer uma função teórica que pressupõe a homogeneidade da variável dentro dos grupos, levando tanto a uma perda de poder como a uma estimativa imprecisa.122 Categorização de variáveis contínuas pode dificultar a comparação de resultados entre estudos devido aos pontos de corte baseados em dados de um banco usados para definir as categorias.122 O pacote questionr123 fornece a função irec para executar uma interface interativa para codificação de variáveis categóricas. 10.5.3 Quais são as alternativas à categorização de variáveis contínuas? Análise com os dados das variáveis na escala de medida original.117 Análise com modelos de regressão com pesos locais (lowess) tais como splines e polinômios fracionais.117 10.6 Dicotomização de variáveis contínuas 10.6.1 O que são variáveis dicotômicas? Variáveis dicotômicas (ou binárias) podem representar categorias naturais tipo “presente/ausente”, “sim/não”.REF? Variáveis dicotômicas podem representar categorias fictícias, criadas a partir de variáveis multinominais, em que cada nível é convertido em uma variável dicotômica indicatoda (dummy).REF? Dicotomização é considerado um artefato da análise de dados, uma vez que é realizada após a coleta de dados.124 Geralmente são representadas por “1” (presente, sucesso) e “0” (ausente, falha).REF? 10.6.2 Quais argumentos são usados para defender a categorização ou dicotomização de variáveis contínuas? O argumento principal para dicotomização de variáveis é que tal procedimento facilita e simplifica a apresentação dos resultados, principalmente para o público em geral.113 Os pesquisadores não conhecem as consequências estatísticas da dicotomização.117 Os pesquisadores não conhecem os métodos adequados de análise não-paramétrica, não-linear e robusta.117 As categorias representam características existentes dos participantes da pesquisa, de modo que as análises devam ser feitas por grupos e não por indivíduos.117 A confiabilidade da(s) variável(eis) medida(s) é baixa e, portanto, categorizar os participantes resultaria em uma medida mais confiável.117 10.6.3 Por que não é recomendado dicotomizar variáveis contínuas? Nenhum dos argumentos usados para defender a dicotomização de variáveis se sustenta sob uma análise técnica rigorosa.117 Dicotomizar variáveis não é necessário para conduzir análises estatísticas. Ao invés de dicotomizar, priorize as variáveis contínuas.118–120 Em geral, não existe uma justificativa racional (plausibilidade biológica) para assumir que as categorias artificiais subjacentes existam.118–120 Dicotomização causa perda de informação e consequentemente perda de poder estatístico para detectar efeitos.117,118 Dicotomização também classifica indivíduos com valores próximos na variável contínua como indivíduos em pontos opostos e extremos, artificialmente sugerindo que são muito diferentes.118 Dicotomização pode diminuir a variabilidade das variáveis.118 Dicotomização pode ocultar não-linearidades presentes na variável contínua.117,118 A média ou a mediana, embora amplamente utilizadas, não são bons parâmetros para dicotomizar variáveis.113,118 Caso exista um ponto de corte ou limiar verdadeiro que discrimine dois grupos independentes, identificar tal ponto de corte ainda é um desafio.121 10.6.4 Quais cenários legitimam a dicotomização das variáveis contínuas? Quando existem dados e/ou análises que suportem a existência - não apenas a suposição ou teorização - de categorias com um ponto de corte claro e com significado entre elas.117 Quando a distribuição da variável contínua é muito assimétrica, de modo que uma grande quantidade de observações está em um dos extremos da escala.117 10.6.5 Quais métodos são usados para dicotomizar variáveis contínuas? Em termos de tabelas de contingência 2x2, os seguintes métodos permitem121 a identificação do limiar verdadeiro: Youden.125 Gini Index.126 Estatística qui-quadrado (\\(\\chi^2\\)).127 Risco relativo (\\(RR\\)).128 Kappa (\\(\\kappa\\)).129. 10.7 Fatores 10.7.1 O que são fatores? Fator é um sinônimo de variável categórica.REF? Na modelagem, fator é sinônimo de variável preditora, em particular quando se refere à modelagem de efeitos fixos e aleatórios – os fatores (variáveis) são fatores fixos ou fatores aleatórios.REF? Fatores são variáveis controladas pelos pesquisadores em um experimento para determinar seu efeito na(s) variável(ies) de resposta. Um fator pode assumir apenas um pequeno número de valores, conhecidos como níveis. Os fatores podem ser uma variável categórica ou baseados em uma variável contínua, mas usam apenas um número limitado de valores escolhidos pelos experimentadores.REF? O pacote base103 fornece a função as.factor para converter uma variável em fator. 10.7.2 O que são níveis de um fator? Níveis de um fator são as possíveis categorias que descrevem um fator.REF? O pacote base103 fornece as funções levels e nlevels para listar os níveis e a quantidade deles em um fator. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["dados-bigdata-metadados.html", "Capítulo 11 Dados, big data e metadados 11.1 Dados 11.2 Big data 11.3 Metadados", " Capítulo 11 Dados, big data e metadados 11.1 Dados 11.1.1 O que são dados? “Tudo são dados”.130 Dados coletados em um estudo geralmente contêm erros de mensuração e/ou classificação, dados perdidos e são agrupados por alguma unidade de análise.131 11.1.2 Quais são as fontes de dados? Experimentos.REF? Mundo real.REF? Simulação.REF? 11.1.3 O que são dados primários e secundários? Dados primários são dados originais coletados intencionalmente para uma determinada análise exploratória ou inferencial planejada a priori.107 Dados secundários compreendem dados coletados inicialmente para análises de um estudo, e são subsequentemente utilizados para outras análises.107 11.1.4 O que são dados quantitativos e qualitativos? .REF? 11.2 Big data 11.2.1 O que são big data? Big data refere-se a bancos de dados muito grandes com um mecanismo “R” — aleatório (Random), auto-reportado (self-Reported), reportado administrativamente (administratively reported), seletivamente respondido (selectively repondend) — descontrolado ou desconhecido.19 11.3 Metadados 11.3.1 O que são metadados? Metadados são informações técnicas relacionadas às variáveis do estudo, tais como rótulos, limites de valores plausíveis, códigos para dados perdidos e unidades de medida.132 Metadados também são informações relacionadas ao delineamento e/ou protocolo do estudo, recrutamento dos participantes, e métodos para realização das medidas.132 11.3.2 Quais são as recomendações para os metadados de um banco de dados? Utilize rótulos padronizados para variáveis e fatores para facilitar o reuso (reprodutibilidade) do conjuntos de dados e scripts de análise.133 Crie rótulos de variáveis concisos, claros e mutuamente exclusivos.133 Evite muitas letras maiúsculas ou outros caracteres especiais que usam a shift.133 Na existência de versões de instrumentos publicadas em diferentes anos, use o ano de publicação das escalas no rótulo.133 Divida o rótulo da variável ou fator em partes e ordene-as do mais geral para o mais particular geral (ex.: experimento -&gt; repetição -&gt; escala -&gt; item).133 O pacote base103 fornece a função names para declarar o nome de uma variável. O pacote base103 fornece a função labels para declarar o rótulo de uma variável. O pacote units134 fornece a função units para declarar as unidades de medida de uma variável. O pacote units134 fornece a função valid_udunits para listar as opções de unidades de medida de uma variável. O pacote janitor135 fornece a função clean_names para formatar de modo padronizado o nome das variáveis utilizando apenas caracteres, números e o símbolo ‘_’. O pacote Hmisc136 fornece a função contents para criar um objeto com os metadados (nomes, rótulos, unidades, quantidade e níveis das variáveis categóricas, e quantidade de dados perdidos) de um dataframe. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["medidas-instrumentos.html", "Capítulo 12 Medidas e instrumentos 12.1 Escalas 12.2 Medição e Medidas 12.3 Erros de medida 12.4 Instrumentos 12.5 Acurácia e precisão 12.6 Viés e variabilidade", " Capítulo 12 Medidas e instrumentos 12.1 Escalas 12.1.1 O que são escalas? Uma escala de medição grosseira representa um construto de natureza contínua medido por itens tais que diferentes pontuações são agrupadas na mesma categoria no ato da coleta de dados.124 Em escalas grosseiras, erros são introduzidos porque as variações contínunas do constructo são colapsadas em uma mesma categorias ou separadas entre categorias próximas.124 Escalas tipo Likert com 5 categorias tipo “discordo totalmente”, “discordo parcialmente”, “nem concordo nem discordo”, “concordo parcialmente”, e “concordo totalmente” são escalas grosseira porque as diferenças entre as categorias não são iguais. Por exemplo, a diferença entre “discordo totalmente” e “discordo parcialmente” não é a mesma que a diferença entre “concordo parcialmente” e “concordo totalmente”.124 Figura 12.1: Exemplo de instrumento com 3 itens tipo Likert com 5 categorias cada. Tabela 12.1: Descrição dos itens tipo Likert do instrumento. Itens Discordância Neutro Concordância Média DP Item1 40 22 38 2.94 1.38 Item2 36 20 44 3.12 1.42 Item3 38 34 28 2.82 1.32 O pacote likert137 fornece a função likert para analisar respostas de instrumentos em escala tipo Likert. O pacote ggstats138 fornece a função gglikert para gerar um gráfico em escalas tipo Likert. O erros em escalas grosseiras é considerado sistemático mas não pode ser corrigido em nível da unidade de análise.124 12.2 Medição e Medidas 12.2.1 O que é medição? Processo empírico, realizado por meio de um instrumento, que estabelece uma correspondência rigorosa e objetiva entre uma observação e uma categoria em um modelo da observação.139 Esse processo tem como objetivo distinguir de maneira substantiva a manifestação observada de outras possíveis manifestações que também possam ser diferenciadas.139 12.2.2 O que são medidas diretas? .REF? 12.2.3 O que são medidas derivadas? .REF? 12.2.4 O que são medidas por teoria? .REF? 12.2.5 O que são medidas únicas? A medida única da pressão arterial sistólica no braço esquerdo resulta em um valor pontual.REF? Medidas únicas obtidas de diferentes unidades de análise podem ser consideradas independentes se observadas outras condições na coleta de dados.REF? O valor pontual será considerado representativo da variável para a unidade de análise (ex.: 120 mmHg para o participante #9). Tabela 12.2: Tabela de dados brutos com medidas únicas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) 1 118 2 113 3 116 4 110 5 111 6 116 7 120 8 111 9 120 10 112 12.2.6 O que são medidas repetidas? As medidas repetidas podem ser tabuladas separadamente, por exemplo para análise da confiabilidade de obtenção dessa medida.REF? A medida repetida da pressão arterial no braço esquerdo resulta em um conjunto de valores pontuais (ex.: 110 mmHg, 118 mmHg e 116 mmHg para o participante #5). Tabela 12.3: Tabela de dados brutos com medidas repetidas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) #1 Pressão arterial, braço esquerdo (mmHg) #2 Pressão arterial, braço esquerdo (mmHg) #3 1 114 112 112 2 115 120 113 3 115 110 120 4 117 116 114 5 110 118 116 6 110 120 113 7 118 114 117 8 111 112 119 9 120 112 117 10 110 115 115 As medidas repetidas podem ser agregadas por algum parâmetro — ex.: média, mediana, máximo, mínimo, entre outros —, observando-se a relevância biológica, clínica e/ou metodológica desta escolha.REF? Medidas agregadas obtidas de diferentes unidades de análise podem ser consideradas independentes se observadas outras condições na coleta de dados.REF? O valor agregado será considerado representativo da variável para a unidade de análise (ex.: média = 115 mmHg para o participante #5). Tabela 12.4: Tabela de dados brutos com medidas repetidas agregadas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) média 1 113 2 116 3 115 4 116 5 115 6 114 7 116 8 114 9 116 10 113 O pacote stats140 fornece a função aggregate para agregar medidas repetidas utilizando uma função personalizada. 12.2.7 O que são medidas seriadas? Medidas seriadas são possivelmente relacionadas e, portanto, dependentes na mesma unidade de análise.REF? Por exemplo, a medida seriada da pressão arterial no braço esquerdo, em intervalos tipicamente regulares (ex.: 114 mmHg, 120 mmHg e 110 mmHg em 1 min, 2 min e 3 min, respectivamente, para o participante #1). Tabela 12.5: Tabela de dados brutos com medidas seriadas não agregadas. Unidade de análise Tempo (min) Pressão arterial, braço esquerdo (mmHg) 1 1 114 1 2 120 1 3 110 2 1 119 2 2 120 2 3 114 3 1 116 3 2 114 3 3 116 4 1 113 Medidas seriadas também agregadas por parâmetros — ex.: máximo, mínimo, amplitude — são consideradas representativas da variação temporal ou de uma característica de interesse (ex.: amplitude = 10 mmHg para o participante #1). Tabela 12.6: Tabela de dados brutos com medidas seriadas não agregadas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) amplitude 1 10 2 6 3 2 4 6 5 1 6 8 7 9 8 10 9 7 10 5 O pacote stats140 fornece a função aggregate para agregar medidas repetidas utilizando uma função personalizada. 12.2.8 O que são medidas múltiplas? Medidas múltiplas também são possivelmente relacionadas e, portanto, são dependentes na mesma unidade de análise. Medidas múltiplas podem ser obtidas de modo repetido para análise agregada ou seriada.REF? A medida de pressão arterial bilateral resulta em um conjunto de valores pontuais (ex.: braço esquerdo = 114 mmHg, braço direito = 118 mmHg para o participante #8). Neste caso, ambos os valores pontuais são considerados representativos daquela unidade de análise. Tabela 12.7: Tabela de dados brutos com medidas múltiplas. Unidade de análise Pressão arterial, braço esquerdo (mmHg) Pressão arterial, braço direito (mmHg) 1 117 115 2 120 118 3 112 118 4 112 112 5 116 112 6 112 118 7 115 113 8 114 118 9 119 114 10 112 116 O pacote stats140 fornece a função aggregate para agregar medidas repetidas utilizando uma função personalizada. 12.3 Erros de medida 12.3.1 O que são erros de medida? .REF? A natureza dos erros de medida são em geral atribuídos aos (1) instrumentos utilizados e variações no protocolo, na medida em que o seu tamanho médio pode ser reduzido por modificações e melhorias nesses instrumentos; e (2) variações genuínas medida em de curto prazo.141 12.3.2 Quais fontes de variabilidade são comumente investigadas? Intra/Entre participantes (isto é, unidades de análise).142 Intra/Entre repetições.142 Intra/Entre observadores.142 12.4 Instrumentos 12.4.1 O que são instrumentos? .REF? 12.5 Acurácia e precisão 12.5.1 O que é acurácia? Acurácia expressa a proximidade de concordância entre uma mensuração e o valor real.143 Acurária está para medidas como validade está para instrumentos de medida.REF? 12.5.2 O que é precisão? Precisão se refere à proximidade de concordância entre resultados de testes independentes obtidos nas mesmas condições de teste.143 Precisão é um índice de quão próximo os resultados podem ser repetidos entre mensurações repetidas.144 Precisão está para medidas como confiabilidade está para instrumentos de medida.REF? Figura 12.2: Acurácia e precisão como propriedades de uma medida. 12.6 Viés e variabilidade 12.6.1 Qual é a relação entre viés e variabilidade? .REF? Figura 12.3: Viés e variabilidade de uma medida. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["tabulacao-dados.html", "Capítulo 13 Tabulação de dados 13.1 Planilhas eletrônicas", " Capítulo 13 Tabulação de dados 13.1 Planilhas eletrônicas 13.1.1 Qual a organização de uma tabela de dados? As informações podem ser organizadas em formato de dados retangulares (ex.: matrizes, tabelas, quadro de dados) ou não retangulares (ex.: listas).REF? Cada variável possui sua própria coluna (vertical).145 Cada observação possui sua própria linha (horizontal).145 Cada valor possui sua própria célula especificada em um par (linha, coluna).145 Cada célula possui seu próprio dado.145 O pacote DataEditR146 fornece a função data_edit para interativamente criar, editar e salvar a tabela de dados. 13.1.2 Qual a estrutura básica de uma tabela para análise estatística? Use apenas 1 (uma) planilha eletrônica para conter todas as informações coletadas. Evite múltiplas abas no mesmo arquivo, assim como múltiplos arquivos quando possível.147 Use apenas 1 (uma) linha de cabeçalho para nomear os fatores e variáveis do seu estudo.147 Tipicamente, cada linha representa um participante e cada coluna representa uma variável ou fator do estudo. Estudos com medidas repetidas dos participantes podem conter múltiplas linhas para o mesmo participante (repetindo os dados na mesma coluna, conhecido como formato curto) ou só uma linha para o participante (repetindo os dados em colunas separadas, conhecido como formato longo ).148 Tabela 13.1: Estrutura básica de uma tabela de dados. V1 V2 V3 V4 \\(x_{1,1}\\) \\(x_{1,2}\\) \\(x_{1,3}\\) \\(x_{1,4}\\) \\(x_{2,1}\\) \\(x_{2,2}\\) \\(x_{2,3}\\) \\(x_{2,4}\\) \\(x_{3,1}\\) \\(x_{3,2}\\) \\(x_{3,3}\\) \\(x_{3,4}\\) \\(x_{4,1}\\) \\(x_{4,2}\\) \\(x_{4,3}\\) \\(x_{4,4}\\) \\(x_{5,1}\\) \\(x_{5,2}\\) \\(x_{5,3}\\) \\(x_{5,4}\\) 13.1.3 O que usar para organizar tabelas para análise computadorizada? Seja consistente em: códigos para as variáveis categóricas; códigos para dados perdidos; nomes das variáveis; identificadores de participantes; nome dos arquivos; formato de datas; uso de caracteres de espaço.147,148 Crie um dicionário de dados (metadados) em um arquivo separado contendo: nome da variável, descrição da variável, unidades de medida e valores extremos possíveis.147 Use recursos para validação de dados antes e durante a digitação de dados.147,148 O pacote data.table149 fornece a função melt.data.table para reorganizar a tabela em diferentes formatos. 13.1.4 O que não usar para organizar tabelas para análise computadorizada? Não deixe células em branco: substitua dados perdidos por um código sistemático (ex.: NA [not available]).147 Não inclua análises estatísticas ou gráficos nas tabelas de dados brutos.147 Não utilize cores como informação. Se necessário, crie colunas adicionais - variáveis instrumentais ou auxiliares - para identificar a informação de modo que possa ser analisada.147 Não use células mescladas. Delete linhas e/ou colunas totalmente em branco (sem unidades de análise e/ou sem variáveis). 13.1.5 O que é recomendado e o que deve ser evitado na organização das tabelas para análise? Tabela 13.2: Formatação recomendada para tabela de dados. ID Data.Coleta Estado.Civil Numero.Filhos 1 24-09-2025 casado NA 2 25-09-2025 casado 1 3 26-09-2025 casado NA 4 27-09-2025 solteiro NA 5 28-09-2025 casado NA 6 29-09-2025 solteiro 0 7 30-09-2025 solteiro NA 8 01-10-2025 solteiro NA 9 02-10-2025 casado NA 10 03-10-2025 solteiro NA Tabela 13.3: Formatação não recomendada para tabela de dados. ID Data de Coleta Estado Civil Número de Filhos 1 24-09-2025 casado NA 2 25-09-2025 Casado 1 3 26-09-2025 casado NaN 4 27-09-2025 Solteiro N/A 5 28-09-2025 Casado N.A. 6 29-09-2025 solteiro 0 7 30-09-2025 solteiro 8 01-10-2025 Solteiro na 9 02-10-2025 casado n.a. 10 03-10-2025 Solteiro 999 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["distribuicoes-parametros.html", "Capítulo 14 Distribuições e parâmetros 14.1 Distribuições de probabilidade 14.2 Distribuições multivariadas 14.3 Parâmetros 14.4 Tendência central 14.5 Dispersão 14.6 Proporção 14.7 Distribuição 14.8 Extremos 14.9 Robustez em medidas de localização 14.10 Parâmetros robustos", " Capítulo 14 Distribuições e parâmetros 14.1 Distribuições de probabilidade 14.1.1 O que são distribuições de probabilidade? Uma distribuição de probabilidade é uma função que descreve os valores possíveis ou o intervalo de valores de uma variável (eixo horizontal) e a frequência com que cada valor é observado (eixo vertical).107 14.1.2 Como representar distribuições de probabilidade? Tabelas de frequência, polígonos de frequência, gráficos de barras, histogramas e boxplots são formas de representar distribuições de probabilidade.150 Tabelas de frequência mostram as categorias de medição e o número de observações em cada uma. É necessário conhecer o intervalo de valores (mínimo e máximo), que é dividido em intervalos arbitrários chamados “intervalos de classe”.150 Se houver muitos intervalos, não haverá redução significativa na quantidade de dados, e pequenas variações serão perceptíveis. Se houver poucos intervalos, a forma da distribuição não poderá ser adequadamente determinada.150 A quantidade de intervalos pode ser determinada pelo método de Sturges, que é dado pela fórmula \\(k = 1 + 3.322 \\times \\log_{10}(n)\\), onde \\(k\\) é o número de intervalos e \\(n\\) é o número de observações.151 A quantidade de intervalos pode ser determinada pelo método de Scott, que é dado pela fórmula \\(h = 3.5 \\times \\text{sd}(x) \\times n^{-1/3}\\), onde \\(h\\) é a largura do intervalo, \\(\\text{sd}(x)\\) é o desvio-padrão e \\(n\\) é o número de observações.152 A quantidade de intervalos pode ser determinada pelo método de Freedman-Diaconis, que é dado pela fórmula \\(h = 2 \\times \\text{IQR}(x) \\times n^{-1/3}\\), onde \\(h\\) é a largura do intervalo, \\(\\text{IQR}(x)\\) é o intervalo interquartil e \\(n\\) é o número de observações.153 Figura 14.1: Histogramas com diferentes métodos de binning.: Sturges, Scott e Freedman-Diaconis. A largura das classes pode ser determinada dividindo o intervalo total de observações pelo número de classes. Recomenda-se larguras iguais, mas larguras desiguais podem ser usadas quando existirem grandes lacunas nos dados ou em contextos específicos. Os intervalos devem ser mutuamente exclusivos e não sobrepostos, evitando intervalos abertos (ex.: &lt;5, &gt;10).150 Polígonos de frequência são gráficos de linhas que conectam os pontos médios de cada barra do histograma. Eles são úteis para comparar duas ou mais distribuições de frequência.150 Gráficos de barra verticais ou horizontais representam a distribuição de frequências de uma variável categórica. A altura de cada barra é proporcional à frequência da classe. A largura da barra é igual à largura da classe. A área de cada barra é proporcional à frequência da classe. A área total do gráfico de barras é igual ao número total de observações.150 Histogramas representam a distribuição de frequências de uma variável contínua. A altura de cada barra é proporcional à frequência da classe. A largura da barra é igual à largura da classe. A área de cada barra é proporcional à frequência da classe. A área total do histograma é igual ao número total de observações.150 Boxplots representam a distribuição de frequências de uma variável contínua. A linha central divide os dados em duas partes iguais (mediana ou Q2). A caixa inferior representa o primeiro quartil (Q1) e a caixa superior representa o terceiro quartil (Q3). A linha inferior é o mínimo e a linha superior é o máximo. Os valores atípicos são representados por pontos individuais.150 O pacote grDevices154 fornece a função nclass para determinar a quantidade de classes de um histograma com os métodos de Sturge151, Scott152 ou Freedman-Diaconis153. O pacote ggplot2155 fornece a função geom_freqpoly para criar histogramas. 14.1.3 Quais características definem uma distribuição? Uma distribuição pode ser definida por modelos matemáticos e caracterizada por parâmetros de tendência central, dispersão, simetria e curtose.REF? 14.1.4 Quais são as distribuições mais comuns? Distribuções discretas: Bernoulli: resultado de um único teste com dois possíveis desfechos (sucesso ou fracasso).REF? Binomial: número de sucessos em k tentativas.REF? Geométrica: número de testes até o 1o sucesso.REF? Binomial negativa: número de testes até o k-ésimo sucesso.REF? Hipergeométrica: número de indivíduos na amostra tomados sem reposição.REF? Poisson: número de eventos em um intervalo de tempo fixo.REF? Uniforme: resultados (finitos) que são igualmente prováveis.REF? Multinomial: resultados de múltiplos testes com mais de dois possíveis desfechos.REF? Figura 14.2: Distribuições discretas e suas funções de probabilidade. Distribuições contínuas: Uniforme: .REF? Exponencial: .REF? Normal: .REF? Aproximação binomial: .REF? Aproximação Poisson: .REF? t-Student: .REF? Qui-quadrado: .REF? Weibull: .REF? Gama: .REF? Log-normal: .REF? Beta: .REF? Logística: .REF? Pareto.REF? Figura 14.3: Distribuições contínuas básicas e suas funções de densidade. Figura 14.4: Distribuições contínuas aproximadas e suas funções de densidade. Figura 14.5: Distribuições contínuas aproximadas e suas funções de densidade. Figura 14.6: Distribuições contínuas para inferência e suas funções de densidade. Figura 14.7: Distribuições contínuas para dados específicos e suas funções de densidade. Figura 14.8: Distribuições contínuas para probabilidades e proporções e suas funções de densidade. Figura 14.9: Distribuições contínuas com caudas pesadas e suas funções de densidade. 14.1.5 Quais são as funções de uma distribuição? Função de massa de probabilidade (probability mass function, pmf).REF? Função de distribuição cumulativa (cumulative distribution function, cdf).REF? Função quantílicas (quantile function, qf).REF? Função geradora de números aleatórios (random function, rf).REF? O pacote stats140 fornece funções de distribuição de probabilidade (p), funções de densidade (d), funções quantílicas (q) e funções geradores de números aleatórios (r) para as distribuições normal, Student t, binomial, qui-quadrado, uniforme, dentre outras. O pacote ggdist156 fornece a função geom_slabinterval para criar gráficos de distribuição de probabilidade (p) e funções de densidade (d) as distribuições. O pacote ggfortify157 fornece a função ggdistribution para criar gráficos de distribuição de probabilidade (p), funções de densidade (d), funções quantílicas (q) e funções geradores de números aleatórios (r) para as distribuições. 14.1.6 O que é a distribuição normal? A distribuição normal (ou gaussiana) é uma distribuição com desvios simétricos positivos e negativos em torno de um valor central.108 Em uma distribuição normal, o intervalo de 1 desvio-padrão (±1DP) inclui cerca de 68% dos dados; de 2 desvios-padrão (±2DP) cerca de 95% dos dados; e no intervalo de 3 desvios-padrão (±3DP) cerca de 99% dos dados.108 Figura 14.10: Distribuições e funções de probabilidade. 14.1.7 Que métodos podem ser utilizados para identificar a normalidade da distribuição? Histogramas.107 Gráficos Q-Q.107 Testes de hipótese nula:107 Kolmogorov-Smirnov Shapiro-Wilk Anderson-Darling Figura 14.11: Distribuição normal e métodos de visualização e testes de normalidade. 14.1.8 O que são distribuições não-normais? .REF? 14.2 Distribuições multivariadas 14.2.1 O que são distribuições multivariadas? Distribuições multivariadas descrevem a probabilidade conjunta de duas ou mais variáveis aleatórias.REF? Exemplos de distribuições multivariadas incluem a distribuição normal multivariada, a distribuição t multivariada, a distribuição binomial multinomial e a distribuição de Dirichlet.REF? Figura 14.12: Distribuição normal bivariada e amostra simulada com histogramas marginais. 14.3 Parâmetros 14.3.1 O que são parâmetros? Parâmetros são informações que definem um modelo teórico, como propriedades de uma coleção de indivíduos.106 Parâmetros definem características de uma população inteira, tipicamente não observados por ser inviável ter acesso a todos os indivíduos que constituem tal população.107 O pacote base103 fornece a função summary para calcular diversos parâmetros descritivos. 14.3.2 O que é uma análise paramétrica? Testes paramétricos possuem suposições sobre as características e/ou parâmetros da distribuição dos dados na população.107 Testes paramétricos assumem que: a variável é quantitativa numérica (contínua); os dados foram amostrados de uma população com distribuição normal; a variância da(S) amostra(s) é igual à da população; as amostras foram selecionadas de modo aleatório na população; os valores de cada amostra são independentes entre si.107,108 Testes paramétricos são baseados na suposição de que os dados amostrais provêm de uma população com parâmetros fixos determinando sua distribuição de probabilidade.8 14.3.3 O que é uma análise não paramétrica? Testes não-paramétricos fazem poucas suposições, ou menos rigorosas, sobre as características e/ou parâmetros da distribuição dos dados na população.107,108 Testes não-paramétricos são úteis quando as suposições de normalidade não podem ser sustentadas.108 14.3.4 Devemos testar as suposições de normalidade? Testes preliminares de normalidade não são necessários para a maioria dos testes paramétricos de comparação, pois eles são robustos contra desvios moderados da normalidade. Normalidade da distribuição deve ser estabelecida para a população.158 14.3.5 Por que as análises paramétricas são preferidas? Em geral, testes paramétricos são mais robustos (isto é, possuem menores erros tipo I e II) que seus testes não-paramétricos correspondentes.107,159,160 Testes não-paramétricos apresentam menor poder estatístico (maior erro tipo II) comparados aos testes paramétricos correspondentes.108 14.3.6 Que parâmetros podem ser estimados? Parâmetros de tendência central.108,161 Parâmetros de dispersão.108,161,162 Parâmetros de proporção.108,161,163,163 Parâmetros de distribuição.161 Parâmetros de extremos.108 O pacote base103 fornece a função summary para calcular diversos parâmetros descritivos. 14.4 Tendência central 14.4.1 Que parâmetros de tendência central podem ser estimados? Média aritmética, ponderada, geométrica ou harmônica.108,161,164 Mediana.108,161,165 Moda.108,161,165 A posição relativa das medidas de tendência central (média, mediana e moda) depende da forma da distribuição.165 Em uma distribuição normal, as três medidas são idênticas.165 A média é sempre puxada para os valores extremos, por isso é deslocada para a cauda em distribuições assimétricas.165 A mediana fica entre a média e a moda em distribuições assimétricas.165 A moda é o valor mais frequente e, portanto, se localiza no pico da distribuição assimétrica.165 Uma distribuição pode uma moda (unimodal), duas modas (bimodal) ou três ou mais modas (multimodal), indicando a presença de mais de um valor com alta frequência.165 Figura 14.13: Distribuições unimodal, bimodal e multimodal. Figura 14.14: Parâmetros de tendência central em distribuições assimétricas e normais. O pacote base103 fornece a função summary para calcular diversos parâmetros descritivos. 14.4.2 Como escolher o parâmetro de tendência central? A mediana é preferida à média quando existem poucos valores extremos na distribuição, alguns valores são indeterminados, ou há uma distribuição aberta, ou os dados são medidos em uma escala ordinal.165 A moda é preferida quando os dados são medidos em uma escala nominal.165 A média geométrica é preferida quando os dados são medidos em uma escala logarítmica.165 14.5 Dispersão 14.5.1 Que parâmetros de dispersão podem ser estimados? Variância.108,161 Desvio-padrão: Informam sobre a dispersão da população e são, portanto, úteis como preditores da variação em novas amostras.162,166,167 Erro-padrão: Refletem a incerteza na média e sua dependência do tamanho da amostra.162,166 Amplitude.108,161,167 Intervalo interquartil.108,161,167 Intervalo de confiança: Captura a média populacional correspondente ao nível de significância \\(\\alpha\\) pré-estabelecido.108,161,166,168 Figura 14.15: Parâmetros de dispersão em distribuições normais. O pacote base103 fornece a função summary para calcular diversos parâmetros descritivos. O pacote stats140 fornece a função confint para calcular o intervalo de confiança em um nível de significância \\(\\alpha\\). 14.5.2 Como escolher o parâmetro de dispersão? Desvio-padrão é apropriado quando a média é utilizada como parâmetro de tendência central em distribuições simétricas.167 Amplitue ou intervalo interquartil são apropriadas para variáveis ordinais ou distribuições assimétricas.167 14.5.3 O que é a correção de Bessel para variância? Correção de Bessel é um ajuste feito no denominador da fórmula de variância da amostra — ou seja, o número de graus de liberdade — para evitar que a variância amostral seja menor do que a variância populacional.169 A correção de Bessel é feita subtraindo-se 1 do número de observações da amostra, ou seja, \\(n - 1\\).169 14.5.4 Por que a correção de Bessel para variância é importante? A correção de Bessel é importante porque a variância amostral tende a ser menor do que a variância populacional, especialmente em amostras pequenas.169 A correção de Bessel ajuda a garantir que a variância amostral seja uma estimativa mais precisa da variância populacional, o que é fundamental para a validade dos testes estatísticos e das inferências feitas a partir da amostra.169 14.6 Proporção 14.6.1 Que parâmetros de proporção podem ser estimados? Frequência absoluta.108,161,163 Frequência relativa.108,161,163 Percentil.108,161,163 Quantil: é o ponto de corte que define a divisão da amostra em grupos de tamanhos iguais. Portanto, não se referem aos grupos em si, mas aos valores que os dividem:163 Tercil: 2 valores que dividem a amostra em 3 grupos de tamanhos iguais.163 Quartil: 3 valores que dividem a amostra em 4 grupos de tamanhos iguais.163 Quintil: 4 valores que dividem a amostra em 5 grupos de tamanhos iguais.163 Decil: 9 valores que dividem a amostra em 10 grupos de tamanhos iguais.163 O pacote base103 fornece a função summary para calcular diversos parâmetros descritivos. O pacote base103 fornece a função table para calcular proporções. O pacote stats103 fornece a função quantile para executar análise de percentis. 14.7 Distribuição 14.7.1 Que parâmetros de distribuição podem ser estimados? Assimetria.161 Curtose.161 Figura 14.16: Parâmetros de distribuição: Assimetria e Curtose. Figura 14.17: Parâmetros de distribuição: Curtose em distribuições simétricas (normal vs. uniforme). 14.8 Extremos 14.8.1 O que são valores extremos? Valores extremos podem constituir valores legítimos ou ilegítimos de uma distribuição.170 Valores extremos, quando raros ou desproporcionais, podem se tornar discrepantes ou influentes, afetando as análises estatísticas, sendo recomendado uma análise robusta.REF? 14.8.2 Que parâmetros extremos podem ser estimados? Mínimo.108 Máximo.108 Figura 14.18: Regressão linear com valores extremos. 14.9 Robustez em medidas de localização 14.9.1 O que é ponto de quebra (breakdown value)? É a menor proporção de contaminação que pode levar o estimador a resultados arbitrariamente errados; quanto maior, mais robusto.171 14.9.2 Por que a média não é robusta? Porque tem ponto de quebra \\(~0%\\) e função influência não limitada; um único outlier pode distorcer a média arbitrariamente.171 14.9.3 Qual a alternativa robusta para localização? Mediana, com \\(~50%\\) de ponto de quebra e função influência limitada.171 14.9.4 Como estimar escala de forma robusta? Median Absolute Deviation (MAD) (??), com correção 1,483 para normalidade, com \\(~50%\\) de ponto de quebra..171 \\[\\begin{equation} \\tag{14.1} MAD = 1.483 \\cdot \\text{median}(|x_i - \\text{median}(x)|) \\end{equation}\\] Primeiro quartil das diferenças pareadas (\\(Qn\\)) (14.2), com \\(~50%\\) de ponto de quebra.171 \\[\\begin{equation} \\tag{14.2} Qn = 2.2219 \\cdot \\text{first quartile}(|x_i - x_j|; i &lt; j) \\end{equation}\\] O intervalo interquartil (\\(IQR\\)) @ref(eq;iqr) é robusto, com ponto de quebra \\(~25%\\), sendo simples de interpretar e útil em boxplots.171 \\[\\begin{equation} \\tag{14.3} IQR = Q3 - Q1 \\end{equation}\\] 14.10 Parâmetros robustos 14.10.1 O que são parâmetros robustos? Parâmetros robustos são medidas de posição e dispersão que permanecem estáveis mesmo na presença de valores discrepantes.172 14.10.2 Que parâmetros robustos podem ser estimados? Mediana em vez da média aritmética, pois é menos sensível a valores extremos.172 MAD (Median Absolute Deviation) em vez do desvio padrão, que pode ser escalonado por 1.483 para comparabilidade.172 Qn e Sn como estimadores alternativos de dispersão robusta.172 Média e variância Winsorizadas como opções intermediárias, reduzindo a influência dos outliers.172 14.10.3 Por que utilizar parâmetros robustos? Eles garantem maior confiabilidade quando os dados não seguem a normalidade ou apresentam contaminação por outliers.172 Permitem análises mais estáveis em estudos exploratórios, evitando decisões equivocadas sobre variabilidade ou tendência central.172 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["dados-perdidos-imputados.html", "Capítulo 15 Dados perdidos e imputados 15.1 Dados perdidos 15.2 Mecanismos geradores de dados perdidos 15.3 Estratégias para lidar com dados perdidos 15.4 Dados imputados", " Capítulo 15 Dados perdidos e imputados 15.1 Dados perdidos 15.1.1 O que são dados perdidos? Dados perdidos são dados não coletados de um ou mais participantes, para uma ou mais variáveis.173 Tabela 15.1: Tabela simulada com 10 indivíduos de um RCT (dados com perdas aleatórias). id Grupo Idade Sexo Desfecho (pré) Desfecho (pós) 1 Controle 53 F 57.0 41.3 2 Controle 64 F 45.3 70.0 3 Controle 65 M 39.3 NA 4 Intervenção 66 F 47.8 NA 5 Controle 44 M 39.7 65.7 6 Intervenção NA F 42.7 NA 7 Intervenção 67 M 43.7 64.9 8 Intervenção NA F 33.1 63.3 9 Controle 68 F 58.4 61.6 10 Controle 74 M 51.5 54.3 O pacote base103 fornece a função is.na para identificar que elementos de um objeto são dados perdidos. 15.1.2 Qual o problema de um estudo ter dados perdidos? Uma grande quantidade de dados perdidos pode comprometer a integridade científica do estudo, considerando-se que o tamanho da amostra foi estimado para observar um determinado tamanho de efeito mínimo.173 Perda de participantes no estudo por dados perdidos pode reduzir o poder estatístico (erro tipo II).173 Não existe solução globalmente satisfatória para o problema de dados perdidos.173 15.2 Mecanismos geradores de dados perdidos 15.2.1 Quais os mecanismos geradores de dados perdidos? Dados perdidos completamente ao acaso (missing completely at random, MCAR), em que os dados perdidos estão distribuídos aleatoriamente nos dados da amostra.174,175 Figura 15.1: Representação gráfica de dados perdidos completamente ao acaso (MCAR) em um estudo randomizado controlado (RCT). Dados perdidos ao acaso (missing at random, MAR), em que a probabilidade de ocorrência de dados perdidos é relacionada a outras variáveis medidas.174,175 Figura 15.2: Representação gráfica de dados perdidos ao acaso (MAR) em um estudo randomizado controlado (RCT). Dados perdidos não ao acaso (missing not at random, MNAR), em que a probabilidade da ocorrência de dados perdidos é relacionada com a própria variável.174,175 Figura 15.3: Representação gráfica de dados perdidos não ao acaso (MNAR) em um estudo randomizado controlado (RCT). 15.2.2 Como identificar o mecanismo gerador de dados perdidos em um banco de dados? Por definição, não é possível avaliar se os dados foram perdidos ao acaso (MAR) ou não (MNAR).174 Testes t e regressões logísticas podem ser aplicados para identificar relações entre variáveis com e sem dados perdidos, criando um fator de análise (‘dado perdido’ = 1, ‘dado observado’ = 0).174 O pacote misty176 fornece a função na.test para executar o Little’s Missing Completely at Random (MCAR) test177. O pacote naniar178 fornece a função mcar_test para executar o Little’s Missing Completely at Random (MCAR) test177. O pacote naniar178 fornece a função gg_miss_upset para gerar o gráfico Upset para visualizar padrões de dados perdidos. 15.3 Estratégias para lidar com dados perdidos 15.3.1 Que estratégias podem ser utilizadas na coleta de dados quando há expectativa de perda amostral? Na expectativa de ocorrência de perda amostral, com consequente ocorrência de dados perdidos, recomenda-se ampliar o tamanho da amostra com um percentual correspondente a tal estimativa (ex.: 10%), embora ainda não corrija potenciais vieses pela perda.173 15.3.2 Que estratégias podem ser utilizadas na análise quando há dados perdidos? Na ocorrência de dados perdidos, a análise mais comum compreende apenas os ‘casos completos’, com exclusão de participantes com algum dado perdido nas variáveis do estudo. Em casos de grande quantidade de dados perdidos, pode-se perder muito poder estatístico (erro tipo II elevado).173 A análise de dados completos é válida quando pode-se argumentar que a probabilidade de o participante ter dados completos depende apenas das covariáveis e não dos desfechos.175 A análise de dados completos é eficiente quando todos os dados perdidos estão no desfecho, ou quando cada participante com dados perdidos nas covariáveis também possui dados perdidos nos desfechos.175 O pacote base103 fornece a função na.omit para remover dados perdidos de um objeto em um banco de dados. O pacote stats140 fornece a função complete.cases para identificar os casos completos - isto é, sem dados perdidos - em um banco de dados. 15.3.3 Que estratégias podem ser utilizadas na redação de estudos em que há dados perdidos? Informar: o número de participantes com dados perdidos; diferenças nas taxas de dados perdidos entre os braços do estudo; os motivos dos dados perdidos; o fluxo de participantes; quaisquer diferenças entre os participantes com e sem dados perdidos; o padrão de ausência (por exemplo, se é aleatória); os métodos para tratamento de dados perdidos das variáveis em análise; os resultados de quaisquer análises de sensibilidade; as implicações dos dados perdidos na interpretação do resultados.179 15.4 Dados imputados 15.4.1 O que são dados imputados? .REF? 15.4.2 Quando a imputação de dados é indicada? A análise com imputação de dados pode ser útil quando pode-se argumentar que os dados foram perdidos ao acaso (MAR); quando o desfecho foi observado e os dados perdidos estão nas covariáveis; e variáveis auxiliares — preditoras do desfecho e não dos dados perdidos — estão disponíveis.175 Na ocorrência de dados perdidos, a imputação de dados (substituição por dados simulados plausíveis preditos pelos dados presentes) pode ser uma alternativa para manter o erro tipo II estipulado no plano de análise.173 15.4.3 Quais são os métodos de imputação de dados? Modelos lineares e logísticos podem ser utilizados para imputar dados perdidos em variáveis contínuas e dicotômicas, respectivamente.180 Os métodos de imputação de dados mais robustos incluem a imputação multivariada por equações encadeadas (multivariate imputation by chained equations, MICE)181 e a correspondência média preditiva (predictive mean matching, PMM).182,183 Os pacotes mice181 e miceadds184 fornecem funções mice e mi.anova para imputação multivariada por equações encadeadas, respectivamente, para imputação de dados. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["dados-anonimizados-sinteticos.html", "Capítulo 16 Dados anonimizados e sintéticos 16.1 Dados anonimizados 16.2 Dados sintéticos", " Capítulo 16 Dados anonimizados e sintéticos 16.1 Dados anonimizados 16.1.1 O que são dados anonimizados? .REF? 16.1.2 Com anonimizar os dados de um banco? .REF? O pacote ids185 fornece a função random_id para criar identificadores aleatórios por criptografia. O pacote hash186 fornece a função hash para criar identificadores por objetos hash. O pacote anonimizer187 fornece a função anonymize para criar uma versão anônima de variáveis em um banco de dados. O pacote digest188 fornece a função digest para criar identificadores por objetos hash criptografados ou não. 16.2 Dados sintéticos 16.2.1 O que são dados sintéticos? .REF? O pacote synthpop189 fornece a função syn para criar bancos de dados sintéticos a partir de um banco de dados real. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["parte-5.html", "PARTE 5: ANÁLISES DESCRITIVAS E EXPLORATÓRIAS Primeiros passos na análise: descrever, visualizar e explorar padrões nos dados", " PARTE 5: ANÁLISES DESCRITIVAS E EXPLORATÓRIAS Primeiros passos na análise: descrever, visualizar e explorar padrões nos dados "],["analise-inicial.html", "Capítulo 17 Análise inicial de dados 17.1 Análise inicial de dados", " Capítulo 17 Análise inicial de dados 17.1 Análise inicial de dados 17.1.1 O que é análise inicial de dados? Análise inicial de dados190 é uma sequência de procedimentos que visam principalmente a transparência e integridade das pré-condições do estudo para conduzir a análise estatística apropriada de modo responsável para responder aos problemas da pesquisa.132 O objetivo da análise inicial de dados é propiciar dados prontos para análise estatística, incluindo informações confiáveis sobre as propriedades dos dados.132 A análise inicial de dados pode ser dividida nas seguintes etapas:132 Configuração dos metadados Limpeza dos dados Verificação dos dados Relatório inicial dos dados Refinamento e atualização do plano de análise estatística Documentação e relatório da análise inicial de dados A análise inicial de dados não deve ser confundida com análise exploratória,191 nem deve ser utilizada para hipotetizar após os dados serem coletados (conhecido como Hypothesizing After Results are Known, HARKing).63 17.1.2 Como conduzir uma análise inicial de dados? Desenvolva um plano de análise inicial de dados consistente com os objetivos da pesquisa. Por exemplo, verifique a distribuição e escala das variáveis, procure por observações não-usuais ou improváveis, avalie possíveis padrões de dados perdidos.132 Não altere diretamente os dados de uma tabela obtida de uma fonte. Use scripts para implementar eventuais alterações, de modo a manter o registro de todas as modificações realizadas no banco de dados.132 Use os metadados do estudo para guiar a análise inicial dos dados e compartilhe com os dados para maior transparência e reprodutibilidade.132 Representação gráfica dos dados pode ajudar a identificar características e padrões no banco de dados, tais como suposições e tendências.132 Verifique a frequência e proporção de dados perdidos em cada variável, e depois examine por padrões de dados perdidos simultaneamente por duas ou mais variáveis.132 Verifique a frequência e proporção de dados perdidos em cada variável, e depois examine por padrões de dados perdidos simultaneamente por duas ou mais variáveis.132 Exclusão de dados ad hoc baseada no desfecho pode influenciar os resultados do estudo, portanto os critérios de exclusão de dados antes da análise estatística (descritiva e/ou inferencial) devem ser reportados.192 17.1.3 Quais problemas podem ser detectados na análise inicial de dados? Ocorrência de dados perdidos, que podem ser excluídos ou imputados para não reduzir o poder do estudo.REF? O pacote stats140 fornece a função na.omit para retornar os dados sem os dados perdidos. O pacote stats140 fornece a função complete.cases para identificar os casos completos - isto é, sem dados perdidos - em um banco de dados. Registros duplicados, que devem ser excluídos para não inflar a amostra.193 O pacote base103 fornece a função duplicated para identificar elementos duplcados de um banco de dados. Codificação 0 ou 1 para variáveis dicotômicas para representar a direção esperada da associação entre elas.193 Ordenação cronológica de variáveis com registros temporais (retrospectivos ou prospectivos).193 A distribuição das variáveis para verificação das suposições das análises planejadas.193 Ocorrência de efeitos teto e piso nas variáveis.193 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["descricao.html", "Capítulo 18 Descrição 18.1 Análise de descrição 18.2 Estimação", " Capítulo 18 Descrição 18.1 Análise de descrição 18.1.1 O que é análise de descrição de dados? A análise descritiva utiliza métodos para calcular, descrever e resumir os dados coletados da(s) amostra(s) de modo que sejam interpretadas adequadamente.107 As análises descritivas geralmente compreendem a apresentação quantitativa (numérica) em tabelas e/ou gráficos.107 O pacote explore194 fornece a função explore para análise exploratória de um banco de dados. O pacote dataMaid195 fornece a função makeDataReport para criar um relatório de análise exploratória de um banco de dados. O pacote DataExplorer196 fornece a função create_report para criar um relatório de análise exploratória de um banco de dados. O pacote SmartEDA197 fornece a função ExpReport para criar um relatório de análise exploratória de um banco de dados. O pacote esquisse198 fornece a função esquisser para executar uma interface interativa para visualização de dados. 18.2 Estimação 18.2.1 O que é estimativa? Estimativa é o valor de uma variável de interesse calculado a partir de uma amostra.REF? 18.2.2 O que é estimativa pontual? Estimativa pontual é o valor único de uma variável de interesse calculado a partir de uma amostra.REF? 18.2.3 O que é estimativa intervalar? Estimativa intervalar é um intervalo de valores de uma variável de interesse calculado a partir de uma amostra.REF? 18.2.4 O que é estimativa de parâmetro? Estimativa de parâmetro é o valor de uma variável de interesse calculado a partir de uma amostra que representa o valor da população.REF? /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["analise-exploratoria.html", "Capítulo 19 Análise exploratória de dados 19.1 Análise exploratória de dados 19.2 Ingredientes da análise exploratória de dados", " Capítulo 19 Análise exploratória de dados 19.1 Análise exploratória de dados 19.1.1 O que é análise exploratória de dados? Análise exploratória de dados consiste em um processo iterativo de elaboração e interpretação da síntese de dados, tabelas e gráficos, considerando os aspectos teóricos do estudo.191 Análise exploratória deve ser separada da análise inferencial de testes de hipóteses; a decisão sobre os modelos a testar deve ser feita a priori.199 19.1.2 Quais são os objetivos centrais da análise exploratória de dados? A análise exploratória de dados (EDA) tem dois objetivos principais: (a) descrição dos dados e (b) formulação de modelos. A descrição envolve resumir os dados e destacar características essenciais, enquanto a formulação de modelos auxilia na geração de hipóteses e na escolha de procedimentos estatísticos adequados.190 19.1.3 Por que conduzir a análise exploratória de dados? A condução de análise exploratória de dados pode ajudar a identificar padrões e pode orientar trabalhos futuros, mas os resultados não devem ser interpretados como inferências sobre uma população.199 A análise exploratória não deve ser usada para definir as questões e hipóteses científicas do estudo.199 O pacote explore194 fornece a função explore para análise exploratória de um banco de dados. O pacote dataMaid195 fornece a função makeDataReport para criar um relatório de análise exploratória de um banco de dados. O pacote DataExplorer196 fornece a função create_report para criar um relatório de análise exploratória de um banco de dados. O pacote SmartEDA197 fornece a função ExpReport para criar um relatório de análise exploratória de um banco de dados. O pacote gtExtras200 fornece a função gt_plt_summary para criar uma tabela descritiva síntese com histogramas ou gráficos de barra a partir de um banco de dados. O pacote radiant201 fornece a função radiant para executar uma interface interativa para análise exploratória de dados. 19.2 Ingredientes da análise exploratória de dados 19.2.1 Quais são os principais elementos que compõem a análise exploratória de dados? Verificação da qualidade dos dados (erros, ausências, outliers), o cálculo de estatísticas descritivas (média, desvio-padrão, intervalos, correlações) e o uso de representações gráficas como histogramas, diagramas de dispersão, boxplots e gráficos de séries temporais.190 Técnicas multivariadas exploratórias, como análise de componentes principais e análise de clusters, podem revelar padrões em dados complexos.190 19.2.2 Quais etapas constituem a análise exploratória de dados? Cada combinação de problema de pesquisa e delineamento de estudo pode demandar um plano de análise exploratório distinto.199 Verifique a existência e/ou influência de valores discrepantes (“fora da curva” ou outliers):190,191,199 Boxplots Gráficos quantil-quantil (Q-Q) A análise exploratória valoriza o uso de gráficos interativos e técnicas de brushing e linking, que permitem explorar padrões ocultos, relacionar múltiplas variáveis e destacar subconjuntos de observações.202 O pacote ggplot2155 fornece a função geom_boxplot para construção de gráficos boxplot. Verifique a homocedasticidade (homogeneidade da variância):199 Boxplots condicionais (por fator de análise) Análise dos resíduos do modelo de regressão Gráfico resíduos vs. valores ajustados Verifique a normalidade da distribuição dos dados:190,199 Histograma das variáveis (por fator de análise) Histograma dos resíduos da regressão Verifique a existência de grande quantidade de valores nulos (=0):199 Histograma das variáveis (por fator de análise) Verifique a existência de colinearidade entre variáveis independentes de um modelo de regressão:199 Fator de inflação de variância (variance inflation factor, VIF) Coeficiente de correlação de Pearson (\\(r\\)) Gráfico de dispersão entre variáveis Verifique possíveis relações entre as variáveis dependente(s) e independente(s) de um modelo de regressão:199 Gráfico de dispersão entre variáveis independente e dependente Verifique possíveis interações entre as variáveis dependente(s) de um modelo de regressão:199 Gráfico coplot de dispersão entre variáveis dependentes O pacote ggcleveland203 fornece a função gg_coplot para construção de gráficos boxplot condicionais. Verifique por dependência entre variáveis de um modelo de regressão:199 Gráfico de série temporal das variáveis Gráfico de autocorrelação entre as variáveis Medidas como mediana, trimean, distância absoluta mediana e procedimentos de winsorizing ou trimming são preferidos, pois reduzem a influência de valores extremos e oferecem resumos mais fiéis202. A análise exploratória adota o esquema dados = ajuste + resíduo, no qual o analista ajusta modelos provisórios, examina resíduos e refina os modelos em ciclos sucessivos de aproximação.202 Valores discrepantes (outliers) não devem ser ignorados; eles podem indicar erros de coleta ou fenômenos relevantes. Fringeliers, casos menos extremos mas recorrentes, também merecem atenção.202 Transformar variáveis em novas formas (por exemplo, log ou inverso) pode revelar simetrias ocultas e tornar relações mais claras e lineares.202 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["analise-descritiva.html", "Capítulo 20 Análise descritiva 20.1 Análise descritiva 20.2 Apresentação de resultados numéricos 20.3 Tabelas 20.4 Tabela 1 20.5 Tabela 2 20.6 Visualização efetiva de dados 20.7 Gráficos 20.8 Tipos de gráficos 20.9 Gráficos dinâmicos", " Capítulo 20 Análise descritiva 20.1 Análise descritiva 20.1.1 O que é análise descritiva? Análise descritiva é usada para compreendermos algum aspecto de um conjunto de dados, respondendo a perguntas do tipo “quando?”, “onde?”, “quem?”, “o quê?”, “como?” e “e daí?”.107,204 O pacote base103 fornece a função summary para calcular diversos parâmetros descritivos. 20.1.2 Como apresentar os resultados descritivos? Variáveis categóricas: Reporte valores de frequência absoluta e relativa (n, percentual).205 Organização das tabelas: as variáveis são exibidas em linhas e os grupos são exibidos em colunas.205 Calcule percentagens para as colunas (isto é, entre grupos) e não entre linhas.205 Em caso de dados perdidos, não inclua uma linha com total de dados perdidos, pois distorce as proporções entre colunas e as análises de tabela de contingência. Indique no texto ou em uma coluna separada o total de dados perdidos por variável.205 20.2 Apresentação de resultados numéricos 20.2.1 O que são casas decimais? O número de casas decimais refere-se à quantidade de dígitos que aparecem após a vírgula decimal.206,207 Para tamanhos de efeito: use 2–3 dígitos significativos.208 Para medidas de variabilidade (SD/SE/IC): use 1–2 dígitos significativos.208 20.2.2 O que são dígitos significativos? O termo “dígitos significativos” é preferido a “algarismos significativos” ou “dígitos efetivos” e não se relaciona com significância estatística.206,207 O número de dígitos significativos é a soma total de dígitos, desconsiderando a vírgula decimal e os zeros à esquerda; os zeros à direita são considerados informativos, salvo exceções.206,207 20.2.3 Como arredondar dados numéricos? Apresentar dados com quantidade excessiva de casas decimais pode dificultar a interpretação e induzir erroneamente uma precisão espúria.206,207 A precisão é determinada pelo grau de arredondamento aplicado, medido em casas decimais ou dígitos significativos.206,207 Tabela 20.1: Quantidade de casas decimais e dígitos significativos. Valor Casas Decimais Dígitos Significativos 0,00789 5 0 0,0456 4 0 45,6 1 2 123,456 3 3 7890,0000 4 4 O arredondamento também introduz erros, uma vez que aumenta a imprecisão (isto é, incerteza) em torno do valor original.206,207 Tabela 20.2: Valores originais, arredondamentos e erros de arredondamento por casas decimais. Valor Casas Decimais Dígitos Significativos 2 Casas decimais [Margem de erro] 1 Casa decimal [Margem de erro] Sem casa decimal [Margem de erro] 0,00789 5 0 0,01 [0,005, 0,015] 0,0 [-0,05, 0,05] 0 [-0,5, 0,5] 0,0456 4 0 0,05 [0,045, 0,055] 0,0 [-0,05, 0,05] 0 [-0,5, 0,5] 45,6 1 2 45,60 [45,595, 45,605] 45,6 [45,55, 45,65] 46 [45,5, 46,5] 123,456 3 3 123,46 [123,455, 123,465] 123,5 [123,45, 123,55] 123 [122,5, 123,5] 7890,0000 4 4 7890,00 [7889,995, 7890,005] 7890,0 [7889,95, 7890,05] 7890 [7889,5, 7890,5] A regra geral é utilizar 2 ou 3 dígitos significativos para tamanhos de efeito e 1 ou 2 dígitos significativos para medidas de variabilidade.207 Regra dos 3 dígitos significativos para proporção de risco: em média, o erro de arredondamento é menor que os 0,5% exigidos, de modo que três dígitos significativos são mais precisos do que o necessário.206 Regra dos 4 dígitos significativos para proporção de risco: divida a proporção de risco por quatro e arredonde para dois dígitos significativos e, em seguida, relate a proporção para esse número de casas decimais.206 20.3 Tabelas 20.3.1 Por que usar tabelas? Tabelas complementam o texto (e vice-versa), e podem apresentar os dados de modo mais acessível e informativo.209 20.3.2 Que informações incluir nas tabelas? Título ou legenda, uma síntese descritiva (geralmente por meio de parâmetros descritivos), intervalos de confiança e/ou P-valores conforme necessário para adequada interpretação.209,210 20.3.3 Quais são os tipos de tabelas? Tabela de frequência: apresenta a quantidade de ocorrências (frequência absoluta e relativa) de cada categoria de uma variável; usada com variáveis qualitativas ou quantitativas discretas.REF? Tabela de frequência agrupada: organiza dados contínuos em intervalos de classe (ex: faixas etárias) e mostra as frequências correspondentes.REF? Tabela de contingência (ou tabela cruzada): cruza duas variáveis categóricas, permitindo observar possíveis associações entre elas.REF? Tabela de medidas descritivas: resume variáveis quantitativas com estatísticas como média, mediana, desvio-padrão, mínimo, máximo e quartis.REF? Tabela de comparação entre grupos: apresenta médias, desvios-padrão e ocasionalmente resultados de testes de inferência estatística para comparar dois ou mais grupos.REF? Tabela de resultados de testes estatísticos: exibe valores de estatísticas de teste , P valores e intervalos de confiança; usada para mostrar inferências.REF? Tabela de regressão (ou de modelos estatísticos): mostra os coeficientes de regressão, erros padrão, intervalos de confiança e P valores para cada variável de um modelo.REF? Tabela de séries temporais ou longitudinais: organiza dados medidos em diferentes momentos no tempo, permitindo visualizar tendências ou variações longitudinais.REF? O pacote gtsummary211 fornece a função tbl_summary para construção da ‘Tabela 1’ com dados descritivos. O pacote table1212 fornece a função table1 para construção de tabelas. O pacote flextable213 fornece as funções flextable, as_flextable e save_as_docx para criar e salvar tabelas formatadas em DOCX. O pacote rempsyc214 fornece a função nice_table para criar tabelas formatadas. 20.3.4 Quais são os erros mais comuns de preenchimento de tabelas? Erros tipográficos.215 Ausência de rótulos ou unidades nas variáveis.215 Relatar estatísticas incorretamente, tais como rotular variáveis contínuas como porcentagens.215 Estatísticas descritivas de tendência central (ex.: médias) relatadas sem a estatística de dispersão correspondente (ex.: desvio-padrão).215 Desvio-padrão nulo (\\(\\sigma=0\\)).215 Valores porcentuais que não correspondem ao numerador dividido pelo denominador.215 20.4 Tabela 1 20.4.1 O que é a ‘Tabela 1’? A ‘Tabela 1’ descreve as características demográficas, sociais e clínicas da amostra, completa ou agrupada por algum fator, geralmente por meio de parâmetros de tendência central e dispersão.216,217 20.4.2 Qual a utilidade da ‘Tabela 1’? Descrever (conhecer) as características da amostra e dos grupos sendo comparados, quando aplicável.217 Verificar aderência ao protocolo do estudo, incluindo critérios de inclusão/exclusão, tamanho da amostra e perdas amostrais.217 Permitir a replicação do estudo.217 Meta-analisar os dados junto a estudos similares.217 Avaliar a generalização (validade externa) das conclusões do estudo.217 20.4.3 O que é a falácia da ‘Tabela 1’? Falácia da Tabela 1 ocorre pela interpretação errônea dos P-valores na comparação entre grupos, na linha de base, de um ensaio clínico aleatorizado.218 Não interprete P da linha de base em ensaios clínicos como “desequilíbrio” (falácia da Tabela 1). Mantenha P-valor apenas como descritivo (ou omita), enfatizando desenho e aleatorização.208 20.4.4 Como construir a ‘Tabela 1’? A Tabela 1 geralmente é utilizada para descrever as características da amostra estudada, possibilitando a análise de ameaças à validade interna e/ou externa ao estudo.159,219 O pacote table1212 fornece a função table1 para construção de tabelas. O pacote gtsummary211 fornece a função tbl_summary para construção da ‘Tabela 1’ com dados descritivos. #mlvuytmmcw table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #mlvuytmmcw thead, #mlvuytmmcw tbody, #mlvuytmmcw tfoot, #mlvuytmmcw tr, #mlvuytmmcw td, #mlvuytmmcw th { border-style: none; } #mlvuytmmcw p { margin: 0; padding: 0; } #mlvuytmmcw .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mlvuytmmcw .gt_caption { padding-top: 4px; padding-bottom: 4px; } #mlvuytmmcw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mlvuytmmcw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mlvuytmmcw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mlvuytmmcw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mlvuytmmcw .gt_column_spanner_outer:first-child { padding-left: 0; } #mlvuytmmcw .gt_column_spanner_outer:last-child { padding-right: 0; } #mlvuytmmcw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mlvuytmmcw .gt_spanner_row { border-bottom-style: hidden; } #mlvuytmmcw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #mlvuytmmcw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mlvuytmmcw .gt_from_md > :first-child { margin-top: 0; } #mlvuytmmcw .gt_from_md > :last-child { margin-bottom: 0; } #mlvuytmmcw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mlvuytmmcw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mlvuytmmcw .gt_row_group_first td { border-top-width: 2px; } #mlvuytmmcw .gt_row_group_first th { border-top-width: 2px; } #mlvuytmmcw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mlvuytmmcw .gt_first_summary_row.thick { border-top-width: 2px; } #mlvuytmmcw .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mlvuytmmcw .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mlvuytmmcw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_left { text-align: left; } #mlvuytmmcw .gt_center { text-align: center; } #mlvuytmmcw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mlvuytmmcw .gt_font_normal { font-weight: normal; } #mlvuytmmcw .gt_font_bold { font-weight: bold; } #mlvuytmmcw .gt_font_italic { font-style: italic; } #mlvuytmmcw .gt_super { font-size: 65%; } #mlvuytmmcw .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #mlvuytmmcw .gt_asterisk { font-size: 100%; vertical-align: 0; } #mlvuytmmcw .gt_indent_1 { text-indent: 5px; } #mlvuytmmcw .gt_indent_2 { text-indent: 10px; } #mlvuytmmcw .gt_indent_3 { text-indent: 15px; } #mlvuytmmcw .gt_indent_4 { text-indent: 20px; } #mlvuytmmcw .gt_indent_5 { text-indent: 25px; } #mlvuytmmcw .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #mlvuytmmcw div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Tabela 20.3: Características da amostra por grupo. Características N Controle N = 1031 Intervenção N = 971 Valor-p2 Sexo 200 0.060     F 49 (48%) 59 (61%)     M 54 (52%) 38 (39%) Idade 200 0.8     Média (Desvio Padrão) 61 (12) 60 (12)     Mediana [Q1, Q3] 61 [53, 69] 60 [53, 69] IMC 200 0.2     Média (Desvio Padrão) 26.8 (3.7) 27.5 (4.0)     Mediana [Q1, Q3] 26.6 [24.5, 29.7] 27.6 [25.6, 29.9] 1 n (%) 2 Teste qui-quadrado de independência; Teste de soma de postos de Wilcoxon 20.5 Tabela 2 20.5.1 Qual a utilidade da ‘Tabela 2’? A Tabela 2 mostra associações ajustadas multivariadas com o resultado para variáveis resumidas na Tabela 1.216 20.5.2 O que é a falácia da ‘Tabela 2’? A Tabela 2 pode induzir ao erro de interpretação pelas estimativas de efeitos para covariáveis do modelo também serem utilizados para controlar a confusão da exposição.216,220 Ao apresentar estimativas de efeito ajustadas para covariáveis juntamente com a estimativa de efeito ajustada para a exposição primária, a Tabela 2 sugere implicitamente que todas estas estimativas podem ser interpretadas de forma semelhante, se não de forma idêntica, como estimativa do efeito total.216,220 A falácia da Tabela 2 pode ser evitada limitando-se a tabela a estimativas das medidas primárias do efeito de exposição nos diferentes modelos, com as covariáveis secundárias de “ajuste” relatadas em uma nota de rodapé, juntamente com a forma como foram categorizadas ou modeladas.216 #mlvuytmmcw table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #mlvuytmmcw thead, #mlvuytmmcw tbody, #mlvuytmmcw tfoot, #mlvuytmmcw tr, #mlvuytmmcw td, #mlvuytmmcw th { border-style: none; } #mlvuytmmcw p { margin: 0; padding: 0; } #mlvuytmmcw .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mlvuytmmcw .gt_caption { padding-top: 4px; padding-bottom: 4px; } #mlvuytmmcw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mlvuytmmcw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mlvuytmmcw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mlvuytmmcw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mlvuytmmcw .gt_column_spanner_outer:first-child { padding-left: 0; } #mlvuytmmcw .gt_column_spanner_outer:last-child { padding-right: 0; } #mlvuytmmcw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mlvuytmmcw .gt_spanner_row { border-bottom-style: hidden; } #mlvuytmmcw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #mlvuytmmcw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mlvuytmmcw .gt_from_md > :first-child { margin-top: 0; } #mlvuytmmcw .gt_from_md > :last-child { margin-bottom: 0; } #mlvuytmmcw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mlvuytmmcw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mlvuytmmcw .gt_row_group_first td { border-top-width: 2px; } #mlvuytmmcw .gt_row_group_first th { border-top-width: 2px; } #mlvuytmmcw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mlvuytmmcw .gt_first_summary_row.thick { border-top-width: 2px; } #mlvuytmmcw .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mlvuytmmcw .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mlvuytmmcw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_left { text-align: left; } #mlvuytmmcw .gt_center { text-align: center; } #mlvuytmmcw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mlvuytmmcw .gt_font_normal { font-weight: normal; } #mlvuytmmcw .gt_font_bold { font-weight: bold; } #mlvuytmmcw .gt_font_italic { font-style: italic; } #mlvuytmmcw .gt_super { font-size: 65%; } #mlvuytmmcw .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #mlvuytmmcw .gt_asterisk { font-size: 100%; vertical-align: 0; } #mlvuytmmcw .gt_indent_1 { text-indent: 5px; } #mlvuytmmcw .gt_indent_2 { text-indent: 10px; } #mlvuytmmcw .gt_indent_3 { text-indent: 15px; } #mlvuytmmcw .gt_indent_4 { text-indent: 20px; } #mlvuytmmcw .gt_indent_5 { text-indent: 25px; } #mlvuytmmcw .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #mlvuytmmcw div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Tabela 20.4: Tabela 2. (Exemplo clássico suscetível à Falácia da Tabela 2). Características Sem ajuste Ajustado OR 95% IC Valor-p OR 95% IC Valor-p Grupo     Controle — — — —     Intervenção 1.71 0.98, 3.02 0.061 1.70 0.97, 3.03 0.067 Idade 1.02 1.00, 1.05 0.087 IMC 1.05 0.97, 1.13 0.2 Abreviações: IC = Intervalo de Confiança, OR = Razão de chances 20.5.3 Como construir a ‘Tabela 2’? A Tabela 2 pode ser utilizada para apresentar estimativas de múltiplos efeitos ajustados de um mesmo modelo estatístico.216 #mlvuytmmcw table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #mlvuytmmcw thead, #mlvuytmmcw tbody, #mlvuytmmcw tfoot, #mlvuytmmcw tr, #mlvuytmmcw td, #mlvuytmmcw th { border-style: none; } #mlvuytmmcw p { margin: 0; padding: 0; } #mlvuytmmcw .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mlvuytmmcw .gt_caption { padding-top: 4px; padding-bottom: 4px; } #mlvuytmmcw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mlvuytmmcw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mlvuytmmcw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mlvuytmmcw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mlvuytmmcw .gt_column_spanner_outer:first-child { padding-left: 0; } #mlvuytmmcw .gt_column_spanner_outer:last-child { padding-right: 0; } #mlvuytmmcw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mlvuytmmcw .gt_spanner_row { border-bottom-style: hidden; } #mlvuytmmcw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #mlvuytmmcw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mlvuytmmcw .gt_from_md > :first-child { margin-top: 0; } #mlvuytmmcw .gt_from_md > :last-child { margin-bottom: 0; } #mlvuytmmcw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mlvuytmmcw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mlvuytmmcw .gt_row_group_first td { border-top-width: 2px; } #mlvuytmmcw .gt_row_group_first th { border-top-width: 2px; } #mlvuytmmcw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mlvuytmmcw .gt_first_summary_row.thick { border-top-width: 2px; } #mlvuytmmcw .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mlvuytmmcw .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mlvuytmmcw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mlvuytmmcw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mlvuytmmcw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mlvuytmmcw .gt_left { text-align: left; } #mlvuytmmcw .gt_center { text-align: center; } #mlvuytmmcw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mlvuytmmcw .gt_font_normal { font-weight: normal; } #mlvuytmmcw .gt_font_bold { font-weight: bold; } #mlvuytmmcw .gt_font_italic { font-style: italic; } #mlvuytmmcw .gt_super { font-size: 65%; } #mlvuytmmcw .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #mlvuytmmcw .gt_asterisk { font-size: 100%; vertical-align: 0; } #mlvuytmmcw .gt_indent_1 { text-indent: 5px; } #mlvuytmmcw .gt_indent_2 { text-indent: 10px; } #mlvuytmmcw .gt_indent_3 { text-indent: 15px; } #mlvuytmmcw .gt_indent_4 { text-indent: 20px; } #mlvuytmmcw .gt_indent_5 { text-indent: 25px; } #mlvuytmmcw .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #mlvuytmmcw div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Tabela 20.5: Tabela 2. Exposição (OR; 95% IC) com e sem ajuste. Características Sem ajuste Ajustado OR 95% IC Valor-p OR 95% IC Valor-p Grupo     Controle — — — —     Intervenção 1.71 0.98, 3.02 0.061 1.70 0.97, 3.03 0.067 Abreviações: IC = Intervalo de Confiança, OR = Razão de chances Nota. Modelo ajustado por Idade (contínua) e IMC (contínuo). Covariáveis são usadas apenas para controle de confusão e não devem ser interpretadas como efeitos causais (Falácia da Tabela 2). O pacote table1212 fornece a função table1 para construção de tabelas. O pacote gtsummary211 fornece a função tbl_summary para construção da ‘Tabela 1’ com dados descritivos. 20.6 Visualização efetiva de dados 20.6.1 Por que começar pela mensagem antes do gráfico? A figura deve responder a uma pergunta clara (comparação? tendência? composição?) e isso orienta a escolha do tipo de gráfico, dados e anotações. Esboce a mensagem e a pergunta antes de abrir o software.221 20.6.2 Como escolher a geometria e “mostrar os dados”? Prefira geometrias que revelem distribuição/variabilidade (pontos, boxplots, violinos) em vez de médias sozinhas. Sempre que possível, exiba os dados brutos (pontos com jitter) junto da estatística-resumo.221 Figura 20.1: Exemplo de gráfico que mostra os dados brutos junto com um resumo estatístico (média e dispersão). 20.7 Gráficos 20.7.1 O que são gráficos? Gráficos são utilizados para apresentar dados (geralmente em grande quantidade) de modo mais intuitivo e fácil de compreender.222 20.7.2 O que torna um bom gráfico tão poderoso? “Não há ferramenta estatística tão poderosa quanto um gráfico bem escolhido”: gráficos ajudam a explorar dados, comunicar resultados e suportar decisões de forma clara e rápida.223 20.7.3 Que elementos incluir em gráficos? Título, eixos horizontal e vertical com respectivas unidades, escalas em intervalos representativos das variáveis, legenda com símbolos, síntese descritiva dos valores e respectiva margem de erro, conforme necessário para adequada interpretação.222 20.7.4 Para que servem as barras de erro em gráficos? Barras de erro ajudam ao autor a apresentar as informações que descrevem os dados (por exemplo, em uma análise descritiva) ou sobre as inferências ou conclusões tomadas a partir de dados.166,168 Barras de erro mais longas representam mais imprecisão (maiores erros), enquanto barras mais curtas representam mais precisão na estimativa.168 Barras de erro descritivas geralmente apresentam a amplitude (mínimo-máximo) ou desvio-padrão.168 Barras de erro inferenciais geralmente apresentam o erro-padrão ou intervalo de confiança no nível de significância \\(\\alpha\\) pré-estabelecido.166,168 Barras de erro com desvio-padrão são úteis para descrever a variabilidade dos dados, enquanto as barras de erro com erro padrão da média são úteis para descrever a precisão do parâmetro estimado (média) e sua relação com o tamanho da amostra.166 Barras de erro com intervalo de confiança são úteis para fornecer uma estimativa da incerteza da estimativa do parâmetro populacional.166 O comprimento das barras de erro sugere graficamente a imprecisão dos dados do estudo, uma vez que o valor verdadeiro da população pode estar em qualquer nível do intervalo da barra.168 De modo contraintuitivo, um espaço entre as barras não garante significância, nem a sobreposição a descarta—depende do tipo de barra.166 Para amostras pequenas é preferível apresentar os dados brutos, uma vez que as barras de erro não serão muito informativas.166 Figura 20.2: Exemplos de gráficos com barras de erro e dados brutos. Figura 20.3: Exemplos de gráficos com barras de erro e dados brutos em diferentes cenários. Os pacotes ggplot2155, plotly224 e corrplot225 fornecem diversas funções para construção de gráficos tais como ggplot, plot_ly e corrplot respectivamente. 20.7.5 Quais são os principais obstáculos para bons gráficos? Dificuldade técnica, negligência no ensino tradicional e o foco em “beleza” sem clareza podem levar a gráficos ruins, mesmo quando bem intencionados.223 20.8 Tipos de gráficos 20.8.1 Quais são os tipos de gráficos para variáveis categóricas? Gráfico de barras: Mais usado para comparar frequências absolutas ou relativas entre categorias.REF? Figura 20.4: Gráfico de barras simples representando frequências por categoria. Gráfico de barras empilhadas: Útil para comparar proporções entre grupos em mais de uma variável categórica.REF? Figura 20.5: Gráfico de barras empilhadas representando frequências por categoria. Figura 20.6: Gráficos de barras represetando médias, barras de erro e dados individuais. 20.8.2 Quais são os tipos de gráficos para variáveis numéricas? Histograma: Distribuição de frequência de uma variável contínua. Mostra a forma da distribuição (simétrica, assimétrica, bimodal).REF? Figura 20.7: Histograma da variável ‘valor’. Gráfico de densidade: Similar ao histograma, mas mais suave. Útil para avaliar a distribuição.REF? Figura 20.8: Gráfico de densidade da variável ‘valor’. Diagrama de caixa (boxplot): Resume mediana, quartis e valores extremos. Excelente para comparar grupos.REF? Figura 20.9: Boxplot por grupo. Gráfico de violino: Combina boxplot e densidade, mostrando a distribuição da variável. Útil para comparar grupos.REF? Figura 20.10: Violin plot por grupo. Gráfico de pontos (dot plot): Mostra cada valor individualmente, útil para pequenas amostras e para visualizar a distribuição.REF? Figura 20.11: Gráfico de pontos da variável ‘valor’. 20.8.3 Quais são os tipos de gráficos para relações entre variáveis? Gráfico de dispersão (scatter plot): Mostra a relação entre duas variáveis quantitativas. Ideal para investigar correlações.REF? Figura 20.12: Gráfico de dispersão representando a relação entre duas variáveis. Gráfico de bolhas (bubble chart): Expande o gráfico de dispersão adicionando uma terceira variável (tamanho da bolha).REF? Figura 20.13: Gráfico de bolhas representando a relação entre três variáveis. Sankey plot: Visualiza fluxos entre categorias em diferentes etapas ou grupos. Útil para mostrar proporções e transições.REF? Figura 20.14: Sankey plot representando fluxos entre categorias. 20.8.4 Quais são os tipos de gráficos para dados longitudinais? Gráfico de spaghetti: Mostra trajetórias individuais ao longo do tempo, útil para dados longitudinais.REF? Figura 20.15: Gráfico spaghetti representando dados longitudinais. 20.8.5 Quais são os tipos de gráficos para séries temporais? Gráfico de linhas: Mostra a evolução de uma variável ao longo do tempo, com pontos conectados por linhas.REF? Figura 20.16: Gráfico de linha representando uma série temporal. 20.8.6 Quais são os tipos de gráficos para dados multivariados? Gráfico de dispersão: Representa a relação entre duas variáveis, com pontos e uma linha de tendência.REF? Figura 20.17: Gráfico de correlação entre duas variáveis com linha de tendência. Gráfico de matriz de dispersão: Mostra relações entre múltiplas variáveis quantitativas, útil para identificar padrões.REF? Figura 20.18: Matriz de dispersão representando relações entre múltiplas variáveis. Gráfico de calor (heatmap): Representa dados em uma matriz, com cores indicando intensidade ou frequência.REF? Figura 20.19: Mapa de calor da correlação entre variáveis. Gráfico de radar (ou gráfico de aranha): Representa várias variáveis em um único gráfico, útil para comparar perfis.REF? Figura 20.20: Gráfico radar representando múltiplas variáveis. 20.8.7 Quais são as boas práticas na elaboração de gráficos? O tamanho da amostra total e subgrupos, se houver, deve estar descrito na figura ou na sua legenda.168 Para análise inferencial de figuras, as barras de erro representadas por erro-padrão ou intervalo de confiança no nível de significância \\(\\alpha\\) pré-estabelecido são preferíveis à amplitude ou desvio-padrão.166,168 Evite gráficos de barra e mostre a distribuição dos dados sempre que possível.208 Exiba os pontos de dados em boxplots.208 Use jitter simétrico em gráficos de pontos para permitir a visualização de todos os dados.208 Prefira palhetas de cor adaptadas para daltônicos.208 Uma boa legenda torna a figura autossuficiente: descreva amostra (n), geometrias, métricas de incerteza, escalas/unidades e mensagem principal. Se houver modelo, indique fórmula/ajustes em nota.221 Evite gráficos de barras com médias para variáveis contínuas; prefira pontos/box/violino e, em amostras pequenas, exiba todos os dados.208 Antes de finalizar um gráfico, faça as seguintes perguntas: (1) Mensagem está explícita? (2) Geometria adequada e dados visíveis? (3) Incerteza correta e rotulada? (4) Cores informativas e acessíveis? (5) Escalas comparáveis (se facetou)? (6) Legenda/caption autossuficiente? (7) Diferença clara entre dados e modelos? (8) Arquivo exportado na resolução/tamanho exigidos?221 O pacote ggsci226 fornece palhetas de cores tais como pal_lancet, pal_nejm e pal_npg inspiradas em publicações científicas para uso em gráficos. O pacote grDevices154 fornece a função dev.new para controlar diversos aspectos do gráfico, tais como tamanho e resolução. O pacote tiff227 fornece a função writeTIFF para exportar gráficos em formato TIFF. 20.9 Gráficos dinâmicos 20.9.1 O que são visualizações dinâmicas? Visualizações dinâmicas combinam interatividade (exploração ativa pelo leitor) e animação (mudanças ao longo do tempo/iterações) para empacotar informação rica em exibições simples, tornando comunicação e exploração mais transparentes.228 20.9.2 Quando preferir interatividade? Durante exploração de dados em equipe: destacar pontos/linhas por participante, filtrar subconjuntos e inspecionar impactos de escolhas analíticas (p.ex., outliers) sem gerar múltiplas figuras novas.228 Figura 20.21: Exemplo de gráfico interativo com Plotly. O pacote plotly224 fornece a função plot_ly para gerar gráficos interativos. 20.9.3 Quando preferir animação? Em apresentações e para ilustrar variação ao longo de tempo/condição/algoritmo, evitando painéis 3D ou facets excessivos. A animação guia a atenção e revela mudanças de forma passiva e fluida.228 O pacote gganimate229 fornece a função transition_states para criar gráficos animados a partir de gráficos estáticos do ggplot2155. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["analise-robusta.html", "Capítulo 21 Análise robusta 21.1 Raciocínio inferencial robusto 21.2 Valores discrepantes 21.3 Valores influentes 21.4 Métodos robustos de tratamento de outliers", " Capítulo 21 Análise robusta 21.1 Raciocínio inferencial robusto 21.1.1 O que é análise robusta? Análise robusta é uma abordagem estatística que busca fornecer resultados confiáveis mesmo quando as suposições clássicas dos modelos estatísticos são violadas, como normalidade e homocedasticidade. Ela utiliza métodos que são menos sensíveis a outliers e outras irregularidades nos dados.230 21.1.2 Por que usar análise robusta? Métodos clássicos como ANOVA e regressão por mínimos quadrados assumem normalidade e homocedasticidade — suposições frequentemente violadas na prática. Violações dessas suposições podem comprometer os resultados, reduzindo o poder estatístico, distorcendo os intervalos de confiança e obscurecendo as reais diferenças entre grupos.230 Testar previamente as suposições não é suficiente: testes de homocedasticidade têm baixo poder e não garantem segurança analítica.230 Métodos estatísticos robustos oferecem uma solução mais segura e eficaz, lidando melhor com dados não ideais.230 21.1.3 Quando usar análise robusta? Em alguns casos, os métodos robustos confirmam os resultados clássicos; em outros, revelam interpretações completamente diferentes. A única forma de saber o impacto real dos métodos robustos é usá-los e comparar com os métodos tradicionais.230 Mínimos e máximos são parâmetros descritivos, mas em certas condições podem se tornar discrepantes ou influentes, distorcendo análises. Nesses casos, a análise robusta oferece alternativas mais seguras.REF? 21.1.4 Por que métodos robustos são preferíveis? Métodos robustos têm a vantagem de resistir à influência de valores extremos, fornecendo medidas de posição e dispersão mais estáveis.172 Estimadores robustos oferecem maior segurança na presença de até 50% de contaminação nos dados, o que representa um ganho significativo em relação aos métodos clássicos.172 21.2 Valores discrepantes 21.2.1 O que são valores discrepantes (outliers)? Em termos gerais, um valor discrepante - “fora da curva” ou outlier - é uma observação que possui um valor relativamente grande ou pequeno em comparação com a maioria das observações.199 Um valor discrepante é uma observação incomum que exerce influência indevida em uma análise.199 Valores discrepantes são dados com valores altos de resíduos.170 Nem todo valor extremo é um valor discrepante, e nem todo valor discrepante será influente.REF? Alguns valores discrepantes são apenas pontos incomuns, outros de fato mudam os resultados e por isso são chamados de influentes.REF? Figura 21.1: Regressão linear com valores discrepantes 21.2.2 Quais são os tipos de valores discrepantes? Valores discrepantes podem ser categorizados em três subtipos: outliers de erro, outliers interessantes e outliers aleatórios.170 Os valores discrepantes de erro são observações claramente não legítimas, distantes de outros dados devido a imprecisões por erro de mensuração e/ou codificação.170 Os valores discrepantes interessantes não são claramente erros, mas podem refletir um processo/mecanismo potencialmente interessante para futuras pesquisas.170 Os valores discrepantes aleatórios são observações que resultam por acaso, sem qualquer padrão ou tendência conhecida.170 Valores discrepantes podem ser univariados ou multivariados.170 21.2.3 Por que é importante avaliar valores discrepantes? Excluir o valor discrepante implica em reduzir inadequadamente a variância, ao remover um valor que de fato pertence à distribuição considerada.170 Manter os dados inalterados (mantendo o valor discrepante) implica em aumentar inadequadamente a variância, pois a observação não pertence à distribuição que fundamenta o experimento.170 Em ambos os casos, uma decisão errada pode influenciar o erro do tipo I (\\(\\alpha\\) — rejeitar uma hipótese verdadeira) ou o erro do tipo II (\\(\\beta\\) — não rejeitar uma hipótese falsa).170 21.2.4 Como detectar valores discrepantes? Na maioria das vezes, não há como saber de qual distribuição uma observação provém. Por isso, não é possível ter certeza se um valor é legítimo ou não dentro do contexto do experimento.170 Recomenda-se seguir um procedimento em duas etapas: detectar possíveis candidatos a outliers usando ferramentas quantitativas; e gerenciar os outliers, decidindo manter, remover ou recodificar os valores, com base em informações qualitativas.170 A detecção de outliers deve ser aplicada apenas uma vez no conjunto de dados; um erro comum é identificar e tratar os outliers (como remover ou recodificar) e, em seguida, reaplicar o procedimento no conjunto de dados já modificado.170 A detecção ou o tratamento dos outliers não deve ser realizada após a análise dos resultados, pois isso introduz viés nos resultados.170 21.2.5 Quais são os métodos para detectar valores discrepantes? Valores univariados são comumente considerados outliers quando são mais extremos do que a média ± (desvio padrão × constante), podenso essa constante ser 3 (99,7% das observações estão dentro de 3 desvios-padrão da média) ou 3,29 (99,9% estão dentro de 3,29 desvios-padrão).170 Para detectar outliers univariados, recomenda-se o uso da Mediana da Desviação Absoluta (Median Absolute Deviation, MAD), calculado a partir de um intervalo em torno da mediana, multiplicado por uma constante (valor padrão: 1,4826).170,231 Para detectar outliers multivariados, comumente utiliza-se a distância de Mahalanobis, que identifica valores muito distantes do centróide formado pela maioria dos dados (por exemplo, 99%).170 Para detectar outliers multivariados, recomenda-se o Determinante de Mínima Covariância (Minimum Covariance Determinant, MCD), pois possui o maior ponto de quebra possível e utiliza a mediana, que é o indicador mais robusto em presença de outliers.170,232 21.2.6 Quais testes são apropriados para detectar valores discrepantes? A escolha do método de detecção depende da natureza do outlier, se univariado ou multivariado.172 Para valores univariados, podem ser usados box-plots (com pontos além de 1,5 vezes o intervalo interquartílico), z-scores clássicos (\\(|z| &gt; 2.5\\) ou \\(|z| &gt; 3\\)) ou z-scores robustos, que substituem média por mediana e desvio-padrão por estimadores robustos.172 Para valores multivariados, recomenda-se a distância de Mahalanobis para medir o afastamento em relação ao centróide, com ajustes robustos de covariância como MCD (Minimum Covariance Determinant) ou MVE (Minimum Volume Ellipsoid).172 Técnicas baseadas em PCA robusta (ROBPCA, PP-PCA, SPCA, EPCA) também podem ser aplicadas para reduzir dimensionalidade e expor outliers mascarados.172 Métodos de trimming multivariado (MVT) podem iterativamente remover observações mais distantes, mas apresentam limitações em alta dimensionalidade.172 Estimadores com alto ponto de quebra, como o MCD, permitem detectar até 50% de outliers antes de comprometer a análise.172 21.2.7 Como manejar os valores discrepantes? Manter outliers pode ser uma boa decisão se a maioria desses valores realmente pertence à distribuição de interesse. Manter outliers que pertencem a uma distribuição alternativa pode ser problemático, pois um teste pode se tornar significativo apenas por causa de um ou poucos outliers.170 Remover outliers pode ser eficaz quando eles distorcem a estimativa dos parâmetros da distribuição. Remover outliers que pertencem legitimamente à distribuição pode reduzir artificialmente a estimativa do erro.170 Remover outliers leva à perda de observações, especialmente em conjuntos de dados com muitas variáveis, quando outliers univariados são excluídos em cada variável.170 Recodificar outliers evita a perda de uma grande quantidade de dados, mas deve ser baseada em argumentos razoáveis e convincentes.170 Erros de observação e de medição são uma justificativa válida para descartar observações discrepantes.199 21.2.8 Como conduzir análises com valores discrepantes? É importante reportar se existem valores discrepantes e como foram tratados.199 Valores discrepantes na variável de desfecho podem exigir uma abordagem mais refinada, especialmente quando representam uma variação real na variável que está sendo medida.199 Valores discrepantes em uma (co)variável podem surgir devido a um projeto experimental inadequado; nesse caso, abandonar a observação ou transformar a covariável são opções adequadas.199 Valores discrepantes podem ser recodificados usando a Winsorização,233 que transforma os outliers em valores de percentis específicos (como o 5º e o 95º).170 O pacote outliers234 fornece a função outlier para identificar os valores mais distantes da média. O pacote outliers234 fornece a função rm.outlier para remover os valores mais distantes da média detectados por testes de hipótese e/ou substitui-los pela média ou mediana. 21.2.9 Como lidar com outliers na análise exploratória de dados? Após a detecção, três estratégias principais podem ser adotadas: (1) manter os outliers, (2) removê-los ou (3) recodificá-los (por exemplo, com Winsorização). A escolha deve ser justificada com base no contexto teórico e nas características do banco de dados. Idealmente, erros devem ser corrigidos ou removidos, enquanto outliers interessantes podem gerar novas hipóteses de pesquisa.170 A decisão sobre como lidar com outliers deve ser definida a priori e preferencialmente registrada em plataformas de pré-registro. Essa prática aumenta a transparência, reduz a flexibilidade analítica e evita inflar taxas de erro tipo I.170 21.3 Valores influentes 21.3.1 O que são valores influentes? Valores influentes são observações que, se removidas, causariam uma mudança significativa nos resultados da análise estatística.REF? Figura 21.2: Regressão linear com valores influentes. 21.3.2 O que é função de influência? A função de influência mede a sensibilidade de um estimador a pequenas contaminações nos dados. Um estimador é considerado robusto se sua função de influência for limitada, indicando que valores extremos não exercem impacto desproporcional.235 21.3.3 O que é ponto de quebra? O ponto de quebra representa a fração mínima de observações contaminadas necessária para distorcer um estimador até o infinito. Por exemplo, a média tem ponto de quebra 0, enquanto a mediana atinge o ponto de quebra máximo (50%).235 21.3.4 Como detectar valores influentes? A alavancagem (leverage) mede o quão distante uma observação está dos valores médios das variáveis independentes. Observações com alta alavancagem têm o potencial de influenciar significativamente a linha de regressão.REF? Figura 21.3: Alavancagem vs Resíduos Padronizados com distância de Cook para análise da influência de pontos. 21.4 Métodos robustos de tratamento de outliers 21.4.1 O que é Winsorização? Winsorização é uma técnica que substitui os valores extremos (outliers) por valores menos extremos, preservando a estrutura dos dados. Isso é feito definindo limites superior e inferior e substituindo os valores que ultrapassam esses limites pelos próprios limites.230 21.4.2 Quais são as alternativas à Winsorização? Podar (trimming): remove diretamente uma fração fixa das observações mais extremas.REF? Estimadores robustos: resistem à influência de outliers sem transformar os dados.REF? Transformações de variáveis: reduzem a assimetria e impacto de valores extremos, mas mudam a escala interpretativa.REF? O pacote WRS2236 fornece as funções winmean e winvar para calcular a média e variância Winsorizadas. O pacote WRS2236 fornece a função yuen para realizar o teste de comparação de Yuen de médias Winsorizadas para amostras independentes ou dependentes. O pacote WRS2236 fornece a função wincor para calcular a correlação Winsorizada. O pacote WRS2236 fornece as funções t1way, t2way e t3way para realizar testes de comparação de médias Winsorizadas para análise de variância para 1, 2 ou 3 fatores, respectivamente. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["analise-preditiva.html", "Capítulo 22 Análise preditiva 22.1 Predição via modelagem 22.2 Interpretação e aplicação 22.3 Análise de curva de decisão 22.4 Risco de vieses em estudos de predição", " Capítulo 22 Análise preditiva 22.1 Predição via modelagem 22.1.1 O que são predições? .REF? O pacote ggeffects237 fornece a função predict_response para calcular valores preditos marginais ou ajustados das variáveis de desfecho. O pacote ggeffects237 fornece a função test_response para testar valores preditos marginais ou ajustados das variáveis de desfecho. 22.1.2 Como árvores de decisão são usadas para predição? Utilizam padrões históricos para prever resultados futuros em novos registros.238 Identificam combinações de fatores que elevam ou reduzem o risco de um evento clínico.238 Podem ser aplicadas em diagnósticos médicos para prever subtipos de condições ou diferentes respostas terapêuticas.238 22.2 Interpretação e aplicação 22.2.1 Quais são as implicações do uso de árvores de decisão em predição? Tornam os resultados mais compreensíveis para clínicos e pesquisadores, com regras “se-então” claras.238 Auxiliam na formulação de hipóteses clínicas e direcionamento de futuras pesquisas.238 Podem ser estendidas para predição de sobrevivência, subgrupos de tratamento e análise de custo-benefício.238 22.3 Análise de curva de decisão 22.3.1 O que é a análise de curva de decisão? Análise de curva de decisão é um método para avaliar a utilidade clínica de modelos preditivos em comparação às estratégias padrão “tratar todos” ou “tratar ninguém”.239 22.3.2 O que significam os eixos da curva de decisão? O eixo vertical mostra o benefício líquido, ganho obtido ao usar o modelo em relação às estratégias de referência. O eixo horizontal mostra a preferência, que corresponde ao limiar de decisão: a probabilidade mínima de evento a partir da qual se recomenda intervir.240 O limiar reflete o equilíbrio entre o risco de perder casos da doença e o risco de intervenções desnecessárias.240 22.3.3 Como interpretar o benefício líquido? O benefício líquido é o número de verdadeiros positivos obtidos ajustado pelo “custo” dos falsos positivos, expresso na mesma unidade dos verdadeiros positivos.240 Quando a estratégia padrão é “tratar todos”, o benefício líquido também pode ser expresso como intervenções desnecessárias evitadas, facilitando a interpretação clínica.240 22.3.4 Por que é importante comparar sempre com “tratar todos” e “tratar nenhum”? Porque essas duas estratégias são frequentemente plausíveis em contextos reais: tratar todos os pacientes de risco ou tratar nenhum.240 Um modelo ou teste só é considerado útil se apresentar maior benefício líquido do que ambas as estratégias, garantindo que realmente agrega valor clínico.240 Essa comparação evita que um modelo com bom AUC mas má calibração seja usado, já que pode apresentar net benefit inferior às estratégias padrão.240 22.3.5 Quais são os limites e usos da análise de curva de decisão? A análise de curva de decisão não substitui uma análise de decisão completa ou uma avaliação de custo-efetividade, mas é mais simples e prática, exigindo apenas a definição de um intervalo de limiares de decisão razoáveis.240 Em situações claras (modelo com nenhum benefício ou benefício amplo), pode dispensar análises complexas.240 Em casos ambíguos, serve como primeiro passo antes de análises mais detalhadas.240 22.3.6 A análise de curva de decisão pode ser conduzida sem dados individuais de pacientes? Em modelos bem calibrados e com tamanho amostral adequado, a análise de curva de decisão pode ser realizada utilizando apenas estimativas sumárias (média e desvio-padrão).239 22.3.7 Como funciona o cálculo do benefício líquido? O benefício líquido é estimado contrastando verdadeiros positivos e falsos positivos em diferentes limiares de decisão.239 22.4 Risco de vieses em estudos de predição 22.4.1 Como avaliar o risco de vieses em estudos de predição? Para estudos de modelos preditivos recomenda-se aplicar a ferramenta PROBAST para avaliar risco de viés.53 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["analise-causal.html", "Capítulo 23 Análise causal 23.1 Causalidade 23.2 Abordagens filosóficas e estatísticas da causalidade 23.3 Ilusões de causalidade 23.4 Inferência causal em estudos observacionais 23.5 Critérios de Hill para inferência causal 23.6 Críticas contemporâneas aos critérios de Hill 23.7 Visão atual sobre os critérios de Hill 23.8 Linguagem causal em estudos observacionais 23.9 Efeitos diretos e indiretos 23.10 O papel do tempo e a causalidade dinâmica 23.11 Diagrama acíclico direcionado (DAG)", " Capítulo 23 Análise causal 23.1 Causalidade 23.1.1 O que é análise causal? Análise causal é usada para explicar a relação entre causa e efeito em um conjunto de dados, respondendo a perguntas do tipo “por quê?”.204 Análise causal implica em contrafactual, no sentido de que a análise causal é baseada na comparação entre o que realmente aconteceu e o que teria acontecido se uma ou mais variáveis tivessem sido diferentes.204 23.1.2 Quais os dois grandes tipos de causalidade? Baseada em experiência: conhecimento empírico, muitas vezes sem compreensão dos mecanismos. Estatística tem papel central na causalidade baseada em experiência.241 Mecanicista: busca entender processos internos e mecanismos. Estatística tem seu papel ainda limitado, mas crescente, especialmente em sistemas complexos.241 23.2 Abordagens filosóficas e estatísticas da causalidade 23.2.1 O que é realidade causal? A estatística assume tanto a presença do acaso quanto de causalidade. Entretanto, a natureza de cada um (se essencial ou apenas reflexo de ignorância) é raramente debatida.241 23.2.2 Por que estatísticos historicamente evitaram falar em causalidade? Pearson e Fisher defenderam que estatística trata apenas de associação, não de causalidade, o que gerou cautela excessiva e paralisou avanços em áreas como economia e ciências sociais.241 Autores como Judea Pearl, Robins e Rubin trouxeram definições mais precisas, especialmente via modelos contrafactuais.241 O uso de ensaios clínicos randomizados consolidou o papel da estatística em inferência causal aplicada.241 23.3 Ilusões de causalidade 23.3.1 O que são ilusões de causalidade? Ocorrem quando acreditamos que há uma relação causal entre dois eventos que, na realidade, são independentes. São comuns em superstições, pseudociências e crenças do cotidiano.242 23.3.2 Quais fatores favorecem a ilusão? Alta frequência do desfecho: quando o resultado ocorre frequentemente por acaso, as pessoas superestimam a eficácia da causa (ex.: melhora espontânea de sintomas atribuída a um tratamento).242 Alta frequência da causa: quanto mais vezes um comportamento ou tratamento é aplicado, mais coincidências com o desfecho ocorrem, aumentando a crença no efeito.242 Coincidências causa–desfecho: damos peso desproporcional a casos em que causa e efeito ocorrem juntos, mesmo que sejam apenas coincidências.242 23.3.3 Como reduzir ilusões de causalidade? Ensinar princípios de controle científico, observando casos em que a causa está ausente (comparação necessária para detectar ausência de relação).242 Diminuir a frequência da causa (ex.: reduzir uso de um “remédio ineficaz” ajuda a perceber que o resultado ocorre independentemente).242 Instruções explícitas para testar hipóteses: orientar a aplicar a causa em apenas 50% das vezes favorece a detecção correta da ausência de efeito.242 Promover educação científica prática, mostrando às pessoas como seus próprios julgamentos podem ser enviesados e oferecendo ferramentas para avaliação crítica.242 23.4 Inferência causal em estudos observacionais 23.4.1 Como diferenciar associação de causalidade? Associação descreve que duas variáveis variam juntas, mas não garante que uma afete a outra.243 Causalidade exige evidências (diretas ou indiretas) de que modificar a variável de exposição altera o desfecho.243 23.4.2 Quais critérios ajudam a sustentar inferência causal? Existência de um mecanismo plausível.243 Controle adequado de confundidores (medidos e não medidos).243 Consistência com literatura prévia e plausibilidade do tamanho do efeito.243 Avaliação de alternativas explicativas (ex.: viés de seleção, mediadores não controlados).243 23.4.3 Qual o papel dos caminhos causais (DAGs)? Ajudam a identificar quais variáveis precisam ser medidas e ajustadas.243 Evitam ajustes indevidos (ex.: em colisores), que podem introduzir viés.243 23.4.4 Como lidar com confundimento residual? Reconhecer que modelos multivariados e escores de propensão não eliminam completamente o confundimento.243 Comparar características basais entre grupos para identificar diferenças persistentes.243 Considerar análises de sensibilidade, mas com cautela na interpretação.243 23.5 Critérios de Hill para inferência causal 23.5.1 Quais são os nove critérios? Temporalidade: A exposição deve preceder o desfecho. Único critério considerado essencial por Hill.244 Força da associação: Associações mais fortes são mais prováveis de refletir causalidade.244 Consistência: A associação é observada em diferentes estudos, populações e contextos.244 Especificidade: Uma exposição leva a um efeito específico (embora nem sempre aplicável).244 Gradiente biológico (dose–resposta): Aumentos na exposição acompanham aumentos no risco.244 Plausibilidade biológica: Compatibilidade com o conhecimento científico da época.244 Coerência: A associação não deve contradizer a história natural ou biologia da doença.244 Evidência experimental: Reduções na exposição devem reduzir o risco observado.244 Analogia: Comparação com relações causais já conhecidas.244 23.5.2 Hill propôs um checklist rígido? Nenhum critério, isoladamente, prova ou refuta causalidade. Devem ser usados como guias para reflexão científica, não como requisitos obrigatórios.244 23.6 Críticas contemporâneas aos critérios de Hill 23.6.1 Qual critério é indispensável? A temporalidade: a exposição deve preceder o desfecho. Mesmo assim, observar uma ordem temporal inversa apenas invalida a hipótese em casos específicos, não em todos.245 23.6.2 A força da associação garante causalidade? Não. Associações fortes podem ainda ser não-causais e associações fracas podem ser causais.245 23.6.3 A consistência é indispensável? Não. A ausência de consistência não elimina causalidade, pois alguns efeitos só se manifestam em condições específicas (ex.: transfusão só causa HIV se o vírus estiver presente).245 A consistência ajuda apenas a afastar a hipótese de viés ou erro em um estudo isolado:contentReference.245 23.6.4 O critério da especificidade é válido? Não. É considerado um critério inválido e enganoso. Uma causa pode ter múltiplos efeitos (tabagismo → vários desfechos) e um efeito pode ter múltiplas causas.245 23.6.5 O gradiente biológico (dose–resposta) é confiável? Nem sempre. Pode ser distorcido por confundimento. A ausência de gradiente não invalida a causalidade.245 23.6.6 A plausibilidade e a coerência são objetivas? Não. Ambas são fortemente dependentes do conhecimento científico da época. O que parecia implausível no passado depois se confirmou como verdadeiro.245 23.6.7 Evidência experimental é decisiva? Pode ser útil, mas raramente está disponível em epidemiologia. Mesmo quando disponível, pode ter explicações alternativas.245 23.6.8 Analogia é útil? Tem pouco valor. Analogias podem sempre ser inventadas e, na prática, funcionam mais como fonte de hipóteses do que como prova.245 23.7 Visão atual sobre os critérios de Hill 23.7.1 Como os critérios de Hill foram revisitados? Estudos recentes propõem integrá-los a três abordagens modernas: DAG (destacam estrutura causal e confundimento), modelos de causa suficiente (enfatizam multifatorialidade) e GRADE (orienta sobre a certeza da evidência em corpos de estudos).246 23.7.2 Quais mudanças na interpretação? Temporalidade e experimentos: seguem centrais, mas analisados com mais sofisticação.246 Força da associação: relevante, mas não garante causalidade (pode haver confundimento).246 Consistência: pensada como transportabilidade entre populações.246 Especificidade: pouco útil hoje; substituída por falsificação (controles negativos).246 Dose–resposta: pode ser espúria, cautela é necessária.246 Coerência e analogia: utilidade limitada.246 23.8 Linguagem causal em estudos observacionais 23.8.1 Quais são as principais recomendações para relatar causalidade? Usar termos causais de forma explícita e criteriosa (“causa”, “efeito”, “reduzir”, “aumentar”), evitando expressões ambíguas como “fator de risco”.243 Contextualizar a causalidade em termos práticos, explicando por que identificar a causa é relevante para intervenções.243 Declarar claramente na introdução se existe hipótese causal, justificando quando não houver.243 Descrever caminhos causais (mediadores, confundidores, colisores) em texto claro ou com diagramas.243 Justificar a seleção de covariáveis com base nas relações causais previstas.243 Avaliar o controle de confundimento, reconhecendo limitações e possível confundimento residual.243 Discutir as inferências causais considerando estimativas, vieses e plausibilidade biológica.243 Indicar recomendações específicas para pesquisas futuras ou prática clínica baseadas nas conclusões causais.243 23.9 Efeitos diretos e indiretos 23.9.1 Como distinguir efeitos diretos de indiretos? Um efeito direto ocorre quando uma variável influencia outra sem mediação.241 Um efeito indireto acontece quando a influência é mediada por variáveis intermediárias.241 23.10 O papel do tempo e a causalidade dinâmica 23.10.1 O que é Granger–Schweder Causality? É um conceito estatístico que analisa como processos passados influenciam o futuro, indo além da simples associação.241 Permite identificar relações direcionais entre processos ao longo do tempo (ex.: cérebro controlando contrações musculares).241 A estatística, nesse contexto, busca “olhar dentro da caixa”, aproximando-se de uma visão mecanicista.241 23.10.2 Por que o tempo é essencial na análise causal? Processos causais não ocorrem de forma estática: efeitos diretos e indiretos se acumulam em cadeias temporais.241 Modelos tradicionais (ex.: regressões estáticas ou DAGs sem tempo) podem falhar em capturar a dinâmica.241 A integração de séries temporais e processos estocásticos é fundamental para compreender mecanismos.241 23.11 Diagrama acíclico direcionado (DAG) 23.11.1 O que são DAGs? DAGs são representações gráficas de relações causais entre variáveis, usando nós (variáveis) e arestas direcionadas (relações causais).REF? DAGs ajudam a identificar confundidores, mediadores e colisores, orientando a seleção de variáveis para ajuste em análises estatísticas.REF? DAGs são acíclicos, ou seja, não permitem ciclos ou loops, refletindo a natureza unidirecional das relações causais.REF? 23.11.2 Quais são os padrões causais básicos? Independência: duas variáveis não têm relação causal direta ou indireta.REF? Cadeia: uma variável causa outra, que por sua vez causa uma terceira (X → M → Y).REF? Garfo: uma variável causa duas outras (X ← Z → Y), onde Z é um confundidor.REF? Colisor: duas variáveis causam uma terceira (X → Z ← Y), onde Z é um colisor.REF? O pacote dagitty247 fornece a função dagitty para criar um objeto grafo a partir de uma descrição textual. O pacote ggdag248 fornece a função ggdag para criar figuras de grafos. O pacote performance249 fornece a função check_dag para criar, verificar e visualizar os modelos em grafos. Figura 23.1: Padrões causais básicos: independência, cadeia, garfo e colisor. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["analise-qualitativa.html", "Capítulo 24 Análise qualitativa 24.1 Análise qualitativa 24.2 Representação de texto", " Capítulo 24 Análise qualitativa 24.1 Análise qualitativa 24.1.1 O que é análise qualitativa? .REF? 24.2 Representação de texto 24.2.1 O que é tokenização? Tokenização é o processo de dividir texto contínuo em unidades menores (tokens), como palavras, pontuação, subpalavras ou caracteres. O objetivo é criar uma representação discreta sobre a qual modelos podem calcular frequências, probabilidades e relações.REF? É comum combinar tokenização com normalização (lowercase), remoção de stopwords, lematização/stemming e regras para números e pontuação.REF? 24.2.2 Modelagem com N-gramas 24.2.3 O que são n-gramas? Um n-grama é uma sequência contígua de n tokens, tais como: 1-gramas (unigramas), 2-gramas (bigramas), 3-gramas (trigramas).REF? Contagens de n-gramas aproximam dependências locais no texto e servem de base para DTM/TF-IDF, modelos de linguagem clássicos e detecção de coligações.REF? O pacote tidytext250 fornece a função unnest_token para transformar um texto em um data frame com uma coluna para cada palavra. O pacote tidytext250 fornece a função stop_words para remover palavras comuns que não agregam significado. O pacote tidytext250 fornece a função get_sentiments para obter listas de palavras com sentimentos associados. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["parte-6.html", "PARTE 6: ANÁLISES INFERENCIAIS Testando hipóteses e estimando parâmetros para responder perguntas de pesquisa", " PARTE 6: ANÁLISES INFERENCIAIS Testando hipóteses e estimando parâmetros para responder perguntas de pesquisa "],["selecao-testes.html", "Capítulo 25 Seleção de testes 25.1 Multiverso de análises estatísticas 25.2 Escolha de testes para análise inferencial", " Capítulo 25 Seleção de testes 25.1 Multiverso de análises estatísticas 25.1.1 Por que escolher o teste é um problema? Analisar a mesma hipótese com o mesmo banco de dados pode resultar em diferenças substanciais nas estimativas estatísticas e nas conclusões.251 As decisões para especificação das análises estatísticas podem ser tão minuciosas que muitas vezes nem sequer são registradas como decisões e, assim, podem impactar negativamente na reprodutibilidade do estudo.251 25.2 Escolha de testes para análise inferencial 25.2.1 Como selecionar os testes para a análise estatística inferencial? .252 .253 .254 .255 .256 .257 .258 .259 Referências "],["analise-inferencial.html", "Capítulo 26 Análise inferencial 26.1 Raciocínio inferencial 26.2 Hipóteses científicas 26.3 Hipóteses estatísticas 26.4 Testes de hipóteses 26.5 Comparações múltiplas 26.6 Inferência visual 26.7 Interpretação de análise inferencial 26.8 Erros de inferência", " Capítulo 26 Análise inferencial 26.1 Raciocínio inferencial 26.1.1 O que é análise inferencial? Na análise inferencial são utilizados dados da(s) amostra(s) para fazer uma inferência válida (isto é, estimativa) sobre os parâmetros populacionais desconhecidos.107 No paradigma de Jerzy Neyman e Egon Pearson, um teste de hipótese científica envolve a tomada de decisão sobre hipóteses nulas (\\(H_{0}\\)) e alternativa (\\(H_{1}\\)) concorrentes e mutuamente exclusivas.260 26.1.2 Quais são os tipos de raciocínio inferencial? Inferência dedutiva: Uma dada hipótese inicial é utilizada para prever o que seria observado caso tal hipótese fosse verdadeira.261 Inferência indutiva: Com base nos dados observados, avalia-se qual hipótese é mais defensável (isto é, mais provável).261 26.1.3 Quais são as questões fundamentais da análise inferencial? A direção do efeito262 A magnitude do efeito262 A importância do efeito262 26.2 Hipóteses científicas 26.2.1 O que é hipótese científica? Hipótese científica é uma ideia que pode ser testada.260 Definir claramente os problemas e os objetivos da pesquisa são o ponto de partida de todos os estudos científicos.131 26.2.2 Quais são as fontes de ideias para gerar hipóteses científicas? Revisão das práticas atuais.263 Desafio a ideias aceitas.263 Conflito entre ideias divergentes.263 Variações regionais, temporais e populacionais.263 Experiências dos próprios pesquisadores.263 Imaginação sem fronteiras ou limites convencionais.263 26.3 Hipóteses estatísticas 26.3.1 O que é hipótese nula? A hipótese nula (\\(H_{0}\\)) é uma expressão que representa o estado atual do conhecimento (status quo), em geral a não existência de um determinado efeito.161 26.3.2 O que é hipótese alternativa? A hipótese alternativa (\\(H_{1}\\)) é uma expressão que contém as situações que serão testadas, de modo que um resultado positivo indique alguma ação a ser conduzida.161 26.3.3 Qual hipótese está sendo testada? A hipótese nula (\\(H_{0}\\)) é a hipótese sob teste em análises inferenciais.108 Pode-se concluir sobre rejeitar ou não rejeitar a hipótese nula (\\(H_{0}\\)).108 Não se conclui sobre a hipótese alternativa (\\(H_{1}\\)).161 Para testar a hipótese nula, deve-se selecionar o nível de significância crítica (P-valor de corte); a probabilidade de rejeitarmos uma hipótese nula verdadeira (\\(\\alpha\\)); e a probabilidade de não rejeitarmos uma hipótese nula falsa (\\(\\beta\\)).260 26.4 Testes de hipóteses 26.4.1 Quais são os tipos de teste de hipóteses? Teste (clássico) de significância da hipótese nula: verifica evidência contra \\(H_{0}\\) usando P-valor.264 Teste de mínimos efeitos (MOTE/MOST/SESOI): testa se o efeito é pelo menos tão grande quanto um limiar de relevância (SESOI). Rejeitar \\(H_{0}\\) sugere efeito grande o suficiente.264 Teste de equivalência (TOST): testa se o efeito está dentro de uma margem de equivalência clinicamente irrelevante (entre \\(\\Delta\\) e \\(-\\Delta\\)). Rejeitar \\(H_{0}\\) sugere equivalência prática.264 Teste de superioridade: avalia se um tratamento/intervenção supera o controle por uma margem \\(&gt;0\\) ou \\(&gt;\\Delta\\).264 Teste de não-inferioridade: avalia se o tratamento não é pior que o controle por mais do que \\(-\\Delta\\).REF? Teste de inferioridade: avalia se o tratamento é pior que o controle (por exemplo, para checar segurança).REF? 26.4.2 O que reportar após um teste de hipótese? P-valores, como estimativa da significância estatística.265 Tamanho do efeito, como estimativa de significância substantiva.265 26.5 Comparações múltiplas 26.5.1 O que é uma família de hipóteses? Família de hipóteses é um conjunto de comparações/inferências que, por desenho ou análise, devem ser consideradas juntas para controle do erro tipo I global (ex.: todas as comparações de um desfecho primário, todos os subgrupos pré-especificados, todos os desfechos coprimários).REF? O controle do family-wise error rate (FWER) ou do false discovery rate (FDR) deve considerar a família pertinente, não comparações isoladas.REF? 26.5.2 O que são testes ad hoc e post hoc? Ad hoc: análises/decisões não planejadas a priori, motivadas por inspeção dos dados. Úteis para gerar hipóteses, não para confirmá-las.REF? Post hoc: procedimentos de comparações múltiplas aplicados após um teste global (ex.: ANOVA) ter indicado diferença (ex.: Tukey, Bonferroni, Holm). Visam controlar o erro tipo I em múltiplas comparações.REF? 26.5.3 Como ajustar a análise inferencial para hipóteses múltiplas? Defina a família (o que entra no ajuste) e priorize desfechos (primário, coprimários, secundários).REF? Aplique métodos de controle FWER (Bonferroni, Holm, Hochberg, Dunnett para múltiplos vs. controle) ou controle FDR (Benjamini–Hochberg) conforme o objetivo (confirmação vs. exploração).REF? Em planos confirmatórios, use hierarquização/gatekeeping: testa-se em sequência; a alocação de \\(\\alpha\\) passa adiante apenas se houver significância no nível anterior.REF? O pacote stats140 fornece a função p.adjust para ajustar o P-valor utilizando diversos métodos. 26.5.4 O que são testes unicaudais e bicaudais? teste unicaudal procura evidência em uma direção específica (ex.: “maior que 0”). Toda a região crítica está numa só cauda; tem maior poder para aquela direção, mas não detecta sinal oposto.REF? Teste bicaudal procura evidência em qualquer direção (ex.: “diferente de 0”). Divide \\(\\alpha\\) em duas caudas (direita e esquerda). É a escolha padrão quando ambas as direções são plausíveis.REF? A decisão entre uma ou duas caudas deve ser pré-especificada com justificativa substantiva.REF? Figura 26.1: Representação gráfica de um teste de hipótese unicaudal à direita, aplicado quando se busca evidência de efeitos positivos (valores significativamente maiores que o esperado sob \\(H_0\\)). Figura 26.2: Representação gráfica de um teste de hipótese unicaudal à esquerda, aplicado quando se busca evidência de efeitos negativos (valores significativamente menores que o esperado sob \\(H_0\\)). Figura 26.3: Representação gráfica de um teste de hipótese bicaudal, aplicado quando se busca evidência de efeitos positivos ou negativos (valores significativamente diferentes do esperado sob \\(H_0\\)). 26.6 Inferência visual 26.6.1 O que é inferência visual? Inferência visual consiste na interpretação de dados apresentados em gráficos.266 Para inferência visual, recomenda-se a apresentação dos dados em gráficos com estimativas de tendência central e seu intervalo (preferencialmete intervalo de confiança no nível de significância \\(\\alpha\\) pré-estabelecido).266 26.6.2 Por que usar intervalos de confiança para inferência visual? Intervalos de confiança fornecem estimativas pontuais e intervalares na mesma unidade de medida da variável.266 Existe uma relação entre o intervalo de confiança e o valor de P obtido pelo teste de significância de hipótese nula, em que ambos consideram o mesmo nível de significância \\(\\alpha\\) pré-estabelecido.266 26.6.3 Como interpretar intervalos de confiança em uma figura? Identifique o que as tendências centrais e as barras de erro representam. Qual é a variável dependente? É expressa em unidades originais ou é padronizada ? A figura mostra intervalos de confiança, erro-padrão ou desvio-padrão? Qual é o desenho experimental?266 Faça uma interpretação substantiva dos valores de tendência central e dos intervalos de confiança.266 O intervalo de confiança é uma faixa de valores plausíveis para a tendência central. Valores fora do intervalo são relativamente implausíveis, no nível de significância \\(\\alpha\\) pré-estabelecido.266 Qualquer valor fora do intervalo de confiança, quando considerado como hipótese nula (\\(H_{0}\\)), equivale a \\(P &lt; \\alpha\\) pré-estabelecido (bicaudal).266 Qualquer valor dentro do intervalo, quando considerado como hipótese nula (\\(H_{0}\\)), equivale a \\(P &gt; \\alpha\\) pré-estabelecido (bicaudal).266 26.7 Interpretação de análise inferencial 26.7.1 Como interpretar uma análise inferencial? Testes de hipótese nula (\\(H_{0}\\)) vs. alternativa (\\(H_{1}\\)) a partir de um nível de significância (\\(\\alpha\\)) pré-especificado.267 P-valor como evidência estatística sobre (\\(H_{0}\\)).267 Estimação de intervalos de confiança de um nível de significância (\\(\\alpha\\)) pré-especificado bicaudal (\\(IC_{1-\\alpha/2}\\)) ou unicaudal (\\(IC_{1-\\alpha}\\)).267 Análise Bayesiana.267 26.7.2 O que são resultados ‘positivos’ e ‘negativos’ ou inconclusivos em teste de hipótese? Resultados ‘positivos’ compreendem um P-valor dentro da zona crítica estatisticamente significativa (ex.: \\(P&lt;0,05\\) ou outro ponto de corte) e sugerem que os autores rejeitem a hipótese nula (\\(H_{0}\\)), confirmando assim sua hipótese científica.268 Resultados ‘negativos’ ou inconclusivos compreendem um P-valor fora da zona crítica estatisticamente significativa (ex.: \\(P \\geq 0,05\\) ou outro ponto de corte) e sugerem que os autores não rejeitem a hipótese nula (\\(H_{0}\\)) porque o efeito observado é nulo (logo, negativo), ou porque o estudo não possui poder suficiente para detectá-lo, não permitindo portanto afirmar a hipótese científica (logo, inconclusivo).268 26.7.3 Qual a importância de resultados ‘negativos’? Conhecer resultados negativos contribui com uma visão mais ampla do campo de estudo junto aos resultados positivos.269 Resultados negativos permitem um melhor planejamento das pesquisas futuras e pode aumentar suas chances de sucesso.269 26.7.4 Resultados inconclusivos: Ausência de evidência ou evidência de ausência? Em estudos (geralmente com amostras grandes), resultados estatisticamente significativos (com P-valores menores do limiar pré-estabelecido, \\(P&lt;\\alpha\\)) podem não ser clinicamente relevantes.270 Em estudos (geralmente com amostras pequenas), resultados estatisticamente não significativos (com P-valores iguais ou maiores do limiar pré-estabelecido, \\(P \\geq \\alpha\\)) não devem ser interpretados como evidência de inexistência do efeito.270 Geralmente é razoável aceitar uma nova conclusão apenas quando há dados a seu favor (‘resultados positivos’). Também é razoável questionar se apenas a ausência de dados a seu favor (‘resultados negativos’) justifica suficientemente a rejeição de tal conclusão.270 26.8 Erros de inferência 26.8.1 O que são erros de inferência estatística? Um erro de inferência é a tomada de decisão incorreta, seja a favor ou contra a hipótese nula (\\(H_{0}\\)).260 26.8.2 O que são erros Tipo I e Tipo II? Erro Tipo I significa a rejeição de uma hipótese nula (\\(H_{0}\\)) quando esta é verdadeira.260 Erro Tipo II significa a não rejeição de uma hipótese nula (\\(H_{0}\\)) quando esta é falsa.260 Tabela 26.1: Tabela de erros tipos I e II de inferência estatística. Hipótese nula \\(H_{0}\\) é falsa Hipótese nula \\(H_{0}\\) é verdadeira Hipótese nula \\(H_{0}\\) foi rejeitada Decisão correta Decisão incorreta (erro tipo I) Hipótese nula \\(H_{0}\\) não foi rejeitada Decisão incorreta (erro tipo II) Decisão correta Figura 26.4: Representação gráfica dos erros tipo I e tipo II em um teste de hipótese (bicaudal). Figura 26.5: Erro tipo I: Distribuição dos p-valores em 100 testes de hipótese de amostras aleatórias de tamanho 30. A linha vermelha pontilhada indica o nível de significância estatística de 0,05. Figura 26.6: Erro tipo II: Distribuição dos p-valores em 100 testes de hipótese de amostras aleatórias de tamanho 10. A linha vermelha pontilhada indica o nível de significância estatística de 0,05. 26.8.3 O que são erros Tipo S e Tipo M? Erro Tipo S (do inglês sign) significa a identificação errônea da direção - positiva ou negativa - do efeito observado.271,272 Tabela 26.2: Tabela de erro tipo S de inferência estatística. Sinal positivo Sinal negativo Sinal positivo Decisão correta Decisão incorreta (erro tipo S) Sinal negativo Decisão incorreta (erro tipo S) Decisão correta Figura 26.7: Representação gráfica do erro tipo S (sinal) em um teste de hipótese (bicaudal). Erro Tipo M (do inglês magnitude) significa a identificação errônea - em geral, exagerada - da magnitude do efeito observado.271,272 Tabela 26.3: Tabela de erro tipo M de inferência estatística. Magnitude alta Magnitude baixa Magnitude alta Decisão correta Decisão incorreta (erro tipo M) Magnitude baixa Decisão incorreta (erro tipo M) Decisão correta Figura 26.8: Representação gráfica do erro tipo M (magnitude) em um teste de hipótese (bicaudal). /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["tamanhoefeito-pvalor.html", "Capítulo 27 Tamanho do efeito e P-valor 27.1 Tamanho do efeito 27.2 Efeitos brutos e padronizados 27.3 Efeito principal 27.4 Efeito de interação 27.5 Efeito de mediação 27.6 Efeito de modificação 27.7 P-valor 27.8 P-valor de 2ª geração 27.9 Boas práticas", " Capítulo 27 Tamanho do efeito e P-valor 27.1 Tamanho do efeito 27.1.1 O que é o tamanho do efeito? Tamanho do efeito quantifica a magnitude de um efeito real da análise, expressando uma importância descritiva dos resultados.273 27.1.2 Quais são os tipos de tamanho do efeito? Diferenças padronizadas entre grupos:265,273 Cohen’s d Glass’s \\(\\Delta\\) Razão de chances (\\(RC\\) ou \\(OR\\)) Risco relativo ou razão de risco (\\(RR\\)) Medidas de associação:265,273 Coeficiente de correlação de Pearson (\\(r\\)), ponto-bisserial (\\(r_{s}\\)), Spearman (\\(\\rho\\)), Kendall (\\(\\tau\\)), Cramér (\\(V\\)) e \\(\\phi\\). Coeficiente de determinação (\\(R^2\\)) 27.1.3 Como converter um tamanho de efeito em outro? .273 O pacote effectsize274 fornece diversas funções para conversão de diferentes estimativas de tamanhos de efeito. 27.1.4 Como interpretar um tamanho do efeito? Tamanhos de efeito podem ser comparadores entre diferentes estudos.265 O pacote effectsize274 fornece a função rules para criar regras de interpretação de tamanhos de efeito. O pacote effectsize274 fornece a função interpret para interpretar os tamanhos de efeito com base em uma lista de regras pré-definidas. O pacote pwr275 fornece a função cohen.ES para obter os tamanhos de efeito “pequeno”, “médio” e “grande” para diversos testes de hipóteses. 27.2 Efeitos brutos e padronizados 27.2.1 O que é efeito bruto? .276 .277 27.2.2 O que é efeito padronizado? .276 .277 27.3 Efeito principal 27.3.1 O que é efeito principal? .278 27.4 Efeito de interação 27.4.1 O que é efeito de interação? A interação - representada pelo símbolo * - é o termo estatístico empregado para representar a heterogeneidade de um determinado efeito.279 .278 Figura 27.1: Análise de efeito de interação (direta) entre grupos e tempo. Retas paralelas sugerem ausência de efeito de interação. Figura 27.2: Análise de efeito de interação (inversa) entre grupos e tempo. Retas paralelas sugerem ausência de efeito de interação. O pacote nlme280 fornece a função nlme para ajustar um modelo de regressão misto não linear. O pacote mmrm281 fornece a função mmrm para ajuste de um modelo de regressão misto linear. O pacote emmeans282 fornece a função emmeans para calcular as médias marginais dos fatores e suas combinações de um modelo de regressão misto linear. 27.5 Efeito de mediação 27.5.1 O que é um mediador de efeito? .283 .278 27.5.2 O que é efeito de mediação? .283 .278 27.5.3 O que é efeito direto? .283 .278 27.5.4 O que é efeito indireto? .283 .278 27.5.5 O que é efeito total? .283 .278 27.6 Efeito de modificação 27.6.1 O que é um modificador de efeito? .278 27.6.2 O que é efeito de modificação? .278 27.7 P-valor 27.7.1 O que é significância estatística? A expressão “significância estatística”284 ou “evidência estatística de significância” sugere apenas que um experimento merece ser repetido, uma vez que um baixo P-valor (calculado a partir dos dados, modelos e demais suposições do estudo) sugere ser improvável que os dados coletados sejam coletados no contexto de que a hipótese nula (\\(H_{0}\\)) assumida é verdadeira.285 27.7.2 Como justificar o nível de significância estatística de um teste? .REF? O pacote Superpower286 fornece a função optimal_alpha para calcular e justificar o nível de significância \\(\\alpha\\) por balanço dos erros tipo I e II. O pacote Superpower286 fornece a função ANOVA_compromise para calcular e justificar o nível de significância \\(\\alpha\\) por balanço dos erros tipo I e II em análise de variância (ANOVA). 27.7.3 O que é o P-valor? P-valor é a probabilidade, assumindo-se um dado modelo estatístico, de que um efeito calculado a partir dos dados seria igual ou mais extremo do que o seu valor observado.287 P-valor é uma variável aleatória que possui distribuição uniforme quando a hipótese nula (\\(H_{0}\\)) é verdadeira.288 27.7.4 Como interpretar o P-valor? P-valores abaixo de um nível de significância estatística pré-especificado representam que um experimento merece ser repetido, com a rejeição da hipótese nula (\\(H_{0}\\)) justificada apenas quando experimentos adicionais frequentemente reportem igualmente resultados positivos (rejeição da hipótese nula (\\(H_{0}\\)).267 P-valor resulta da coleta e análise de dados, e assim quantifica a plausibilidade dos dados observados sob a hipótese nula (\\(H_{0}\\)).289 P-valores podem indicar quantitativamente a incompatibilidade entre os dados obtidos e o modelo estatístico especificado a priori (geralmente constituído pela hipótese nula (\\(H_{0}\\)).287 P-valores menores/maiores do que o nível de significância estatístico pré-estabelecido não devem ser utilizados como única fonte de informação para tomada de decisão em ciência.287 27.7.5 O que o P-valor não é? P-valor não representa a probabilidade de que a hipótese nula (\\(H_{0}\\)) seja verdadeira, nem a probabilidade de que os dados tenham sido produzidos pelo acaso.287 P-valor não mede o tamanho do efeito ou a relevância da sua observação.287 P-valor sozinho não provê informação suficiente sobre a evidência sobre um modelo teórico. A sua interpretação correta requer uma descrição ampla sobre o delineamento, métodos e análises estatísticas aplicados no estudo.287 Evidência estatística de significância não provê informação sobre a magnitude do efeito observado e não necessariamente implica que o efeito é robusto.192,288 27.7.6 Qual a origem do ‘P&lt;0,05’? A origem do P&lt;0,05 remonta aos trabalhos de R. A. Fisher nas décadas de 1920 e 1930. Fisher introduziu o conceito de valor-P dentro de uma abordagem frequentista de inferência estatística.267 O P&lt;0,05 foi sugerido por Ronald A. Fisher como um limiar prático para indicar que um resultado era “estatisticamente significativo”.267 Para Ronald A. Fisher, a significância estatística não era prova definitiva, mas um sinal de que o resultado merecia investigação adicional. A rejeição da hipótese nula só deveria ocorrer após repetidas observações significativas, e não com base em um único teste.267 Figura 27.3: Visualização espacial de p &lt; 0,05 (5 quadrados aleatórios em 100). 27.7.7 Quais são os complementos ou alternativas ao P-valor? Intervalos de confiança, credibilidade ou predição.287 Razão de verossimilhança.287 Métodos Bayesianos, fator Bayes.287 27.8 P-valor de 2ª geração 27.8.1 O que é o P-valor de 2ª geração? O p-valor de 2ª geração (SGPV) resume a fração das hipóteses apoiadas pelos dados que também pertencem à hipótese nula intervalar (intervalo de equivalência previamente especificado). Quantifica quanto do intervalo de estimativa (p.ex., IC95%) recai dentro da zona de indiferença científica/clinicamente irrelevante.290 Essa abordagem exige declarar a hipótese nula como intervalo (e não um ponto), incorporando o que é considerado “efeito sem relevância prática” segundo o contexto científico (precisão de medida, relevância clínica etc.).290 27.8.2 Como definir a hipótese nula intervalar e \\(\\delta\\)? Especifique \\(H_0\\) como um intervalo de equivalência \\([H_0^{-}, H_0^{+}]\\) que contém efeitos considerados praticamente nulos. Defina \\(\\delta\\) como a meia-largura do intervalo de equivalência (\\(\\delta = (H_0^{+} - H_0^{-})/2\\)).290 A escolha deve ser a priori e justificada por critérios científicos (p.ex., MCID, precisão de medida).290 27.8.3 Como calcular o SGPV? Seja \\(I=[a,b]\\) o intervalo apoiado pelos dados (p.ex., IC 95%) e \\(H_0\\) o intervalo nulo. O SGPV é (27.1), onde \\(|I|\\) é a largura do intervalo de estimativa, \\(|H_0|\\) é a largura do intervalo nulo e \\(|I \\cap H_0|\\) é a largura da sobreposição entre os dois intervalos. O SGPV é restrito ao intervalo \\([0,1]\\).290 \\[\\begin{equation} \\tag{27.1} p_{\\delta} = \\frac{|\\,I \\cap H_0\\,|}{|\\,I\\,|} \\times \\max\\!\\left\\{ \\frac{|\\,I\\,|}{2|\\,H_0\\,|}, \\, 1 \\right\\} \\end{equation}\\] Quando \\(|I|&lt;2|H_0|\\), \\(p_{\\delta}\\) é apenas a fração de sobreposição \\(|I\\cap H_0|/|I|\\).290 Quando \\(|I|&gt;2|H_0|\\), o SGPV reduz-se a \\(\\tfrac{1}{2}\\times \\dfrac{|,I\\cap H_0,|}{|,H_0,|}\\le \\tfrac{1}{2}\\), sinalizando inconclusão por imprecisão.290 Tabela 27.1: Comparação entre p-valor (bicaudal, inferido do IC 95%) e SGPV (\\(p_{\\delta}\\)) nos cenários simulados. Cenário \\(a\\) \\(b\\) \\(H_0^{-}\\) \\(H_0^{+}\\) \\(\\hat\\theta\\) \\(SE\\) p-valor (bicaudal) \\(p_{\\delta}\\) Conclusão (SGPV) 1 0.350 0.550 -0.100 0.100 0.450 0.0510 0.000 Apoia alternativas (SGPV=0) 2 -0.050 0.080 -0.100 0.100 0.015 0.0332 0.651 1.000 Equivalência (SGPV=1) 3 -0.500 0.700 -0.100 0.100 0.100 0.3061 0.744 0.500 Inconclusivo (0 4 0.050 0.250 -0.100 0.100 0.150 0.0510 0.003 0.250 Inconclusivo (0 5 -0.250 -0.050 -0.100 0.100 -0.150 0.0510 0.003 0.250 Inconclusivo (0 6 0.150 0.550 -0.100 0.100 0.350 0.1020 0.001 0.000 Apoia alternativas (SGPV=0) 7 -0.550 -0.150 -0.100 0.100 -0.350 0.1020 0.001 0.000 Apoia alternativas (SGPV=0) 27.8.4 Como interpretar o SGPV? \\(p_{\\delta}=0\\): dados apoiam apenas hipóteses alternativas relevantes (IC totalmente fora da equivalência).290 \\(p_{\\delta}=1\\): dados apoiam apenas hipóteses nulas (equivalentes) (IC totalmente dentro da equivalência).290 \\(0&lt;p_{\\delta}&lt;1\\): inconclusivo; o valor expressa o grau de inconclusão. Em particular, \\(p_{\\delta}=\\tfrac{1}{2}\\) indica inconclusão estrita.290 O SGPV é descritivo (não é probabilidade posterior de \\(H_0\\)).290 27.8.5 Relação com testes de equivalência (TOST) Tanto SGPV quanto TOST comparam o IC com os limites de equivalência. Se o IC \\((1-2\\alpha)\\) (p.ex., 90% quando \\(\\alpha=0{,}05\\)) cai inteiro dentro dos limites, TOST conclui equivalência — situação análoga a \\(p_{\\delta}=1\\).291 Com ICs simétricos, há pontos de ancoragem em que as estatísticas coincidem: quando \\(p_{\\text{TOST}}=0{,}5\\), então \\(\\mathrm{SGPV}=0{,}5\\); quando o IC toca o limite mas fica inteiramente dentro (fronteira), \\(p_{\\text{TOST}}=0{,}025\\) e \\(\\mathrm{SGPV}=1\\); quando o IC fica inteiramente fora tocando o limite, \\(p_{\\text{TOST}}=0{,}975\\) e \\(\\mathrm{SGPV}=0\\).291 Em ICs assimétricos ou quando \\(|I|&gt;2|H_0|\\), o SGPV fica difícil de interpretar quando \\(0&lt;p_{\\delta}&lt;1\\); nesses cenários, o TOST costuma diferenciar melhor os resultados.291 27.8.6 Propriedades frequenciais e múltiplas comparações Usando ICs \\(100(1-\\alpha)%\\), sob qualquer hipótese em \\(H_0\\), \\(\\Pr(p_{\\delta}=0)\\le \\alpha\\) e \\(\\to 0\\) com o aumento de \\(n\\); fora de \\(H_0\\), \\(\\Pr(p_{\\delta}=0)\\to 1\\) quando \\(n\\) cresce.290 O SGPV mitiga naturalmente inflação de erro Tipo I em muitas comparações e prioriza relevância científica (não requer ajustes ad hoc).290 27.9 Boas práticas Defina \\(H_0\\) intervalar e \\(\\delta\\) a priori com justificativa científica.290,291 Reporte: estimativa pontual, IC, limites de equivalência e \\(p_{\\delta}\\); interprete \\(p_{\\delta}\\in{0,1}\\) de forma dicotômica e \\(0&lt;p_{\\delta}&lt;1\\) como inconclusivo; quando necessário, complemente com TOST.290,291 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["testes-estatisticos.html", "Capítulo 28 Testes estatísticos 28.1 Testes de Qui-quadrado (\\(\\chi^2\\)) 28.2 Teste exato de Fisher", " Capítulo 28 Testes estatísticos 28.1 Testes de Qui-quadrado (\\(\\chi^2\\)) Teste Qui-quadrado (com correção de Yates) Tumor Response 0 1 Total P-valor Chemotherapy Treatment0.637 Drug A672895 Drug B653398 Total13261193 Teste qui-quadrado de independência Teste Qui-quadrado (sem correção de Yates) Tumor Response 0 1 Total P-valor Chemotherapy Treatment0.530 Drug A672895 Drug B653398 Total13261193 Teste qui-quadrado de independência 28.2 Teste exato de Fisher Teste exato de Fisher Tumor Response 0 1 Total P-valor Chemotherapy Treatment0.540 Drug A672895 Drug B653398 Total13261193 Teste exato de Fisher /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, "],["comparacao.html", "Capítulo 29 Comparação 29.1 Análise inferencial de comparação 29.2 F-teste", " Capítulo 29 Comparação 29.1 Análise inferencial de comparação 29.1.1 O que é análise de comparação de dados? .REF? O pacote cocor292 fornece as funções cocor.indep.groups, cocor.dep.groups.overlap e cocor.dep.groups.nonoverlap para comparar 2 coeficientes de correlação entre grupos independentes, grupos sobrepostos ou independentes, respectivamente.292 29.2 F-teste 29.2.1 O que é o F-teste? O F-teste é uma estatística que compara a variabilidade entre grupos com a variabilidade dentro dos grupos.REF? A estatística é calculada como \\(F=\\dfrac{\\text{QM}_{\\text{entre}}}{\\text{QM}_{\\text{dentro}}}\\), onde \\(\\text{QM}\\) são “quadrados médios”, com \\(gl_{1}\\) e \\(gl_{2}\\) definidos pelo desenho (ex.: fatores e resíduos).REF? 29.2.2 Quando usar o F-teste? ANOVA de um fator (≥3 grupos) e ANOVA multifatorial (efeitos principais e interações).REF? GLM / regressão linear: teste global \\(H_{0}:\\beta_{1}=\\cdots=\\beta_{p}=0\\).REF? ANCOVA (comparação de grupos ajustando covariáveis).REF? Contrastes planejados ou pós-hoc (usando a razão F correspondente).REF? 29.2.3 Quais são os pressupostos? Observações independentes.REF? Normalidade (aproximada) dos resíduos.REF? Homogeneidade de variâncias entre grupos (homoscedasticidade).REF? Se houver violações importantes: considerar ANOVA de Welch, transformações apropriadas ou alternativas não paramétricas (ex.: Kruskal–Wallis para um fator).REF? 29.2.4 Como interpretar o resultado? Valor de \\(F\\) elevado com \\(P&lt;\\alpha\\) indica evidência contra \\(H_{0}\\) (diferenças entre grupos/modelo com ajuste significativo).REF? Relate sempre \\(gl_{1}\\), \\(gl_{2}\\), \\(F\\) e \\(P\\), além de um tamanho de efeito (ex.: \\(\\eta^{2}\\), \\(\\eta^{2}_{p}\\) ou \\(\\omega^{2}\\)) e intervalo de confianca quando possível.REF? Após rejeitar \\(H_{0}\\), use contrastes ou pós-hoc com ajuste para múltiplas comparações para localizar as diferenças.REF? 29.2.5 O que reportar em publicações? Estrutura do desenho (fatores, níveis, balanceamento).REF? Verificação/diagnóstico dos pressupostos.REF? Estatística \\(F\\) com \\(gl\\) e \\(P\\).REF? Tamanho de efeito e intervalo de confiança.REF? Método de ajuste para múltiplas comparações quando aplicável.REF? /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["associacao.html", "Capítulo 30 Associação 30.1 Análise inferencial de associação 30.2 Associação bivariada 30.3 Associação multivariada", " Capítulo 30 Associação 30.1 Análise inferencial de associação 30.1.1 O que é análise de associação? .REF? 30.2 Associação bivariada 30.2.1 O que são análises de associação bivariada? .REF? 30.2.2 Quais testes podem ser usados para análises de associação bivariada? Teste Qui-quadrado (\\(\\chi^2\\)).293,294 O teste qui-quadrado (\\(\\chi^2\\)) avalia uma hipótese global se a relação entre duas variáveis e/ou fatores é independente ou associada.294 O teste qui-quadrado é utilizado para comparar a distribuição de uma variável categórica em uma amostra ou grupo com a distribuição em outro. Se a distribuição da variável categórica não for muito diferente nos diferentes grupos, pode-se concluir que a distribuição da variável categórica não está relacionada com a variável dos grupos. Pode-se também concluir que a variável categórica e os grupos são independentes.294 Tipo: não paramétrico.293,294 Suposições:293,294 As variáveis são ordinais ou categóricas nominais, de modo que as células representem frequência. Os níveis dos fatores (variáveis categóricas) são mutuamente exclusivos. Tamanho de amostra grande e adequado porque é baseado em uma abordagem de aproximação. Menos de 20% das células com frequências esperadas &lt; 5 Nenhuma célula com frequência esperada &lt; 1. Hipóteses:294 Nula (\\(H_{0}\\)): independente (sem associação) Alternativa (\\(H_{1}\\)): não independente (associação) Tamanho do efeito:294 Phi (\\(\\phi\\)), para tabelas de contingência 2x2 Razão de chances (\\(RC\\) ou \\(OR\\)), para tabelas de contingência 2x2 Cramer V (\\(V\\)), para tabelas de contingência NxM O pacote gtsummary211 fornece a função tbl_cross para criar uma tabela NxM. Teste Exato de Fisher (\\(\\chi^2\\)).293,294 O teste exato de Fisher avalia a hipótese nula de independência aplicando a distribuição hipergeométrica dos números nas células da tabela.294 Hipóteses:293,294 Nula (\\(H_{0}\\)): independente (sem associação) Alternativa (\\(H_{1}\\)): não independente (associação) Tamanho do efeito:293,294 Phi (\\(\\phi\\)), para tabelas de contingência 2x2 Razão de chances (\\(RC\\) ou \\(OR\\)), para tabelas de contingência 2x2 Cramer V (\\(V\\)), para tabelas de contingência NxM O pacote gtsummary211 fornece a função tbl_cross para criar uma tabela NxM. 30.3 Associação multivariada 30.3.1 O que são análises de associação multivariada? .REF? 30.3.2 Quais testes podem ser usados para análises de associação multivariada? .REF? /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["correlacao.html", "Capítulo 31 Correlação 31.1 Análise inferencial de correlação 31.2 Coeficientes de correlação 31.3 Colinearidade", " Capítulo 31 Correlação 31.1 Análise inferencial de correlação 31.1.1 O que é covariância? .REF? 31.1.2 O que é correlação? .REF? 31.1.3 Qual é a interpretação das medidas de correlação? Os valores de correlação estão no intervalo \\([-1; 1]\\).111,295,296 Valores de correlação positivos representam uma relação direta entre as variáveis, tal que valores maiores de uma variável estão associados a valores maiores de outra variável.295,296 Valores de correlação negativos representam uma relação indireta (ou inversa) entre as variáveis, tal que valores maiores (menores) de uma variável estão associados a valores maiores (menores) de outra variável.295,296 Valores de correlação próximos de \\(0\\) representam a inexistência de relação entre as variáveis.295,296 Figura 31.1: Exemplo de diferentes forças e direção de correlação entre duas variáveis X e Y. 31.1.4 Quais precauções devem ser tomadas na interpretação de medidas de correlação? Tamanhos de efeito grande (ou qualquer outro) não representam necessariamente uma relação causa-efeito entre as variáveis.295 Tamanhos de efeito grande (ou qualquer outro) não representam necessariamente uma relação de concordância ou confiabilidade entre as variáveis.295 Uma escala de medição com representação agregada do constructo na coleta de dados pode subestimar o tamanho do efeito da correlação \\(r\\) em de cerca de 13% e do coeficiente de determinação \\(R^2\\) de cerca de 30%.124 Neste caso, a correlação desatenuada \\(r_{x&#39;y&#39;}\\) pode ser calculada por (31.1), utilizando a correlação observada \\(r_{xy}\\) e os fatores de correção \\(r_{xx&#39;}\\) e \\(r_{yy&#39;}\\) para o número de intervalos nas variáveis X e Y, respectivamennte:124 \\[\\begin{equation} \\tag{31.1} r_{x&#39;y&#39;} = \\dfrac{r_{xy}}{r_{xx&#39;}r_{yy&#39;}} \\end{equation}\\] O pacote psychmeta297 fornece a função correct_r_coarseness para calcular o coeficiente de correlação desatenuado (\\(r_{x&#39;y&#39;}\\)). O pacote psychmeta297 fornece a função correct_r para calcular o coeficiente de correlação em escala restrita e/ou com erro de mensuração (\\(r_{x&#39;y&#39;}\\)). Os coeficientes de correlação possuem suposições que, se violadas, podem levar a interpretações equivocadas. Nestes cenários, visualizar os dados e as relações entre as variáveis pode contribuir com a interpretação e utilidade dos coeficientes de correlação.298 O quarteto de Anscombe é um conjunto de quatro bancos de dados bivariados que possuem a mesma média, variância, correlação e regressão linear (até a 2a casa decimal), mas que são visualmente diferentes e, assim, demonstram a importância da análise gráfica da correlação.298 Tabela 31.1: Quarteto de Anscombe. ID x1 x2 x3 x4 y1 y2 y3 y4 1 10 10 10 8 8.04 9.14 7.46 6.58 2 8 8 8 8 6.95 8.14 6.77 5.76 3 13 13 13 8 7.58 8.74 12.74 7.71 4 9 9 9 8 8.81 8.77 7.11 8.84 5 11 11 11 8 8.33 9.26 7.81 8.47 6 14 14 14 8 9.96 8.10 8.84 7.04 7 6 6 6 8 7.24 6.13 6.08 5.25 8 4 4 4 19 4.26 3.10 5.39 12.50 9 12 12 12 8 10.84 9.13 8.15 5.56 10 7 7 7 8 4.82 7.26 6.42 7.91 11 5 5 5 8 5.68 4.74 5.73 6.89 Tabela 31.1: Análise descritiva do Quarteto de Anscombe demostrando os conjuntos de dados bivariados com parâmetros quase idênticos. X1Y1 X2Y2 X3Y3 X4Y4 Observações 11.00 11.00 11.00 11.00 Média x 9.00 9.00 9.00 9.00 Média y 7.50 7.50 7.50 7.50 Variância x 11.00 11.00 11.00 11.00 Variância y 4.13 4.13 4.12 4.12 Correlação 0.82 0.82 0.82 0.82 Coeficiente angular 0.50 0.50 0.50 0.50 Coeficiente linear 3.00 3.00 3.00 3.00 Coeficiente de determinação 0.67 0.67 0.67 0.67 Figura 31.2: Gráfico de dispersão do Quarteto de Anscombe para representação gráfica de conjuntos de dados bivariados com parâmetros quase idênticos e relações muito distintas. O pacote anscombiser299 fornece a função anscombise para gerar bancos de dados que compartilham os mesmos valores de parâmetros do Quarteto de Anscombe. 31.2 Coeficientes de correlação 31.2.1 Quais coeficientes podem ser usados em análises de correlação? Coeficiente de correlação de Pearson (\\(r\\)).295,296 O coeficiente de correlação de Pearson (\\(r\\)) avalia a força e direção da relação linear entre duas variáveis quantitativas.295,296 Tipo: paramétrico.295,296 Hipóteses:296 Nula (\\(H_{0}\\)): \\(r=0\\) Alternativa (\\(H_{1}\\)): \\(r≠0\\) Tamanho do efeito:295,296 Coeficiente de correlação de Pearson (\\(r\\)) O pacote stats140 fornece a função cor.test para calcular o coeficiente de correlação de Pearson (\\(r\\)). O pacote correlation300 do projeto easystats301 fornece a função correlation para calcular o coeficiente de correlação de Pearson (\\(r\\)). Coeficiente de correlação ponto-bisserial (\\(r_{s}\\)).295 O coeficiente de correlação ponto-bisserial (\\(r_{s}\\)) avalia a força e direção da relação linear entre uma variável quantitativa e outra dicotômica.295 Tipo: paramétrico.295 Hipóteses:295 Nula (\\(H_{0}\\)): \\(r_{s}=0\\) Alternativa (\\(H_{1}\\)): \\(r_{s}≠0\\) Tamanho do efeito:295 Coeficiente de correlação ponto-bisserial (\\(r_{s}\\)) O pacote stats140 fornece a função cor.test para calcular o coeficiente de correlação ponto-bisserial (\\(r_{s}\\)). O pacote correlation300 do projeto easystats301 fornece a função correlation para calcular o coeficiente de correlação ponto-bisserial (\\(r_{s}\\)). Coeficiente de correlação de Spearman (\\(\\rho\\)).295,296 O coeficiente de correlação de Spearman (\\(\\rho\\)) avalia a força e direção da relação monotônica entre duas variáveis quantitativas.295,296 O coeficiente de correlação de Spearman (\\(\\rho\\)) pode ser também definida como a correlação de Pearson (\\(r\\)) entre as classificações (ranks) das duas variáveis quantitativas.295,296 Tipo: não-paramétrico.295,296 Hipóteses:295,296 Nula (\\(H_{0}\\)): \\(\\rho=0\\) Alternativa (\\(H_{1}\\)): \\(\\rho≠0\\) Tamanho do efeito:295,296 Coeficiente de correlação de Spearman (\\(\\rho\\)) O pacote stats140 fornece a função cor.test para calcular o coeficiente de correlação de Spearman (\\(\\rho\\)). O pacote correlation300 do projeto easystats301 fornece a função correlation para calcular o coeficiente de correlação de Spearman (\\(\\rho\\)). Coeficiente de Kendall (\\(\\tau\\)).295,296 O coeficiente Kendall \\(\\tau\\) avalia a força e direção da relação monotônica entre duas variáveis quantitativas ou qualitativas.295,296 O coeficiente Kendall \\(\\tau\\) é definido como a proporção de todos os pares concordantes menos a proporção de todos os pares discordantes.295,296 Tipo: não-paramétrico.295,296 Hipóteses:295,296 Nula (\\(H_{0}\\)): \\(\\tau=0\\) Alternativa (\\(H_{1}\\)): \\(\\tau≠0\\) Tamanho do efeito:295,296 Kendall \\(\\tau\\) O pacote stats140 fornece a função cor.test para calcular o coeficiente Kendall \\(\\tau\\). O pacote correlation300 do projeto easystats301 fornece a função correlation para calcular o coeficiente coeficiente Kendall \\(\\tau\\). Coeficiente de Cramér (\\(V\\)).REF? O coeficiente Cramér (\\(V\\)) avalia a força e direção da relação entre duas variáveis qualitativas.REF? Tipo: não-paramétrico.REF? Hipóteses:REF? Nula (\\(H_{0}\\)): \\(V=0\\) Alternativa (\\(H_{1}\\)): \\(V≠0\\) Tamanho do efeito:REF? Coeficiente Cramer (\\(V\\)) Coeficiente de Sheperd \\(\\phi\\).REF? O coeficiente Phi (\\(\\phi\\)) avalia a força e direção da relação entre duas variáveis dicotômicas.REF? Tipo: não-paramétrico.REF? Hipóteses:REF? Nula (\\(H_{0}\\)): \\(\\phi=0\\) Alternativa (\\(H_{1}\\)): \\(\\phi≠0\\) Tamanho do efeito:REF? Coeficiente Phi (\\(\\phi\\)) O pacote correlation300 do projeto easystats301 fornece a função correlation para calcular o coeficiente coeficiente Sheperd \\(\\phi\\). O pacote corrplot225 fornece a função cor.mtest para calcular os P-valores e intervalos de confiança da matriz de correlação. O pacote corrplot225 fornece a função corrplot para visualização da matriz de correlação. 31.3 Colinearidade 31.3.1 O que é colinearidade? Colinearidade representa a correlação entre duas variáveis.302 Colinearidade exata indica uma relação linear perfeita entre duas variáveis.302 31.3.2 Como identificar colinearidade na matriz de correlação? A colinearidade pode ser identificada na matriz de correlação por meio da análise dos coeficientes de correlação entre as variáveis.302 Valores de correlação próximos de \\(1\\) ou \\(-1\\) indicam colinearidade entre as variáveis.302 O pacote GGally303 fornece a função ggally_cor para estimar a correlação bivariada e exibir o coeficiente de correlação e o P-valor na matriz de correlação.303 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["regressao.html", "Capítulo 32 Regressão 32.1 Análise de regressão 32.2 Estruturas de análise de regressão 32.3 Tipos e famílias de modelos de regressão 32.4 Preparação de variáveis 32.5 Multicolinearidade 32.6 Redução de dimensionalidade 32.7 Suposições dos modelos de regressão", " Capítulo 32 Regressão 32.1 Análise de regressão 32.1.1 O que é regressão? Regressão refere-se a uma equação matemática que permite que uma ou mais variável(is) de desfecho (dependentes) seja(m) prevista(s) a partir de uma ou mais variável(is) independente(s). A regressão implica em uma direção de efeito, mas não garante causalidade.268 Para estimar os efeitos imparciais de um fator de exposição primária sobre uma variável de desfecho, frequentemente constroem-se modelos estatísticos de regressão.220 O pacote modelsummary304 fornece as funções modelsummary e modelplot para gerar tabelas e gráficos de coeficientes de regressão. O pacote gtsummary211 fornece a função tbl_regression para construção da ‘Tabela 2’ com dados do modelo de regressão. 32.1.2 Quais são os algoritmos de regressão? Linear: Simples, Múltipla, Polinomial.REF? Linear generalizado: Binomial (logística), Multinomial, Ordinal, Poisson, Binomial negativa, Gama.REF? Não-linear (nos parâmetros).REF? Aditivo generalizado.REF? Efeitos mistos: Linear, Generalizado.REF? Sobrevida: Cox, Weibull, Exponencial, Log-normal, Log-logístico.REF? Regularização: Ridge, Lasso.REF? 32.2 Estruturas de análise de regressão 32.2.1 O que são análises de regressão simples? A análise de regressão simples consiste em modelos estatísticos com uma variável dependente (desfecho) e uma variável independente (preditor).305 A equação de regressão simples é expressa como (32.1), onde \\(Y\\) é a variável dependente, \\(X\\) é a variável independente, \\(\\beta_0\\) é o intercepto (constante), \\(\\beta_1\\) é o coeficiente de regressão da variável independente e \\(\\epsilon\\) representa o erro aleatório do modelo.305 \\[\\begin{equation} \\tag{32.1} Y = \\beta_0 + \\beta_1 X + \\epsilon \\end{equation}\\] 32.2.2 O que são análises de regressão multivariável? A análise multivariável (ou múltiplo) consiste em modelos estatísticos com uma variável dependente (desfecho) e duas ou mais variáveis independentes.305 A equação de regressão multivariável é expressa como (32.2), onde \\(Y\\) é a variável dependente, \\(X_1, X_2, ..., X_n\\) são as variáveis independentes, \\(\\beta_0\\) é o intercepto (constante), \\(\\beta_1, \\beta_2, ..., \\beta_n\\) são os coeficientes de regressão das variáveis independentes e \\(\\epsilon\\) representa o erro aleatório do modelo.305 \\[\\begin{equation} \\tag{32.2} Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n + \\epsilon \\end{equation}\\] 32.2.3 O que são análises de regressão multivariada? A análise multivariada consiste em modelos estatísticos com duas ou mais variáveis dependente (desfechos) e duas ou mais variáveis independentes.305 A equação de regressão multivariada é expressa como (32.3), onde \\(Y_1, Y_2, ..., Y_m\\) são as variáveis dependentes, \\(X_1, X_2, ..., X_n\\) são as variáveis independentes, \\(\\beta_{0j}\\) é o intercepto (constante) da variável dependente \\(Y_j\\), \\(\\beta_{ij}\\) são os coeficientes de regressão das variáveis independentes para a variável dependente \\(Y_j\\) e \\(\\epsilon_j\\) representa o erro aleatório do modelo para a variável dependente \\(Y_j\\).305 \\[\\begin{align} \\tag{32.3} Y_1 &amp;= \\beta_{01} + \\beta_{11} X_1 + \\beta_{12} X_2 + \\dots + \\beta_{1n} X_n + \\epsilon_1 \\\\ Y_2 &amp;= \\beta_{02} + \\beta_{21} X_1 + \\beta_{22} X_2 + \\dots + \\beta_{2n} X_n + \\epsilon_2 \\\\ &amp;\\vdots \\\\ Y_m &amp;= \\beta_{0m} + \\beta_{m1} X_1 + \\beta_{m2} X_2 + \\dots + \\beta_{mn} X_n + \\epsilon_m \\end{align}\\] 32.3 Tipos e famílias de modelos de regressão 32.3.1 O que são modelos de regressão linear? Modelos lineares (32.4) descrevem uma relação linear nos parâmetros entre um desfecho contínuo \\(Y\\) e um ou mais preditores \\(X\\).REF? \\[\\begin{equation} \\tag{32.4} Y = \\beta_0 + \\sum_{i=1}^{n} \\beta_i X_i + \\epsilon \\end{equation}\\] Assumem erros independentes, de média zero e variância constante (homocedasticidade).REF? A normalidade dos resíduos é uma hipótese comum para inferência estatística, mas não obrigatória para estimação dos coeficientes.REF? Figura 32.1: Regressão linear. 32.3.2 O que são modelos de regressão polinomial? São extensões da regressão linear em que se incluem termos elevados a potências das variáveis independentes (ex.: \\(X^2\\), \\(X^3\\)), permitindo capturar relações curvas.REF? Modelos de regressão polinomial continuam sendo lineares nos parâmetros, por isso ainda se enquadram como um caso particular da regressão linear.REF? Figura 32.2: Regressão polinomial. 32.3.3 O que são modelos de regressão não-linear? São modelos em que a relação entre os parâmetros e a variável resposta não é linear. Podem assumir formas funcionais mais complexas (ex.: exponencial, logarítmica, logística).REF? Importante diferenciar “não-linear na variável” (ex.: polinomial) de “não-linear no parâmetro” (ex.: modelos logísticos de crescimento).REF? Figura 32.3: Regressão não-linear. 32.3.4 O que são modelos de regressão logística? Modelos logísticos são casos de regressão linear generalizada em que a resposta \\(Y\\) é binária.REF? A equação (32.5) modela a razão de chances (odds) em função dos preditores.REF? \\[\\begin{equation} \\tag{32.5} \\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 X + ... + \\beta_n X_n \\end{equation}\\] A ligação (link) usada é o logit (32.6).REF? \\[\\begin{equation} \\tag{32.6} g(p) = \\log\\left(\\frac{p}{1-p}\\right) \\end{equation}\\] Figura 32.4: Regressão logística. 32.3.5 O que são modelos de regressão multinomial? Modelos de regressão multinomial são usados quando a variável resposta é categórica com mais de dois níveis não ordenados.REF? Estendem a regressão logística binária, modelando as razões de chances (odds ratios) de cada categoria em relação a uma categoria de referência.REF? Figura 32.5: Regressão multinomial 32.3.6 O que são modelos de regressão ordinal? Modelos de regressão ordinal são usados quando a variável resposta é categórica com mais de dois níveis ordenados.REF? Modelam a probabilidade acumulada de estar em ou abaixo de cada categoria, usando uma função de ligação logit, probit ou log-log.REF? Assumem a proporcionalidade dos coeficientes entre as categorias (proportional odds).REF? 32.3.7 O que são modelos de regressão de Poisson? Modelos de regressão de Poisson são usados quando a variável resposta é uma contagem de eventos não negativos.REF? Assumem que \\(Y \\sim Poisson(\\mu)\\), com \\(\\mu = E[Y|X]\\) relacionado aos preditores via função de ligação log.REF? A sobre-dispersão (variância maior que a média) pode exigir modelos alternativos como a regressão binomial negativa.REF? Figura 32.6: Regressão de Poisson. 32.3.8 O que são modelos de regressão binomial negativa? Modelos de regressão binomial negativa são usados para contagens superdispersas, onde a variância excede a média.REF? Introduzem um parâmetro de dispersão adicional para modelar a variabilidade extra.REF? A função de ligação log é comumente usada, semelhante à regressão de Poisson.REF? 32.3.9 O que são modelos de regressão Gama? Modelos de regressão Gama são usados para variáveis resposta contínuas e positivas, frequentemente com distribuição assimétrica.REF? A função de ligação log é comumente usada para garantir predições positivas.REF? 32.3.10 O que são modelos de regressão com efeitos mistos? Modelos de efeitos mistos incorporam efeitos fixos (coeficientes comuns a todos os indivíduos) e efeitos aleatórios (variações específicas de grupos ou indivíduos).REF? Usados para dados hierárquicos ou longitudinais, onde observações estão agrupadas.REF? Permitem modelar correlações intra-grupo e variabilidade entre grupos.REF? 32.3.11 O que são modelos de regressão com efeitos mistos generalizados? Modelos de efeitos mistos generalizados (GLMM) estendem os modelos de efeitos mistos para variáveis resposta que seguem distribuições da família exponencial (ex.: binomial, Poisson).REF? Combinam a flexibilidade dos modelos lineares generalizados com a capacidade de modelar correlações e variabilidade entre grupos.REF? Usados para dados hierárquicos ou longitudinais com desfechos não normais.REF? 32.3.12 O que são modelos de regressão ridge? Regressão ridge é um modelo linear regularizado que adiciona uma penalização L2 à soma dos quadrados dos coeficientes.REF? Ajuda a reduzir multicolinearidade e overfitting, encolhendo os coeficientes em direção a zero, mas nunca os tornando exatamente nulos.REF? O hiperparâmetro de regularização é \\(\\lambda\\), controlando a intensidade da penalização. Valores maiores de \\(\\lambda\\) resultam em maior encolhimento dos coeficientes.REF? Figura 32.7: Regressão ridge. 32.3.13 O que são modelos de regressão lasso? Regressão lasso (Least Absolute Shrinkage and Selection Operator) utiliza penalização L1, que pode zerar coeficientes.REF? Além de reduzir overfitting, também realiza seleção automática de variáveis.REF? Enquanto a regressão ridge mantém todos os preditores, a lasso pode excluir variáveis irrelevantes.REF? 32.4 Preparação de variáveis 32.4.1 Como preparar as variáveis categóricas para análise de regressão? Variáveis fictícias (dummy) compreendem variáveis criadas para introduzir, nos modelos de regressão, informações contidas em outras variáveis que não podem ser medidas em escala numérica.306 Variáveis categóricas nominais, com 2 ou mais níveis, devem ser subdivididas em variáveis fictícias dicotômicas para ser usada em modelos de regressão.307 Cada nível da variável categórica nominal será convertido em uma nova variável fictícias dicotômica, tal que a nova variável dicotômica assume valor 1 para a presença do nível correspondente e 0 em qualquer outro caso.307 O pacote fastDummies308 fornece a função dummy_cols para preparar as variáveis categóricas fictícias para análise de regressão. 32.4.2 Por que é comum escolher a categoria mais frequente como referência em modelos epidemiológicos? Maior estabilidade estatística: a categoria mais frequente costuma gerar estimativas mais estáveis, com menor erro padrão nos coeficientes das demais categorias.REF? A escolha da referência não altera o ajuste nem o valor predito pelo modelo — apenas muda o ponto de comparação.REF? 32.5 Multicolinearidade 32.5.1 O que é multicolinearidade? Multicolinearidade representa a intercorrelação entre as variáveis independentes (explanatórias) de um modelo.302 32.5.2 Como diagnosticar multicolinearidade de forma quantitativa? Verifique a existência de multicolinearidade entre as variáveis candidatas.309 O Coeficiente de determinação (\\(R^2\\)) é uma medida de quão bem as variáveis independentes explicam a variabilidade da variável dependente. Valores próximos a 1 indicam que as variáveis independentes estão fortemente correlacionadas entre si, o que pode indicar multicolinearidade.302 O Fator de Inflação da Variância (variance inflation factor, VIF) é uma medida que quantifica o quanto a variância de um coeficiente de regressão é inflacionada devido à multicolinearidade. Valores de VIF maiores que 10 são frequentemente considerados indicativos de multicolinearidade significativa.302 O recíproco da VIF é chamado de Tolerância, que mede a proporção da variância de uma variável independente que não é explicada pelas outras variáveis independentes. Valores baixos de Tolerância (geralmente abaixo de 0.1) indicam multicolinearidade.302 O número de condições (Condition Number) é uma medida que avalia a estabilidade numérica de um modelo de regressão. Valores altos (entre 10 de 30) indicam multicolinearidade, e valores maiores que 30 indicam forte multicolinearidade.302 Figura 32.8: Multicolinearidade entre variáveis candidatas em modelos de regressão multivariável. O pacote GGally303 fornece a função ggpairs para criar uma matriz gráfica de correlações bivariadas. O pacote car310 fornece a função vif para calcular o fator de inflação da variância (VIF). 32.5.3 O que fazer em caso de multicolinearidade elevada? Verifique a transformação (codificação) de variáveis numéricas em categóricas.302 Aumente o tamanho da amostra, se possível, para reduzir a multicolinearidade.302 Combine níveis de variáveis categóricas com baixa frequência de ocorrência.302 Combine variáveis numéricas altamente correlacionadas em uma única variável composta, como a média ou soma das variáveis.302 Considere a exclusão de variáveis altamente correlacionadas do modelo, especialmente se elas não forem essenciais para a análise.302 Use técnicas de seleção de variáveis, como seleção passo a passo, para identificar e remover variáveis redundantes.302 Use técnicas de regularização, como regressão ridge ou lasso, que podem lidar com multicolinearidade ao penalizar coeficientes de regressão.302 32.6 Redução de dimensionalidade 32.6.1 Correlação bivariada pode ser usada para seleção de variáveis em modelos de regressão multivariável? Seleção bivariada de variáveis - isto é, aplicação de testes de correlação em pares de variáveis candidatas e variável de desfecho afim de selecionar quais serão incluídas no modelo multivariável - é um dos erros mais comuns na literatura.289,309,311 A seleção bivariada de variáveis torna o modelo mais suscetível a otimismo no ajuste se as variáveis de confundimento não são adequadamente controladas.309,311 32.6.2 Variáveis sem significância estatística devem ser excluídas do modelo final? Eliminar uma variável de um modelo significa anular o seu coeficiente de regressão (\\(\\beta = 0\\)), mesmo que o valor estimado pelos dados seja outro. Desta forma, os resultados se afasTAM de uma solução de máxima verossimilhança (que tem fundamento teórico) e o modelo resultante é intencionalmente subótimo.289 Os coeficientes de regressão geralmente dependem do conjunto de variáveis do modelo e, portanto, podem mudam de valor (“mudança na estimativa” positiva ou negativa) se uma (ou mais) variável(is) for(em) eliminada(s) do modelo.289 32.6.3 Por que métodos de regressão gradual não são recomendados para seleção de variáveis em modelos de regressão multivariável? Métodos diferentes de regressão gradual podem produzir diferentes seleções de variáveis de um mesmo banco de dados.307 Nenhum método de regressão gradual garante a seleção ótima de variáveis de um banco de dados.307 As regras de término da regressão baseadas em P-valor tendem a ser arbitrárias.307 32.6.4 O que pode ser feito para reduzir o número de variáveis candidatas em modelos de regressão multivariável? Em caso de uma proporção baixa entre o número de participantes e de variáveis, use o conhecimento prévio da literatura para selecionar um pequeno conjunto de variáveis candidatas.309 Colapse categorias com contagem nula (células com valor igual a 0) de variáveis candidatas.309 Use simulações de dados para identificar qual(is) variável(is) está(ão) causando problemas de convergência do ajuste do modelo.309 A eliminação retroativa tem sido recomendada como a abordagem de regressão gradual mais confiável entre aquelas que podem ser facilmente alcançadas com programas de computador.289 32.6.5 Quando devemos forçar uma variável no modelo? Sempre que houver base teórica ou evidência prévia forte, ou se for a variável de exposição principal.312 32.7 Suposições dos modelos de regressão 32.7.1 Quais suposições são feitas para regressão? As suposições dos modelos de regressão incluem linearidade, independência, homocedasticidade, normalidade dos resíduos e ausência de multicolinearidade.REF? 32.7.2 Como avaliar as suposições de uma regressão? Usando diagnóstico de regressão (ex.: análise de resíduos, gráficos de valores observados vs. preditos) e comparação com análises estratificadas.312 Figura 32.9: Diagnóstico de regressão para avaliar suposições do modelo: linearidade, normalidade dos resíduos, homocedasticidade e alavancagem. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["redes.html", "Capítulo 33 Redes 33.1 Análise de redes", " Capítulo 33 Redes 33.1 Análise de redes 33.1.1 O que é análise de rede? .REF? /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, "],["parte-7.html", "PARTE 7: MODELAGEM Estratégias para entender relações complexas, prever resultados e explorar padrões ocultos", " PARTE 7: MODELAGEM Estratégias para entender relações complexas, prever resultados e explorar padrões ocultos "],["modelos.html", "Capítulo 34 Modelos 34.1 Modelos 34.2 Modelos estocásticos 34.3 Preditores e desfechos 34.4 Suposições dos modelos 34.5 Fome de dados 34.6 Desempenho e estabilidade de modelos 34.7 Avaliação de modelos 34.8 Validação de modelos 34.9 Calibração de modelos 34.10 Comparação de modelos", " Capítulo 34 Modelos 34.1 Modelos 34.1.1 O que são modelos? Modelos são representações simplificadas de um sistema real, usados para entender, prever ou controlar fenômenos complexos.REF? 34.1.2 O que é modelagem? Modelagem é o processo de usar dados para selecionar um modelo matemático explícito que represente o processo gerador dos dados.312 34.1.3 Por que a escolha do modelo é complexa? Há inúmeras combinações possíveis de variáveis, formas funcionais (lineares, quadráticas, transformações), interações e formas do desfecho, o que torna o espaço de possibilidades muito amplo.312 Todos os modelos são errados, mas alguns são úteis.313 O pacote equatiomatic314 fornece a função extract_eq para extrair a equação dos modelos em formato LaTeX para visualização. 34.1.4 O que diferencia modelos clássicos e modernos em predição? Modelos clássicos, como a regressão logística e as árvores de decisão, contrastam com os modelos modernos, como máquinas de vetor de suporte, redes neurais e random forests , principalmente pela maior flexibilidade e capacidade destes últimos de capturar não linearidades e interações.315 34.2 Modelos estocásticos 34.2.1 O que são modelos estocásticos? .REF? 34.2.2 O que são cadeias de Markov? As cadeias de Markov descrevem processos em que o estado futuro depende apenas do estado presente, e não da trajetória passada.316 Figura 34.1: Cadeia de Markov com 3 estados (a, b, c) e suas probabilidades de transição. Figura 34.2: Trajetória de estados e proporção acumulada por estado em uma cadeia de Markov com 3 estados (a, b, c). O pacote markovchain317 fornece a função markovchainFit ajusta uma cadeia com base em dados observados. 34.3 Preditores e desfechos 34.3.1 O que são desfechos de um modelo? .REF? 34.3.2 O que são preditores de um modelo? .REF? 34.3.3 Como selecionar preditores para um modelo? .REF? 34.4 Suposições dos modelos 34.4.1 Quais suposições são feitas para modelagem? .REF? 34.4.2 Como avaliar as suposições de um modelo? .REF? O pacote performance249 fornece a função check_model para analisar a colinearidade entre variáveis, a normalidade da distribuição das variáveis e a heteroscedasticidade. 34.5 Fome de dados 34.5.1 O que significa “fome de dados”? Data hungry descreve a necessidade de um modelo contar com muitos eventos por variável (EPV) para alcançar estabilidade estatística. Enquanto a regressão logística (LR) atinge desempenho estável com cerca de 20–50 EPV, modelos como random forest (RF), redes neurais (NN) e máquinas de vetor de suporte (SVM) podem demandar &gt;200 EPV para reduzir o otimismo e estabilizar a AUC. 34.5.2 Por que a “fome de dados” é relevante? Em bases de dados pequenas, modelos clássicos tendem a ser mais robustos e menos suscetíveis a superajuste.315 O uso de modelos modernos só se justifica quando há grandes bases de dados, caso contrário o ganho em acurácia é marginal.315 Esse conceito conecta diretamente a escolha do modelo ao planejamento amostral.315 34.6 Desempenho e estabilidade de modelos 34.6.1 Como avaliar o desempenho dos modelos? Pela área sob a curva ROC em conjunto com o otimismo (diferença entre AUC aparente e validada).315 O desempenho melhora com maior tamanho amostral, mas de forma desigual entre técnicas.315 34.6.2 Qual modelo alcança estabilidade mais rapidamente? Regressão logística é o mais estável e menos data hungry.315 Árvore de decisão para classificação e regressão estabiliza rápido, mas em nível de desempenho baixo.315 Máquina de vetores de suporte, redes neurais e random forests apresentam instabilidade mesmo em amostras muito grandes.315 34.7 Avaliação de modelos 34.7.1 Como avaliar a qualidade de ajuste de um modelo? Coeficiente de determinação (\\(R^2\\)) e \\(R^2\\) ajustado: Medem a proporção da variabilidade dos dados explicada pelo modelo. O \\(R^2\\) ajustado penaliza a inclusão de variáveis irrelevantes.REF? Figura 34.3: Exemplos de ajuste de modelos de regressão linear simples (y ~ x) com diferentes níveis de ruído (R²). Cada painel mostra a reta ajustada (cinza) e os valores observados (pontos). Os valores anotados indicam o coeficiente angular simulado (β), o coeficiente angular estimado (β̂) e o R² observado. Erro quadrático médio (\\(RMSE\\)): Mede a média dos erros ao quadrado entre os valores observados e os valores previstos pelo modelo. Valores menores indicam melhor ajuste.REF? Critério de Informação Akaike (\\(AIC\\)) e Critério de Informação Bayesiano (\\(BIC\\)): Avaliam o ajuste do modelo penalizando a complexidade (número de parâmetros). Modelos com menor AIC ou BIC são preferíveis.REF? Desvio residual (\\(\\sigma\\)): Mede a variabilidade dos resíduos do modelo. Valores menores indicam melhor ajuste.REF? Tabela 34.1: Métricas de desempenho do modelo de regressão linear. Métrica Valor AIC 513.017 AIC corrigido 513.267 BIC 520.833 \\(R^2\\) 0.007 \\(R^2\\) ajustado -0.003 Erro quadrático médio (RMSE) 3.053 Desvio residual (sigma) 3.084 O pacote performance249 fornece a função model_performance para calcular as métricas de ajuste da regressão adequadas ao modelo pré-especificado. O pacote performance249 fornece a função compare_performance para comparar o desempenho e a qualidade do ajuste de diversos modelos de regressão pré-especificados. 34.8 Validação de modelos 34.8.1 Como validar modelos estatísticos? .REF? 34.9 Calibração de modelos 34.9.1 Como calibrar modelos estatísticos? .REF? 34.10 Comparação de modelos 34.10.1 Como comparar modelos de aprendizagem de máquina? .REF? O pacote correctR318 fornece funções para comparar o desempenho e a qualidade do ajuste de diversos modelos de aprendizagem de máquina em amostras correlacionadas. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["modelagem-temporal.html", "Capítulo 35 Modelagem temporal 35.1 Modelos temporais", " Capítulo 35 Modelagem temporal 35.1 Modelos temporais 35.1.1 O que são modelos temporais? .REF? /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, "],["modelagem-espacial.html", "Capítulo 36 Modelagem espacial 36.1 Modelos espaciais", " Capítulo 36 Modelagem espacial 36.1 Modelos espaciais 36.1.1 O que são modelos espaciais? .REF? /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, "],["modelagem-sobrevida.html", "Capítulo 37 Modelagem de sobrevida 37.1 Sobrevida 37.2 Análise de sobrevida", " Capítulo 37 Modelagem de sobrevida 37.1 Sobrevida 37.1.1 O que é sobrevida? A sobrevida é um termo utilizado em estatística e análise de dados para descrever o tempo que decorre até a ocorrência de um evento específico, como a morte, a falha de um equipamento ou a recidiva de uma doença. Em estudos clínicos, por exemplo, a sobrevida pode referir-se ao tempo que um paciente vive após o diagnóstico de uma doença ou após o início de um tratamento.REF? 37.2 Análise de sobrevida 37.2.1 O que é análise de sobrevida? A análise de sobrevida é uma área da estatística que se concentra no estudo desses tempos até o evento, levando em consideração que nem todos os indivíduos podem ter experimentado o evento durante o período de estudo (censura).REF? Métodos comuns de análise de sobrevida incluem a estimativa da função de sobrevivência, a análise de Kaplan-Meier e modelos de regressão como o modelo de riscos proporcionais de Cox.REF? Figura 37.1: Curvas de Kaplan–Meier simuladas para dois grupos (controle e tratamento). /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, "],["parte-8.html", "PARTE 8: ANÁLISES AVANÇADAS Do avanço estatístico ao poder computacional: Métodos modernos para problemas complexos", " PARTE 8: ANÁLISES AVANÇADAS Do avanço estatístico ao poder computacional: Métodos modernos para problemas complexos "],["redes-meurais.html", "Capítulo 38 Redes neurais 38.1 Neurônios artificiais 38.2 Rede neural artificial 38.3 Espaço de decisão", " Capítulo 38 Redes neurais 38.1 Neurônios artificiais 38.1.1 O que são neurônios artificiais? Neuronios artificiais (ou perceptrons) são modelos matemáticos que imitam o funcionamento dos neurônios biológicos, recebendo entradas, aplicando pesos e uma função de ativação para produzir uma saída.319–321 A equação geral de um neurônio artificial é dada por (38.1), onde \\(x_i\\) são as entradas, \\(w_i\\) os pesos, \\(b\\) o viés e \\(\\phi\\) a função de ativação: \\[\\begin{equation} \\tag{38.1} y = \\phi\\left(\\sum_{i=1}^{d} w_i\\,x_i + b\\right) \\end{equation}\\] Figura 38.1: Representação esquemática de um neurônio computacional. Figura 38.2: Exemplo de um perceptron (regressão logística) para classificação linear. 38.2 Rede neural artificial 38.2.1 O que é uma rede neural? .REF? Figura 38.3: Representação esquemática de uma rede neural. 38.2.2 Quais são as funções de ativação mais comuns? As funções de ativação introduzem não-linearidades nas redes neurais, permitindo que aprendam padrões complexos, como sigmoide (38.2), tangente hiperbólica (38.3) e unidade linear retificada (ReLU) (38.4).REF? \\[\\begin{equation} \\tag{38.2} \\sigma(z) = \\frac{1}{1 + e^{-z}} \\end{equation}\\] \\[\\begin{equation} \\tag{38.3} \\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} \\end{equation}\\] \\[\\begin{equation} \\tag{38.4} \\operatorname{ReLU}(z) = \\max(0, z) \\end{equation}\\] Figura 38.4: Gráficos das funções de ativação mais comuns. 38.3 Espaço de decisão 38.3.1 O que é espaço de decisão? O espaço de decisão é a região do espaço de entrada onde o modelo classifica as entradas em diferentes categorias. Ele é definido pelas fronteiras de decisão aprendidas pelo modelo durante o treinamento.REF? 38.3.2 Como ele é visualizado? O espaço de decisão pode ser visualizado graficamente, especialmente em problemas de classificação binária ou multiclasse, onde as regiões correspondem às classes previstas pelo modelo.REF? Figura 38.5: Comparação do espaço de decisão entre um modelo linear (regressão logística) e um modelo não linear (MLP). /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["aprendizado-maquina.html", "Capítulo 39 Aprendizado de máquina 39.1 Aprendizado de máquina 39.2 Tipos de aprendizado 39.3 Principais algoritmos 39.4 Regressão logística 39.5 Máquina de vetores de suporte 39.6 K-nearest neighbours 39.7 K-means Clustering 39.8 Árvores de decisão 39.9 Análise de componentes principais 39.10 Random forests 39.11 Ensemble 39.12 Desbalanceamento de classes", " Capítulo 39 Aprendizado de máquina 39.1 Aprendizado de máquina 39.1.1 O que é aprendizado de máquina? .REF? 39.2 Tipos de aprendizado 39.2.1 O que é aprendizado supervisionado? .REF? 39.2.2 O que é aprendizado não supervisionado? .REF? 39.2.3 O que é aprendizado semi-supervisionado? .REF? 39.2.4 O que é aprendizado por reforço? .REF? 39.2.5 O que é aprendizado profundo? .REF? 39.2.6 Quais são os limites do progresso em classificadores supervisionados? Os maiores ganhos de acurácia vêm de modelos simples, como análise discriminante linear; métodos mais sofisticados oferecem apenas ganhos marginais.322 O aumento da complexidade do modelo traz retornos decrescentes em termos de redução da taxa de erro.322 39.2.7 Quais problemas práticos limitam a generalização de classificadores? Population drift: mudanças na distribuição dos dados ao longo do tempo degradam a performance de modelos.322 Sample selectivity bias: amostras de treino podem não representar a população futura, levando a superestimação de desempenho.322 Erros de rótulo e definições arbitrárias de classes comprometem a validade dos modelos.322 39.2.8 Por que estudos comparativos entre classificadores podem ser enganosos? Resultados dependem da experiência do pesquisador com cada método, da escolha dos conjuntos de dados e do critério de avaliação usado.322 Diferenças pequenas em acurácia frequentemente desaparecem quando se consideram incertezas reais de aplicação.322 39.3 Principais algoritmos 39.3.1 Quais são os principais algoritmos de aprendizado de máquina? Modelos de regressão não penalizados, modelos de regressão penalizados, modelos baseados em árvores, modelos baseados em vizinhos, redes neurais, máquinas de vetores de suporte, Naive Bayes e ensembles do tipo Superlearner.323 39.4 Regressão logística 39.4.1 O que são é regressão logística? .REF? 39.5 Máquina de vetores de suporte 39.5.1 O que são máquinas de vetores de suporte? .REF? 39.6 K-nearest neighbours 39.6.1 O que é K-nearest neighbours? .REF? 39.7 K-means Clustering 39.7.1 O que é K-means clustering? .REF? 39.8 Árvores de decisão 39.8.1 O que são árvores de decisão? São modelos de aprendizado supervisionado que dividem os dados em ramos e folhas, representando regras de decisão de forma hierárquica.239 Podem lidar eficientemente com grandes conjuntos de dados sem pressupor estrutura paramétrica complexa.238 São aplicáveis a variáveis contínuas e discretas, tanto como preditoras quanto como desfechos.238 Figura 39.1: Exemplo de árvore de decisão para predizer depressão a partir de idade, tabagismo e sintomas. 39.8.2 Quais são os principais usos de árvores de decisão? Seleção de variáveis relevantes em cenários com muitos preditores, como registros clínicos eletrônicos.238 Avaliação da importância relativa das variáveis, com base na redução da pureza dos nós ou da acurácia ao remover variáveis.238 Tratamento de valores ausentes, seja classificando-os como categoria própria ou imputando-os por previsão dentro da árvore.238 Predição de novos casos a partir de dados históricos.238 Manipulação de dados, colapsando categorias muito numerosas ou subdividindo variáveis contínuas assimétricas.238 39.8.3 Quais são os componentes básicos de uma árvore de decisão? Nós raiz (ou de decisão): subdividem todos os registros iniciais.238 Nós internos (ou de chance): representam subdivisões intermediárias.238 Nós folha (ou finais): resultados finais após sucessivas divisões.238 Ramos: representam condições “se-então”, ligando nós em sequência até a classificação final.238 39.8.4 Como funcionam splitting, stopping e pruning? Splitting: divide registros em subconjuntos mais homogêneos com base em métricas como entropia, índice de Gini e ganho de informação.238 Stopping: evita árvores excessivamente complexas ao definir parâmetros como número mínimo de registros por nó ou profundidade máxima.238 Pruning: reduz árvores grandes eliminando ramos pouco informativos, usando validação ou métodos como qui-quadrado.238 39.8.5 Quais são as vantagens e limitações de árvores de decisão? Vantagens: simplificam relações complexas; são intuitivas e fáceis de interpretar; não exigem pressupostos de distribuição; lidam bem com valores ausentes e dados enviesados; são robustas a outliers.238 Limitações: podem sofrer overfitting ou underfitting em amostras pequenas; podem selecionar variáveis correlacionadas sem relação causal real.238 39.8.6 Como se comparam à regressão logística? A regressão logística assume relações lineares entre variáveis e log-odds.239 Árvores de decisão permitem capturar relações não lineares e interações de forma automática.239 Figura 39.2: Comparação entre modelos de regressão logística e árvore de decisão. O pacote h2o@correctR fornece funções construir modelos de aprendizado de máquina. O pacote correctR318 fornece as funções kfold_ttest, repkfold_ttest e resampled_ttest para calcular estatística para comparação de modelos de aprendizado de máquina em amostras dependentes. O pacote caret@caret fornece um conjunto de funções para pré-processamento, ajuste, avaliação e comparação de modelos de aprendizado de máquina. O pacote mlr3@mlr3 fornece funções para fluxos de trabalho complexos, incluindo pré-processamento, ajuste de hiperparâmetros e integração com diversos algoritmos. 39.9 Análise de componentes principais 39.9.1 O que é análise de componentes principais? .REF? 39.10 Random forests 39.10.1 O que são random forests? .REF? 39.11 Ensemble 39.11.1 O que são ensemble? .REF? 39.12 Desbalanceamento de classes 39.12.1 O que é desbalanceamento de classes (class imbalance)? Ocorre quando as classes do desfecho (por exemplo, presença vs. ausência de um evento) não estão igualmente representadas nos dados de treinamento.REF? 39.12.2 Por que o desbalanceamento é um problema? Modelos podem aprender a priorizar a classe mais frequente, obtendo alta acurácia global, mas baixo desempenho para a classe minoritária.REF? Isso pode comprometer métricas como sensibilidade, especificidade e, em alguns casos, a calibração.REF? 39.12.3 Quais são as abordagens mais comuns para lidar com desbalanceamento de classes? Reamostragem aleatória: superamostragem da classe minoritária; subamostragem da classe majoritária).REF? Ajuste de pesos: penaliza mais os erros na classe menos frequente.REF? Alteração do limiar de decisão: muda o ponto de corte de probabilidade para otimizar métricas específicas.REF? 39.12.4 Qual é o impacto do desbalanceamento de classes na calibração de modelos? Corrigir o desbalanceamento de classes nem sempre melhora a calibração e, em alguns casos, pode piorá-la.324 Em simulações computacionais, modelos sem correção tiveram calibração igual ou superior aos corrigidos.324 A piora observada foi caracterizada por superestimação do risco, nem sempre reversível com re-calibração.324 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["inteligencia-artificial.html", "Capítulo 40 Inteligência artificial 40.1 Inteligência artificial 40.2 IA generativa e grandes modelos de linguagem", " Capítulo 40 Inteligência artificial 40.1 Inteligência artificial 40.1.1 O que é inteligência artificial (IA)? .REF? 40.1.2 Qual é a unidade básica de IA? A unidade básica de IA é o neurônio artificial, que simula o comportamento de um neurônio biológico, recebendo entradas, aplicando pesos e uma função de ativação para produzir uma saída.REF? A rede neural é uma coleção de neurônios artificiais organizados em camadas, onde cada camada processa informações e passa para a próxima, permitindo o aprendizado de padrões complexos.REF? 40.1.3 Como ela se relaciona com estatística, ciência de dados e aprendizado de máquina? .REF? 40.2 IA generativa e grandes modelos de linguagem 40.2.1 O que são grandes modelos de linguagem (large language models, LLM)? .REF? 40.2.2 Como funcionam modelos como GPT, BERT e similares? .REF? Figura 40.1: Representação esquemática de um modelo de linguagem grande (LLM) O pacote keras@keras funções para criar, treinar e avaliar modelos de redes neurais. O pacote torch325 permite criar e treinar redes neurais com alto desempenho. O pacote reticulate326 integra R e Python em um mesmo ambiente de trabalho, permitindo chamar funções Python a partir de R e facilitar o uso de bibliotecas de IA disponíveis nesse ecossistema. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, "],["parte-9.html", "PARTE 9: PLANEJAMENTO DE ESTUDOS Definindo poder, tamanho amostral e plano de análise", " PARTE 9: PLANEJAMENTO DE ESTUDOS Definindo poder, tamanho amostral e plano de análise "],["poder-estatistico.html", "Capítulo 41 Poder estatístico 41.1 Poder do teste", " Capítulo 41 Poder estatístico 41.1 Poder do teste 41.1.1 O que é poder do teste? Poder do teste é a probabilidade de rejeitar corretamente a hipótese nula (\\(H_{0}\\)) quando esta é falsa.260 Poder do teste pode ser calculado como (\\(1 - \\beta\\)).260 41.1.2 O que é análise de poder do teste? Poder é a probabilidade de que um dado tamanho de efeito será observado em um experimento futuro sob um conjunto de hipóteses - tamanho de efeito real e erro tipo I - para um dado tamanho de amostra.327 O objetivo geral da análise de poder ao projetar um estudo é escolher um tamanho de amostra que controle os 2 tipos de erros de inferência estatística: tipo I (\\(\\alpha\\), resultado falso-positivo) e tipo II (\\(\\beta\\), resultado falso-negativo).327 Numericamente, o poder de um estudo é calculado como \\(1-\\beta\\) e reportado em valor percentual.327 41.1.3 Quando realizar a análise de poder do teste? Na fase de projeto de pesquisa: a análise de poder para determinar o tamanho da amostra objetiva que o tamanho da amostra permita uma probabilidade razoável de detectar um efeito significativo pré-especificado.327 Após a coleta de dados: a análise de poder objetiva informar estudos futuros a respeito do tamanho da amostra necessário para a detecção de um efeito significativo pré-especificado.327 O pacote pwr275 fornece a função pwr.2p.test para cálculo do poder do teste de proporção balanceado (2 amostras com mesmo número de participantes). O pacote pwr275 fornece a função pwr.2p2n.test para cálculo do poder do teste de proporção não balanceado (2 amostras com diferente número de participantes). O pacote pwr275 fornece a função pwr.anova.test para cálculo do poder do teste de análise de variância balanceado (3 ou mais amostras com mesmo número de participantes). O pacote pwr275 fornece a função pwr.chisq.test para cálculo do poder do teste de qui-quadrado \\(\\chi^2\\). O pacote pwr275 fornece a função pwr.f2.test para cálculo do poder do teste com modelo linear geral. O pacote pwr275 fornece a função pwr.norm.test para cálculo do poder do teste de média de uma distribuição normal com variância conhecida. O pacote pwr275 fornece a função pwr.p.test para cálculo do poder do teste de proporção (1 amostra). O pacote pwr275 fornece a função pwr.r.test para cálculo do poder to teste de correlação (1 amostra). O pacote pwr275 fornece a função pwr.t.test para cálculo do poder do teste t de diferença de 1 amostra, 2 amostras dependentes ou 2 amostras independentes (grupos balanceados). O pacote pwr275 fornece a função pwr.t2n.test para cálculo do poder do teste t de diferença de 2 amostras independentes (grupos não balanceados). O pacote longpower328 fornece a função power.mmrm para calcular o poder de testes com análises por modelo de regressão linear misto. O pacote Superpower286 fornece a função power.ftest para calcular o poder do teste por análise de testes F. O pacote Superpower286 fornece a função power_oneway_between para calcular o poder do teste por análise de variância (ANOVA) de 1 fator entre-sujeitos. O pacote Superpower286 fornece a função power_oneway_within para calcular o poder do teste por análise de variância (ANOVA) de 1 fator intra-sujeitos. O pacote Superpower286 fornece a função power_oneway_ancova para calcular o poder do teste por análise de covariância (ANCOVA). O pacote Superpower286 fornece a função power_twoway_between para calcular o poder do teste por análise de covariância (ANOVA) de 2 fatores entre-sujeitos. O pacote Superpower286 fornece a função power_threeway_between para calcular o poder do teste por análise de covariância (ANOVA) de 3 fatores entre-sujeitos. O pacote InteractionPoweR329 fornece a função power_interaction para calcular o poder do teste por análise de efeito de interações. 41.1.4 Por que a análise de poder do teste post hoc é inadequada? A análise do poder é teoricamente incorreta, uma vez que a probabilidade calculada \\(1-\\beta\\) expressa a probabilidade de um evento futuro, o que não é mais relevante quando o evento de interesse já ocorreu.205,327 41.1.5 O que pode ser realizado ao invés da análise de poder? Após a coleta e análise de dados, recomenda-se realizar a análise e interpretação dos resultados a partir do tamanho do efeito e do seu intervalo de confiança no nível de significância \\(\\alpha\\) pré-estabelecido.327 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["tamanho-amostral.html", "Capítulo 42 Tamanho da amostra 42.1 Tamanho da amostra 42.2 Saturação em pesquisas qualitativas 42.3 Eventos por variável (EPV) em modelos preditivos 42.4 Cálculo do tamanho da amostra 42.5 Perdas de amostra 42.6 Ajustes no tamanho da amostra 42.7 Justificativa do tamanho da amostra", " Capítulo 42 Tamanho da amostra 42.1 Tamanho da amostra 42.1.1 O que é tamanho da amostra? Tamanho da amostra \\(n\\) é a quantidade de participantes (ou unidades de análise) necessárias para conduzir um estudo a fim de testar uma hipótese.330 O cálculo do tamanho da amostra depende de quatro pilares interligados — tamanho de efeito esperado, variabilidade, nível de significância (\\(\\alpha\\)) e poder (\\(1-\\beta\\)) — cuja combinação determina o \\(n\\) necessário para detectar efeitos de interesse com precisão adequada.15 42.1.2 Por que determinar o tamanho da amostra é importante? É virtualmente impossível, devido a limitações de recursos - tempo, acesso, custo, dentre outros - coletar dados da população completa.8 Uma amostra muito pequena para o estudo pode resultar em ajuste exagerado, imprecisão e baixo poder do teste.131 42.1.3 Quais fatores devem ser considerados para determinar o tamanho da amostra? Tamanho da população (\\(N\\)): O tamanho da amostra depende parcialmente do tamanho da população de origem. Geralmente assume-se que a população tem tamanho desconhecido ou infinito. Em alguns estudos serão amostradas populações de tamanho finito (inferior a 100.000 indivíduos), geralmente em pesquisas descritivas, em que esse tamanho deve ser incorporado nos cálculos.330 Delineamento do estudo.330 Quantidade e características (dependente vs. independente) dos grupos de participantes do estudo.330 Erros tipo I (\\(\\alpha\\)) e tipo II (\\(\\beta\\)).330 Tipo de variável a ser observada (contínua, intervalo, ordinal, nominal, dicotômica).330 Tamanho de efeito mínimo a ser observado.330 Variabilidade da(s) variável(eis) coletada(s).330 Lateralidade do teste de hipótese (uni- ou bicaudais).330 Perdas de dados durante a coleta e/ou acompanhamento dos participantes do estudo.330 O pacote pwr275 fornece a função plot.power.htest para apresentar graficamente a relação entre o tamanho da amostra e o poder de testes de hipóteses. 42.1.4 Quais aspectos éticos estão envolvidos no tamanho da amostra? Determinar a priori o tamanho da amostra pode diminuir o risco de realizar testes ou intervenções desnecessários, de desperdício de recursos (tempo e dinheiro) associados e, por outro lado, de coletar dados insuficientes para testar as hipóteses do estudo.330 O tratamento ético dos participantes do estudo, portanto, não exige que se considere se o poder do estudo é inferior à meta convencional de 80% ou 90%.331 Estudos com poder &lt;80% não são necessariamente antiéticos.331 Metas convencionais de poder (80–90%) são guias pragmáticos e não regras morais rígidas; estudos com poder &lt;80% não são automaticamente antiéticos quando bem justificados.331 Grandes estudos podem ser desejáveis por outras razões que não as éticas.331 42.2 Saturação em pesquisas qualitativas 42.2.1 O que é saturação de dados em pesquisas qualitativas? Saturação é o ponto em que a coleta de dados não produz novas informações, categorias ou temas, indicando que o fenômeno investigado já foi suficientemente explorado.332 Essa noção surgiu na teoria fundamentada com o termo “saturação teórica”, mas hoje é amplamente usada em diferentes tradições qualitativas, incluindo fenomenologia, etnografia e análise temática.333 42.2.2 Quais tipos de saturação existem? Saturação de códigos: ocorre quando não emergem novos códigos relevantes nos dados333 Saturação de significados: atinge-se quando a profundidade e a variação dos significados de um tema foram plenamente exploradas.333 Saturação teórica: quando categorias estão suficientemente desenvolvidas e suas relações esclarecidas.332 Saturação de metatemas: em pesquisas multicêntricas, quando os grandes temas transversais já foram identificados.334 Figura 42.1: Curvas de poder para testes t (quantitativo). Linhas sólidas: α=0,05 | tracejadas: α=0,01 | linhas horizontais em 80% e 90% de poder. Figura 42.2: Curvas de saturação para estudos qualitativos de descoberta de temas. 42.2.3 Quantas entrevistas ou grupos focais são necessários para alcançar saturação? Estudos empíricos mostram que a saturação de códigos pode ser atingida com 9 a 17 entrevistas em populações homogêneas e objetivos específicos.333 Para saturação de significados, podem ser necessárias entre 16 e 24 entrevistas.333 Em grupos focais, a saturação temática pode ocorrer com 4 a 8 grupos homogêneos.333 Revisões recentes sugerem que a saturação teórica exige 20 a 30 entrevistas ou mais, dependendo da complexidade do estudo.334 42.2.4 Quais debates existem sobre o conceito de saturação? Defensores argumentam que a saturação é central para garantir rigor e confiança nos resultados qualitativos.332 Críticos sugerem que o conceito pode ser usado de forma rígida, levando a coletas excessivas ou pouco sensíveis a perspectivas únicas.332 Pesquisadores contemporâneos recomendam usar a saturação de forma flexível, adaptada ao contexto, método e população estudada.334 42.2.5 Quais recomendações práticas para tamanho de amostras de estudos qualitativos? Para entrevistas individuais: 9–12 entrevistas podem ser suficientes para saturação temática em contextos homogêneos, mas estudos heterogêneos ou multicêntricos exigem mais casos.333,334 Para grupos focais: 4–8 grupos são geralmente adequados.333 Para estudos multicêntricos: recomenda-se 20–40 entrevistas por local para alcançar saturação de metatemas.334 É importante relatar não apenas o número de entrevistas, mas também como e quando a saturação foi avaliada.335 42.3 Eventos por variável (EPV) em modelos preditivos 42.3.1 Quantos eventos por variável (EPV) são necessários? Regressão logística: entre 20 e 50 EPV.315 Árvore de decisão para classificação e regressão: cerca de 60 EPV.315 Máquina de vetores de suporte, redes neurais e random forests : muitas vezes &gt;200 EPV e ainda instáveis.315 42.3.2 O que acontece se não houver eventos suficientes? Modelos modernos podem apresentar alto otimismo (desempenho inflado no treino, mas ruim na validação).315 Pequenos bancos de dados favorecem o uso de modelos clássicos.315 42.4 Cálculo do tamanho da amostra 42.4.1 Como calcular o tamanho da amostra? O tamanho amostral pode ser calculado por meio de fórmulas matemáticas que tendem a assegurar margens de erros tipos I (\\(\\alpha\\)) e II (\\(\\beta\\)) para a estimação dos parâmetros populacionais (tamanho de efeito) a partir dos dados amostrais.330 O tamanho da amostra deve ser calculado para cada um dos objetivos primários e/ou secundários, sendo escolhido o maior tamanho de amostra calculado para o estudo.330 Geralmente é recomendado ser cético em relação às regras práticas para o tamanho da amostra, tais como a proporção entre o número de variáveis (ou eventos) e de participantes.131 42.4.2 Como especificar o tamanho do efeito esperado? Estudo-piloto — realizados nas mesmas condições do estudo, mas envolvendo um tamanho de amostra limitado — pode ser útil na estimativa do tamanho da amostra a partir do tamanho do efeito estimado.330 Utilizar os limites dos intervalos de confiança de estudos-piloto de ensaios clínicos como estimativa do tamanho do efeito pode aumentar o poder estatístico da análise se comparado ao uso das estimativas pontuais obtidas no mesmo piloto.336 Embora os testes de hipótese considerem efeito nulo para a hipótese nula — ex.: diferença de média (\\(H_{0}: \\mu_{1} - \\mu_{2}=0\\)), correlação (\\(H_{0}: r=0\\)), associação (\\(H_{0}: \\beta=0\\) ou \\(H_{0}: OR=1\\)) —, em geral é improvável que os efeitos populacionais sejam de fato nulos (isto é, exatamente 0).337 O pacote pwr275 fornece a função pwr.2p.test para cálculo do tamanho da amostra para testes de proporção balanceados (2 amostras com mesmo número de participantes). O pacote pwr275 fornece a função pwr.2p2n.test para cálculo do tamanho da amostra para testes de proporção não balanceados (2 amostras com diferente número de participantes). O pacote pwr275 fornece a função pwr.anova.test para cálculo do tamanho da amostra para testes de análise de variância balanceados (3 ou mais amostras com mesmo número de participantes). O pacote pwr275 fornece a função pwr.chisq.test para cálculo do tamanho da amostra para testes de qui-quadrado \\(\\chi^2\\). O pacote pwr275 fornece a função pwr.f2.test para cálculo do tamanho da amostra para testes com modelo linear geral. O pacote pwr275 fornece a função pwr.norm.test para cálculo do tamanho da amostra para a média de uma distribuição normal com variância conhecida. O pacote pwr275 fornece a função pwr.p.test para cálculo do tamanho da amostra para testes de proporção (1 amostra). O pacote pwr275 fornece a função pwr.r.test para cálculo do tamanho da amostra para testes de correlação (1 amostra). O pacote pwr275 fornece a função pwr.t.test para cálculo do tamanho da amostra para testes t de diferença de 1 amostra, 2 amostras dependentes ou 2 amostras independentes (grupos balanceados). O pacote pwr275 fornece a função pwr.t2n.test para cálculo do tamanho da amostra para testes t de diferença de 2 amostras independentes (grupos não balanceados). O pacote longpower328 fornece a função power.mmrm para calcular o tamanho da amostra para estudos com análises por modelo de regressão linear misto. 42.5 Perdas de amostra 42.5.1 O que é perda de amostra? Perda de amostra(s) — isto é, participante(s) ou unidade(s) de análise — pode ocorrer durante a coleta e/ou acompanhamento dos participantes do estudo.330 Perda amostral pode ocorrer por: abandono ou desistência do participante, perda de contato com o participante, perda de informação, ocorrência de eventos adversos, morte do participante, entre outros.330 42.5.2 Por que a perda de amostra é um problema? A perda de amostra reduz o tamanho efetivo de \\(n\\) e, portanto, o poder estatístico do estudo, elevando a probabilidade de erro tipo II (\\(\\beta\\)).131,330 A atrição diferencial também pode introduzir viés de seleção (ou de atrito), quando as características dos participantes que permanecem diferem sistematicamente das daqueles que se perdem ao seguimento.330 42.5.3 Como evitar perda de amostra? A perda de amostra pode ser evitada por meio de um planejamento cuidadoso do estudo, incluindo a definição de critérios de inclusão e exclusão claros e apropriados, bem como a definição de estratégias para minimizar a perda de amostra.REF? A perda de amostra pode ser compensada pelo aumento do tamanho da amostra, desde que o aumento seja suficiente para manter o poder do estudo.330 42.6 Ajustes no tamanho da amostra 42.6.1 Por que ajustar o tamanho da amostra? O tamanho da amostra pode ser ajustado durante o estudo para compensar a perda de amostra, desde que o aumento seja suficiente para manter o poder do estudo.330 42.6.2 Como ajustar para perda amostral? Aumentar o tamanho da amostra estimada \\(n\\) pela porcentagem \\(d\\) de perdas esperada ou prevista, para obter o tamanho da amostra efetiva \\(n&#39;\\) com base em (42.1):330 \\[\\begin{equation} \\tag{42.1} n&#39; = \\dfrac{n}{1-d} \\end{equation}\\] 42.7 Justificativa do tamanho da amostra 42.7.1 Como justificar o tamanho da amostra de um estudo? Em estudos que envolvem condições raras, pode ser difícil recrutar o número necessário de participantes devido à limitada disponibilidade de casos da população. Mesmo assim, é aconselhável determinar o tamanho da amostra.330 Quando um estudo deste tipo não é possível, as considerações referentes ao tamanho da amostra são justificadas de acordo com o número máximo de pacientes que podem ser recrutados no decorrer do estudo.330 42.7.2 Como justificar o tamanho da amostra em estudos qualitativos? Pesquisas qualitativas devem apresentar uma justificativa explícita da amostra, relacionando-a à estratégia de coleta, aos objetivos e ao critério de saturação adotado.335 A noção de “poder da informação” (information power) indica que quanto mais relevante e focada é a amostra em relação à pergunta de pesquisa, menor pode ser o número de participantes.335 Relatar claramente o processo de decisão aumenta a transparência e a credibilidade da pesquisa.335 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["plano-analise.html", "Capítulo 43 Plano de análise 43.1 Plano de análise estatística 43.2 Diretrizes para redação", " Capítulo 43 Plano de análise 43.1 Plano de análise estatística 43.1.1 O que é plano de análise estatística? .REF? 43.2 Diretrizes para redação 43.2.1 Quais são as diretrizes para redação de planos de análise estatística? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. Guidelines for the Content of Statistical Analysis Plans in Clinical Trials:338 https://www.equator-network.org/reporting-guidelines/guidelines-for-the-content-of-statistical-analysis-plans-in-clinical-trials/ /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["parte-10.html", "PARTE 10: DELINEAMENTOS E SÍNTESE DE EVIDÊNCIAS Tipos de estudo e integração de resultados: observacionais, experimentais e revisões", " PARTE 10: DELINEAMENTOS E SÍNTESE DE EVIDÊNCIAS Tipos de estudo e integração de resultados: observacionais, experimentais e revisões "],["delineamento-estudos.html", "Capítulo 44 Delineamento de estudos 44.1 Critérios de delineamento 44.2 Alocação 44.3 Cegamento 44.4 Pareamento 44.5 Aleatorização 44.6 Taxonomia de estudos", " Capítulo 44 Delineamento de estudos 44.1 Critérios de delineamento 44.1.1 Quais critérios são utilizados para classificar os delineamentos de estudos? .REF? 44.2 Alocação 44.2.1 O que é alocação? .REF? Figura 44.1: Alocação 1:1 entre dois grupos de participantes 44.3 Cegamento .REF? 44.3.1 O que é cegamento? 44.4 Pareamento 44.4.1 O que é pareamento? Pareamento significa que para cada participante de um grupo (por exemplo, com alguma condição clínica), existe um (ou mais) participantes (por exemplo, grupo controle) que possui características iguais ou similares relativas a algumas variáveis de interesse.339 As variáveis escolhidas para pareamento devem ter relação com as variáveis de desfecho, mas não são de interesse elas mesmas.339 O ajuste por pareamento deve ser incluído nas análises estatísticas mesmo que as variáveis de pareamento não sejam consideradas prognósticas ou confundidores na amostra estudada.339 A ausência de evidência estatística de diferença entre grupos não é considerada pareamento.339 44.5 Aleatorização 44.5.1 O que é aleatorização? .REF? 44.6 Taxonomia de estudos 44.6.1 Como podem ser classificados os estudos científicos? Estudos científicos podem ser classificados em básicos, observacionais, experimentais, acurácia diagnóstica, propriedades psicométricas, avaliação econômica e revisões de literatura:340–349 Estudos básicos341,346 Genética Celular Experimentos com animais Desenvolvimento de métodos Estudos de simulação computacional347,349 Estudos de propriedades psicométricas342,344 Validade Concordância Confiabilidade Estudos de desempenho diagnóstico345,348 Transversal Caso-Controle Comparativo Totalmente pareado Parcialmente pareado com subgrupo aleatório Parcialmente pareado com subgrupo não aleatório Não pareado aleatório Não pareado não aleatório Estudos observacionais341,346 Descritivo Estudo de caso Série de casos Transversal Analítico Transversal Caso-Controle Caso-Controle aninhado Caso-Coorte Coorte prospectiva ou retrospectiva Estudos quase-experimentais343 Quase-aleatorizado controlado Estimação de variável instrumental Descontinuidade de regressão Série temporal interrompida controlada Série temporal interrompida Diferença Estudos experimentais341,346 Fases I a IV Aleatorizado controlado Não-aleatorizado controlado Autocontrolado Cruzado Fatorial Campo Comunitário Estudos de avaliação econômica341 Análise de custo Análise de minimização de custo Análise de custo-utilidade Análise de custo-efetividade Análise de custo-benefício Estudos de revisão340 Estado-da-arte Narrativa Crítica Mapeamento Escopo Busca e revisão sistemática Sistematizada Sistemática Meta-análise Bibliométrica.350,351 Sistemática qualitativa Mista Visão geral Rápida Guarda-chuva /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["simulacao-computacional.html", "Capítulo 45 Simulação computacional 45.1 Simulações computacionais 45.2 Características 45.3 Método de Monte Carlo 45.4 Diretrizes para redação", " Capítulo 45 Simulação computacional 45.1 Simulações computacionais 45.1.1 O que são simulações computacionais? Simulações computacionais consistem na geração de dados artificiais baseados em regras matemáticas e estatísticas, permitindo testar hipóteses, validar métodos e explorar cenários complexos sem necessidade de dados reais.52 A simulação é frequentemente usada em estatística para avaliar o desempenho de testes, estimadores e modelos sob diferentes condições.REF? 45.1.2 Por que usar simulações? Testar o comportamento de métodos estatísticos sob diferentes premissas (ex: normalidade, homocedasticidade, tamanho amostral).REF? Avaliar a robustez de algoritmos computacionais.REF? Reproduzir processos naturais ou sociais para compreensão teórica.REF? 45.1.3 Quais são as boas práticas em simulações computacionais? Defina claramente o objetivo da simulação e as hipóteses a serem testadas, incluindo quais aspectos do fenômeno ou do método você pretende avaliar.90 Use uma semente para o gerador de números aleatórios com set.seed() para garantir a reprodutibilidade dos resultados.REF? Documente detalhadamente o processo de simulação, incluindo os parâmetros utilizados, a lógica do algoritmo e as suposições feitas.352 Realize múltiplas simulações (ex.: 1000 ou mais) para obter estimativas estáveis e resultados mais robustos e confiáveis.REF? Analise os resultados de forma crítica, considerando a variabilidade, as limitações do modelo e possíveis vieses do processo de simulação.REF? Use funções vetorizadas para otimizar o desempenho e reduzir o tempo de execução da simulação.REF? O pacote base103 fornece a função set.seed para especificar uma semente e garantir a reprodutibilidade de computações que envolvem números aleatórios. 45.2 Características 45.2.1 Quais são as características de estudos de simulação computacional? .REF? 45.3 Método de Monte Carlo 45.3.1 O que é o método de Monte Carlo? .353 No método Markov Chain Monte Carlo (MCMC), o modelo de Markov é usado para gerar amostras de distribuições complexas a partir da simulação de cadeias com distribuição estacionária prescrita.316 Figura 45.1: Convergência do histograma para a PDF teórica da Normal(0,1) com o aumento do tamanho amostral (n = 10, 100, 1000, 10000). Figura 45.2: Convergência da média e do desvio-padrão amostral para os valores teóricos (0 e 1, respectivamente) com o aumento do tamanho amostral (n = 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000). O pacote base103 fornece a função set.seed para especificar uma semente para reprodutibilidade de computações que envolvem números aleatórios. O pacote simstudy354 fornece as funções defData e genData para criar variáveis e simular um banco de dados de acordo com o delineamento pré-especificado, respectivamente. O pacote faux355 fornece a função sim_design para simular um banco de dados de acordo com o delineamento pré-especificado. O pacote InteractionPoweR329 fornece a função generate_interaction para simular bancos de dads com efeitos de interação. 45.4 Diretrizes para redação 45.4.1 Quais são as diretrizes para redação de estudos de simulação computacional? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. Strengthening the reporting of empirical simulation studies: Introducing the STRESS guidelines:356 https://www.equator-network.org/reporting-guidelines/strengthening-the-reporting-of-empirical-simulation-studies-introducing-the-stress-guidelines/ /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["observacional.html", "Capítulo 46 Estudos observacionais 46.1 Características 46.2 Diretrizes para redação", " Capítulo 46 Estudos observacionais 46.1 Características 46.1.1 Quais são as características de estudos observacionais? .REF? 46.2 Diretrizes para redação 46.2.1 Quais são as diretrizes para redação de estudos observacionais? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Statement: guidelines for reporting observational studies:357 https://www.equator-network.org/reporting-guidelines/strobe/ /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["propriedades-psicometricas.html", "Capítulo 47 Propriedades psicométricas 47.1 Características 47.2 Análise fatorial exploratória 47.3 Análise fatorial confirmatória 47.4 Validade de conteúdo 47.5 Validade de face 47.6 Validade do construto 47.7 Validade fatorial 47.8 Validade convergente 47.9 Validade discriminante 47.10 Validade de critério 47.11 Validade concorrente 47.12 Responsividade 47.13 Concordância 47.14 Confiabilidade 47.15 Diretrizes para redação", " Capítulo 47 Propriedades psicométricas 47.1 Características 47.1.1 O que são propriedades psicométricas? .REF? Tabela 47.1: Tabela de confusão sobre propriedades psicométricas de instrumentos. Concordância alta Concordância baixa Validade alta Adequado Inadequado Validade baixa Inadequado Inadequado O pacote lavaan358 fornece a função cfa para implementar modelos de análise fatorial confirmatória. O pacote lavaan358 fornece a função modificationIndices para calcular os índices de modificação. O pacote semTools359 fornece a função reliability para analisar a confiabilidade de um instrumento. O pacote psych360 fornece a função icc para calcular a confiabilidade utilizando coeficientes de correlação intraclasse. 47.2 Análise fatorial exploratória 47.2.1 O que é análise fatorial exploratória? .REF? 47.3 Análise fatorial confirmatória 47.3.1 O que é análise fatorial confirmatória? .REF? 47.4 Validade de conteúdo 47.4.1 O que é validade interna? .361 47.4.2 O que é validade externa? .361 47.4.3 Que fatores afetam a validade? A amostragem não probabilística pode dificultar a generalização dos achados da amostra para a população, diminuindo assim a validade externa do estudo.15 Quando as características da amostra obtida por seleção não probabilística forem similares às da população, a validade externa pode ser maior.15 47.4.4 Como avaliar a validade de um estudo? As características da amostra apresentadas na Tabela 1 são úteis para interpretação da validade interna e externa dos achados do estudo.216 47.5 Validade de face 47.5.1 O que é validade de face? .[RF] 47.6 Validade do construto 47.6.1 O que é construto? .[RF] 47.7 Validade fatorial 47.7.1 O que é validade fatorial? .[RF] 47.8 Validade convergente 47.8.1 O que é validade convergente? .[RF] 47.9 Validade discriminante 47.9.1 O que é validade discriminante? .[RF] 47.10 Validade de critério 47.10.1 O que é validade de critério? .[RF] 47.11 Validade concorrente 47.11.1 O que é concorrente? .[RF] 47.11.2 O que é validade concorrente? .[RF] 47.11.3 O que é validade preditiva? .[RF] 47.12 Responsividade 47.12.1 O que é responsividade? .REF? 47.13 Concordância 47.13.1 O que é concordância? .REF? 47.13.2 Quais métodos são adequados para análise de concordância de variáveis dicotômicas? Coeficiente de Cohen \\(\\kappa\\): mede a concordância corrigida pelo acaso.362,363 Tabela 47.2: Tabela de confusão 2x2 para análise de concordância de testes e variáveis dicotômicas. Teste positivo Teste negativo Total Teste positivo \\(a\\) \\(b\\) \\(g=a+b\\) Teste negativo \\(c\\) \\(d\\) \\(h=c+d\\) Total \\(e=a+c\\) \\(f=b+d\\) \\(N=a+b+c+d\\) Coeficiente de correlação tetracórica \\(r_{tet}\\).364,365 O pacote psych360 fornece a função tetrachoric para calcular o coeficiente de correlação tetracórica (\\(r_{tet}\\)). 47.13.3 Quais métodos não são adequados para análise de concordância de variáveis dicotômicas? Concordância absoluta \\(C_{A}\\) - quantidade de casos em que examinadores concordam - não é recomendada porque não corrige a estimativa para possíveis concordâncias ao acaso.365 Concordância percentual \\(C_{\\%}\\) - proporção de casos em que examinadores concordam pela quantidade total de casos - não é recomendada porque não corrige a estimativa para possíveis concordâncias ao acaso.365 Qui-quadrado \\(\\chi^2\\) a partir da tabela de contigência não é recomendado porque tal teste analisa associação.365 A família de coeficientes de Cohen \\(\\kappa\\) não é adequada para analisar concordância quando as variáveis são aparentemente (e não originalmente) dicotômicas.365 47.13.4 Quais métodos são adequados para análise de concordância de variáveis categóricas? Coeficiente de Cohen \\(\\kappa\\): mede a concordância corrigida pelo acaso.362,363 Coeficiente de Cohen ponderado \\(\\kappa_{w}\\): mede a concordância corrigida pelo acaso.362,363 Tabela 47.3: Tabela de confusão 3x3 para análise de concordância de testes e variáveis dicotômicas. Grave Moderado Leve Total Grave \\(a\\) \\(b\\) \\(c\\) \\(j=a+b+c\\) Moderado \\(d\\) \\(e\\) \\(f\\) \\(k=d+e+f\\) Leve \\(g\\) \\(h\\) \\(i\\) \\(l=g+h+i\\) Total \\(j=a+d+g\\) \\(k=b+e+h\\) \\(l=c+f+i\\) \\(N=a+b+c+d+e+f+g+h+i\\) Coeficiente de correlação policórica \\(r_{pol}\\).365 O pacote psych360 fornece a função tetrachoric para calcular o coeficiente de correlação policórica (\\(r_{pol}\\)). 47.13.5 Quais métodos são adequados para análise de concordância de variáveis categóricas e contínuas? Coeficiente de correlação bisserial \\(r_{s}\\).365 O pacote psych360 fornece a função tetrachoric para calcular o coeficiente de correlação bisserial (\\(r_{s}\\)). 47.13.6 Quais métodos são adequados para análise de concordância de variáveis ordinais? Coeficiente de Cohen ponderado \\(\\kappa_{w}\\): mede a concordância corrigida pelo acaso.362,363 47.13.7 Quais métodos são adequados para análise de concordância de variáveis contínuas? Gráfico de dispersão com a reta de regressão.142 Gráfico de limites de concordância (média dos testes vs. diferença entre testes) com a reta de regressão do viés e respectivo no nível de significância \\(\\alpha\\) pré-estabelecido.142 O pacote BlandAltmanLeh366 fornece as funções bland.altman.stats e bland.altman.plot para calcular e apresentar, respectivamente, o gráfico com os limites de concordância entre dois métodos. 47.13.8 Quais métodos não são adequados para análise de concordância de variáveis contínuas? Comparação de médias: dois métodos apresentarem médias similares - isto é, ‘sem diferença estatística’ após um teste inferencial de hipótese nula \\(H_{0}:\\mu_{1} = \\mu_{2}\\) - não informa sobre a concordância deles. Métodos com maior erro de medida tendem a ter menos chance de rejeição da hipótese nula.142 Correlação bivariada: o coeficiente de correlação dependente tanto da variação entre indivíduos (isto é, entre os valores verdadeiros) quanto da variação intraindividual (isto é, erro de medida). Se a variância dos erros de medida de ambos os métodos não for pequena comparadas à variância dos valores verdadeiros, o tamanho do efeito da correlação será pequeno mesmo que os métodos possuam boa concordância.142 Regressão linear: o teste da hipótese nula da inclinação da reta de regressão (\\(H_{0}:\\beta = 0\\)) é equivalente a testar a correlação bivariada (\\(H_{0}:\\rho = 0\\)).142 47.13.9 Quais métodos são adequados para modelagem de concordância? Modelo log-linear.365 47.14 Confiabilidade 47.14.1 O que é confiabilidade? .REF? 47.14.2 Quais métodos são adequados para análise de confiabilidade? .REF? 47.15 Diretrizes para redação 47.15.1 Quais são as diretrizes para redação de estudos de propriedades psicométricas? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. COSMIN reporting guideline for studies on measurement properties of patient-reported outcome measures:367 https://www.equator-network.org/reporting-guidelines/cosmin-reporting-guideline-for-studies-on-measurement-properties-of-patient-reported-outcome-measures/ Recommendations for reporting the results of studies of instrument and scale development and testing:368 https://www.equator-network.org/reporting-guidelines/recommendations-for-reporting-the-results-of-studies-of-instrument-and-scale-development-and-testing/ Guidelines for reporting reliability and agreement studies (GRRAS) were proposed:369 https://www.equator-network.org/reporting-guidelines/guidelines-for-reporting-reliability-and-agreement-studies-grras-were-proposed/&gt; /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["desempenho-diagnostico.html", "Capítulo 48 Desempenho diagnóstico 48.1 Características 48.2 Tabelas 2x2 48.3 Tabelas 2x3 48.4 Curvas ROC 48.5 Gráficos crosshair 48.6 Interpretação da validade de um teste 48.7 Diretrizes para redação", " Capítulo 48 Desempenho diagnóstico 48.1 Características 48.1.1 Quais são as características de estudos de desempenho diagnóstico? .REF? 48.2 Tabelas 2x2 48.2.1 O que é uma tabela de confusão 2x2? Tabela de confusão é uma matriz de 2 linhas por 2 colunas que permite analisar o desempenho de classificação de uma variável dicotômica (padrão-ouro ou referência) versus outra variável dicotômica (novo teste).370 48.2.2 Como analisar o desempenho diagnóstico em tabelas 2x2? Verdadeiro-positivo (\\(VP\\)): caso com a condição presente e corretamente identificado como tal.371 Falso-negativo (\\(FN\\)): caso com a condição presente e erroneamente identificado como ausente.371 Verdadeiro-negativo (\\(VN\\)): controle sem a condição presente e corretamente identificados como tal.371 Falso-positivo (\\(FP\\)): controle sem a condição presente e erroneamente identificado como presente.371 Tabela 48.1: Tabela de confusão 2x2 para análise de desempenho diagnóstico de testes e variáveis dicotômicas. Condição presente Condição ausente Total Teste positivo \\(VP\\) \\(FP\\) \\(VP+FP\\) Teste negativo \\(FN\\) \\(VN\\) \\(FN+VN\\) Total \\(VP+FN\\) \\(FP+VN\\) \\(N=VP+VN+FP+FN\\) Tabelas de confusão também podem ser visualizadas em formato de árvores de frequência.370 Figura 48.1: Árvore de frequência do desempenho diagnóstico de uma tabela de confusão 2x2 representando um método novo (dicotômico) comparado ao método padrão-ouro ou referência (dicotômico). O pacote riskyr372 fornece a função plot_prism para construir árvores de frequência a partir de diferentes cenários. 48.2.3 Quais probabilidades caracterizam o desempenho diagnóstico de um teste em tabelas 2x2? Sensibilidade (\\(SEN\\)) (48.1): Proporção de verdadeiro-positivos dentre aqueles com a condição.371 \\[\\begin{equation} \\tag{48.1} SEN = \\dfrac{VP}{VP+FN} \\end{equation}\\] Especificidade (\\(ESP\\)) (48.2): Proporção de verdadeiro-negativos dentre aqueles sem a condição.371 \\[\\begin{equation} \\tag{48.2} ESP = \\dfrac{VN}{VN+FP} \\end{equation}\\] Figura 48.2: Trade-off entre sensibilidade e especificidade em função do limiar de probabilidade (t) para um modelo de classificação. Valor preditivo positivo (\\(VPP\\)) (48.3): Proporção de casos corretamente identificados como verdadeiro-positivos.371 \\[\\begin{equation} \\tag{48.3} VPP = \\dfrac{VP}{VP+FP} \\end{equation}\\] Valor preditivo negativo (\\(VPN\\)) (48.4): Proporção de controles corretamente identificados como verdadeiro-negativos.371 \\[\\begin{equation} \\tag{48.4} VPN = \\dfrac{VN}{VN+FN} \\end{equation}\\] Razão de verossimilhança positiva (\\(LR+\\)) (48.5): Quantifica o quanto a probabilidade de a condição estar presente aumenta quando o teste é positivo.REF? \\[\\begin{equation} \\tag{48.5} LR+ = \\dfrac{SEN}{1 - ESP} = \\dfrac{VP/(VP+FN)}{FP/(FP+VN)} \\end{equation}\\] Razão de verossimilhança negativa (\\(LR-\\)) (48.6): Quantifica o quanto a probabilidade de a condição estar presente diminui quando o teste é negativo.REF? \\[\\begin{equation} \\tag{48.6} LR- = \\dfrac{1 - SEN}{ESP} = \\dfrac{FN/(VP+FN)}{VN/(FP+VN)} \\end{equation}\\] Acurácia (\\(ACU\\)), (48.7): Proporção de casos e controles corretamente identificados.371 \\[\\begin{equation} \\tag{48.7} ACU = \\dfrac{VP+VN}{VP+VN+FP+FN} \\end{equation}\\] Razão de chances diagnóstica (\\(DOR\\)) (48.8), (48.9) e (48.10): Razão entre a chance de um teste ser positivo quando a condição está presente e a chance de um teste ser positivo quando a condição está ausente.373 \\[\\begin{equation} \\tag{48.8} DOR = \\dfrac{VP}{FN} \\div \\dfrac{FP}{VN} = \\dfrac{VP \\cdot VN}{FP \\cdot FN} \\end{equation}\\] \\[\\begin{equation} \\tag{48.9} DOR = \\dfrac{SEN/(1-SEN)}{(1-ESP)/ESP} = \\dfrac{SEN \\cdot ESP}{(1-SEN) \\cdot (1-ESP)} \\end{equation}\\] \\[\\begin{equation} \\tag{48.10} DOR = \\dfrac{LR+}{LR-} \\end{equation}\\] Tabela 48.2: Probabilidades calculados a partir da tabela de confusão 2x2 para análise de desempenho diagnóstico de testes e variáveis dicotômicas. Condição presente Condição ausente Total Probabilidades Teste positivo \\(VP\\) \\(FP\\) \\(VP+FP\\) \\(VPP = \\frac{VP}{VP+FP}\\) Teste negativo \\(FN\\) \\(VN\\) \\(FN+VN\\) \\(VPN = \\frac{VN}{VN+FN}\\) Total \\(VP+FN\\) \\(FP+VN\\) \\(N=VP+VN+FP+FN\\) Probabilidades \\(SEN = \\frac{VP}{VP+FN}\\) \\(ESP = \\frac{VN}{VN+FP}\\) \\(ACU = \\frac{VP+VN}{VP+VN+FP+FN}\\)  \\(DOR = \\frac{VP \\cdot VN}{FP \\cdot FN}\\) O pacote riskyr372 fornece a função comp_prob para estimar 13 probabilidades relacionadas ao desempenho diagnóstico em tabelas 2x2. O pacote caret374 fornece a função confusionMatrix para estimar 11 probabilidades relacionadas ao desempenho diagnóstico em tabelas 2x2. 48.3 Tabelas 2x3 48.3.1 O que é uma tabela de confusão 2x3? É a extensão da tabela 2×2 que inclui uma terceira decisão (deferimento/boundary) além de aceitar (positivo) e rejeitar (negativo).375 As colunas** representam as decisões** (\\(POS\\), \\(BND\\), \\(NEG\\)) e as linhas representam a verdade de referência (condição presente vs ausente).375 Essa formulação vem do arcabouço de Three-Way Decisions (3WD), que particiona o universo em três regiões por dois limiares \\(\\alpha\\) e \\(\\beta\\).375 48.3.2 Como as regiões POS, BND e NEG são definidas? Dado um escore ou probabilidade condicional \\(Pr(C\\mid[x])\\) para a classe \\(C\\), classifica-se como \\(POS\\) (aceitar) quando \\(Pr(C\\mid[x]) \\ge \\alpha\\), como \\(BND\\) (deferir) quando \\(\\beta &lt; Pr(C\\mid[x]) &lt; \\alpha\\) e como \\(NEG\\) (rejeitar) quando \\(Pr(C\\mid[x]) \\le \\beta\\), sendo que os limiares \\((\\alpha,\\beta)\\) determinam simultaneamente as três regiões e os trade-offs entre acurácia e comprometimento.375 48.3.3 Qual é o formato de uma tabela 2×3? Estrutura geral (linhas = condição real; colunas = decisão): Tabela 48.3: Tabela de confusão 3-vias (2×3) com totais: referência vs decisão (3WD). POS (aceitar) BND (deferir) NEG (rejeitar) Total Condição presente (C) \\(|POS\\cap C|\\) \\(|BND\\cap C|\\) \\(|NEG\\cap C|\\) \\(|POS\\cap C|+|BND\\cap C|+|NEG\\cap C|\\) Condição ausente (\\(C^c\\)) \\(|POS\\cap C^c|\\) \\(|BND\\cap C^c|\\) \\(|NEG\\cap C^c|\\) \\(|POS\\cap C^c|+|BND\\cap C^c|+|NEG\\cap C^c|\\) Total \\(|POS\\cap C|+|POS\\cap C^c|\\) \\(|BND\\cap C|+|BND\\cap C^c|\\) \\(|NEG\\cap C|+|NEG\\cap C^c|\\) \\(N\\) 48.3.4 Quais são as medidas básicas na 2×3? Acurácia em POS (\\(M_{PT}\\)), equação (48.11): Proporção de positivos corretamente identificados na região POS.375 \\[\\begin{equation} \\tag{48.11} M_{PT} = \\dfrac{|POS \\cap C|}{|POS|} \\end{equation}\\] Erro em POS (\\(M_{PF}\\)), equação (48.12): Proporção de negativos incorretamente classificados na região POS.375 \\[\\begin{equation} \\tag{48.12} M_{PF} = \\dfrac{|POS \\cap C^{c}|}{|POS|} \\end{equation}\\] Acurácia em NEG (\\(M_{NF}\\)), equação (48.13): Proporção de negativos corretamente identificados na região NEG.375 \\[\\begin{equation} \\tag{48.13} M_{NF} = \\dfrac{|NEG \\cap C^{c}|}{|NEG|} \\end{equation}\\] Erro em NEG (\\(M_{NT}\\)), equação (48.14): Proporção de positivos incorretamente classificados na região NEG.375 \\[\\begin{equation} \\tag{48.14} M_{NT} = \\dfrac{|NEG \\cap C|}{|NEG|} \\end{equation}\\] Frações em BND (\\(M_{BT}\\) e \\(M_{BF}\\)), equações (48.15) e (48.16): Proporção de deferimentos verdadeiros e falsos.375 \\[\\begin{equation} \\tag{48.15} M_{BT} = \\dfrac{|BND \\cap C|}{|BND|} \\end{equation}\\] \\[\\begin{equation} \\tag{48.16} M_{BF} = \\dfrac{|BND \\cap C^{c}|}{|BND|} \\end{equation}\\] 48.3.5 Como escolher os limiares \\(\\alpha\\) e \\(\\beta\\)? Os limiares \\((\\alpha,\\beta)\\) controlam o tamanho das regiões \\(POS\\), \\(NEG\\) e \\(BND\\) e, portanto, os trade-offs entre “acertar mais” (acurácia nas regiões) e “decidir mais” (comprometimento; menos deferimentos).375 48.3.6 Quando preferir 3-vias em vez de 2×2? Quando o custo de erro é assimétrico e/ou há incerteza relevante.375 O deferimento (\\(BND\\)) evita decisões precipitadas e permite avaliação adicional, equilibrando acurácia e cobertura.375 É particularmente útil em triagens diagnósticas com etapas confirmatórias.375 48.4 Curvas ROC 48.4.1 O que representa a curva ROC? A relação entre sensibilidade (\\(SEN\\)) no eixo vertical e \\(1 - ESP\\) no eixo horizontal.376 Cada ponto na curva corresponde a um ponto de corte possível do teste.376 48.4.2 Quais são os tipos de curva ROC? Curva empírica: conecta diretamente os pontos obtidos a partir dos diferentes pontos de corte observados.377 Curva suavizada (paramétrica): assume uma distribuição binormal e gera uma curva ajustada por máxima verossimilhança.377 48.4.3 Como definir o melhor ponto de corte? O ponto de corte em uma curva ROC representa um balanço entre sensibilidade e especificidade, ou seja, a taxa de verdadeiros positivos e a taxa de falsos positivos.376,377 O método de Youden (equação (48.17) maximiza a diferença entre a taxa de verdadeiros positivos e a taxa de falsos positivos. O ponto de corte ideal será aquele com maior valor de \\(Y\\).125 \\[\\begin{equation} \\tag{48.17} Y = SEN + ESP - 1 \\end{equation}\\] O método da distância Euclidiana ((48.18) minimiza a distância entre um ponto da curva ROC e o ponto (0,1), que representa sensibilidade perfeita (\\(SEN = 100%\\)) e especificidade perfeita (\\(ESP = 100%\\)). O ponto de corte ideal será aquele com menor valor de \\(D\\).378 \\[\\begin{equation} \\tag{48.18} D = \\sqrt{(1 - SEN)^2 + (1 - ESP)^2} \\end{equation}\\] 48.4.4 O que é a área sob a curva (AUROC)? A área sob a curva ROC (AUC ou AUROC) quantifica o poder de discriminação ou desempenho diagnóstico na classificação de uma variável dicotômica.379 A área sob a curva (\\(AUC\\)) resume o desempenho global e representa a probabilidade de o teste classificar corretamente um caso positivo selecionado aleatoriamente em relação a um caso negativo selecionado aleatoriamente.376 48.4.5 Como calcular a AUC? Método não paramétrico: soma das áreas trapezoidais sob a curva empírica. Pode subestimar AUC quando os dados são discretos.377 Método paramétrico (binormal): mais robusto para dados em escala ordinal (ex: categorias diagnósticas), com viés reduzido.377 AUC deve sempre vir acompanhada de intervalo de confiança (IC95%).377 O pacote proc380 fornece a função plot.roc para criar uma curva ROC. 48.4.6 Como interpretar a área sob a curva (ROC)? A área sob a curva AUC varia no intervalo \\([0.5; 1]\\), com valores mais elevados indicando melhor discriminação ou desempenho do modelo de classificação.379 As interpretações qualitativas (isto é: pobre/fraca/baixa, moderada/razoável/aceitável, boa ou muito boa/alta/excelente) dos valores de área sob a curva são arbitrários e não devem ser considerados isoladamente.379 Modelos de classificação com valores altos de área sob a curva podem ser enganosos se os valores preditos por esses modelos não estiverem adequadamente calibrados.379 Diferenças pequenas entre AUCs podem não ser estatisticamente significativas.376 A interpretação clínica pode ser equivocada se não houver teste estatístico adequado.376 Se as curvas vêm do mesmo conjunto de pacientes, aplique o teste de DeLong.376 Se as curvas vêm de amostras independentes, use métodos como Dorfman-Alf.376 48.4.7 Por que uma AUC menor que 0.5 está errada? Porque indica desempenho pior que o acaso.376 Geralmente decorre de seleção incorreta da direção do teste ou da variável de estado.376 Verifique se o software está configurado para maiores valores indicam presença do evento ou o inverso.376 Ajuste a direção do teste para que \\(AUC ≥ 0.5\\).376 Figura 48.3: Curva ROC (Receiver Operating Characteristic) para um modelos de classificação com diferentes desempenhos diagnósticos. 48.4.8 Como analisar o desempenho diagnóstico em desfechos com distribuição trimodal na população? Limiares duplos podem ser utilizados para análise de desempenho diagnóstico de testes com distribuição trimodal.381 48.5 Gráficos crosshair 48.5.1 O que um gráfico crosshair? .382 O pacote mada383 fornece a função crosshair para criar um gráfico crosshair382 a partir de dados de verdadeiro-positivo, falso-positivo, verdadeiro-negativo e verdadeiro-positivo de tabelas de confusão 2x2. 48.6 Interpretação da validade de um teste 48.6.1 Que itens devem ser verificados na interpretação de um estudo de validade? O novo teste foi comparado junto ao método padrão-ouro.371 As probabilidades pontuais estimadas que caracterizam o desempenho diagnóstico do novo teste são altas e adequadas para sua aplicação clínica.371 Os intervalos de confiança estimados para as probabilidades do novo teste são estreitos e adequadas para sua aplicação clínica.371 O novo teste possui adequada confiabilidade intra/inter examinadores.371 O estudo de validação incluiu um espectro adequado da amostra.371 Todos os participantes realizaram ambos o novo teste e o padrão-ouro no estudo de validação.371 Os examinadores do novo teste estavam cegados para o resultado do teste padrão-ouro.371 48.7 Diretrizes para redação 48.7.1 Quais são as diretrizes para redação de estudos diagnósticos? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. STARD 2015: An Updated List of Essential Items for Reporting Diagnostic Accuracy Studies:384 https://www.equator-network.org/reporting-guidelines/stard/ /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["ensaio-quase-experimental.html", "Capítulo 49 Ensaios quase-experimentais 49.1 Características 49.2 Diretrizes para redação", " Capítulo 49 Ensaios quase-experimentais 49.1 Características 49.1.1 Quais são as características de ensaios quase-experimentais? .REF? 49.2 Diretrizes para redação 49.2.1 Quais são as diretrizes para redação de ensaios quase-experimentais? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. Guidelines for reporting non-randomised studies:385 https://www.equator-network.org/reporting-guidelines/guidelines-for-reporting-non-randomised-studies/ /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["ensaio-experimental.html", "Capítulo 50 Ensaios experimentais 50.1 Ensaio clínico aleatorizado 50.2 Modelos de análise de comparação 50.3 Comparação na linha de base 50.4 Comparação intragrupos 50.5 Comparação entre grupos 50.6 Comparação de subgrupos 50.7 Efeito de interação 50.8 Ajuste de covariáveis 50.9 Imputação de dados perdidos 50.10 Diretrizes para redação", " Capítulo 50 Ensaios experimentais 50.1 Ensaio clínico aleatorizado 50.1.1 Quais são as características de ensaios clínicos aleatorizados? A característica essencial de um ensaio clínico aleatorizado é a comparação entre grupos.386 Quanto à unidade de alocação:387 Individual Agrupado Quanto ao número de braços:387 Múltiplos Quanto ao número de centros:387 Único Múltiplos Quanto ao cegamento:387 Aberto Simples-cego Duplo-cego Triplo-cego Quádruplo-cego Quanto à alocação:387 Sem sorteio Estratificada (centro apenas) Estratificada Minimizada Estratificada e minimizada 50.1.2 Quais são as estratégias metodológicas para reduzir vieses? Grupo controle: comparar a intervenção a um cuidado usual ou controle ativo ajuda a isolar o efeito específico do tratamento, reduzindo vieses de confusão e maturação.REF? Grupo placebo: prepara uma intervenção indistinguível da ativa para mitigar expectativas de participantes e profissionais, reduzindo viés de desempenho e detecção.REF? Controle sham: em intervenções de procedimento (p.ex., cirúrgicas/fisioterapêuticas), um comparador que reproduz etapas não-específicas do procedimento controla efeitos placebo e da atenção.REF? Cegamento: mascarar participantes, profissionais, avaliadores e/ou analistas diminui vieses de desempenho e detecção; deve-se explicitar quem foi cegado e como a manutenção do cegamento foi assegurada.REF? 50.2 Modelos de análise de comparação 50.2.1 Que modelos podem ser utilizados para comparações? As abordagens compreendem a comparação da variável de desfecho medida entre os momentos antes e depois ou da sua mudança (pré - pós) entre os momentos.388 Se a média da variável é igual entre grupos no início do acompanhamento, ambas abordagens estimam o mesmo efeito. Caso contrário, o efeito será influenciado pela correlação entre as medidas antes e depois. A análise da mudança não controla para desbalanços no início do estudo.388 A abordagem mais recomendada é a análise de covariância (ANCOVA) - equação (50.1) - pois ajusta os valores pós-intervenção (\\(Y_{ij}\\)) aos valores pré-intervenção (\\(X_{ij}\\)) para cada participante (\\(i\\)) de cada grupo {\\(Z_{ij}\\)}, e portanto não é afetada pelas diferenças entre grupos no início do estudo.10,388 \\[\\begin{equation} \\tag{50.1} Y_{ij} = \\beta_0 + \\beta_1 X_{ij} + \\beta_2 Z_j + \\epsilon_{ij} \\end{equation}\\] A ANCOVA modelando seja a mudança (pré - pós: \\(\\Delta = X_{ij} - Y_{ij}\\)) quando o desfecho no pós-tratamento parece ser o método mais efetivo considerando-se o viés de estimação dos parâmetros, a precisão das estimativas, a cobertura nominal (isto é, intervalo de confiança) e o poder do teste.389 Quando a ANCOVA (50.2) é utilizada com a mudança (pré - pós) com variável de desfecho (\\(Y_{ij}\\)), o coeficiente de regressão \\(\\beta_1\\) é diminuído em 1 unidade.10,390 \\[\\begin{equation} \\tag{50.2} (X_{ij} - Y_{ij}) = \\beta_0 + \\beta_1 Z_j + \\epsilon_{ij} \\end{equation}\\] Análise de variância (ANOVA) e modelos lineares mistos (MLM) são outras opções de métodos, embora apresentem maior variância, menor poder, e cobertura nominal comparados à ANCOVA.389 Em desenhos com múltiplas medições por participante, modelos lineares mistos (efeitos aleatórios para indivíduo e, se pertinente, para centro) permitem lidar com correlação intra-sujeito e dados ausentes sob MAR, oferecendo estimativas válidas do efeito de tratamento no tempo.391 Para dados longitudinais com desfechos contínuos, estratégias de modelo de efeitos mistos com medidas repetidas evitam a imputação explícita e, sob suposições de MAR, tendem a melhor cobertura e controle de erro tipo I do que abordagens tipo “última observação transportada”.392 50.3 Comparação na linha de base 50.3.1 O que são dados na linha de base? Dados sociodemográficos, clínicos e funcionais são coletados na linha de base sobre cada participante no momento da aleatorização.393 Os dados de linha de base são usados para caracterizar os pacientes incluídos no estudo e para mostrar que os grupos de tratamento estão bem equilibrados.393 Dados da linha de base podem ser utilizados para a aleatorização de modo a equilíbrar ou estratificar os grupos considerando alguns fatores-chave.393 Dados da linha de base podem ser utilizados como ajuste de covariável para análise do resultado por grupo de tratamento.393 50.3.2 O que é comparação entre grupos na linha de base em ensaios clínicos aleatorizados? A comparação se refere ao teste de hipótese nula de não haver diferença (‘balanço’ ou ‘equilíbrio’) entre grupos de tratamento nas (co)variáveis na linha de base, geralmente apresentadas apenas de modo descritivo na ‘Tabela 1’.394 A interpretação isolada do P-valor da comparação entre grupos na linha de base não permite identificar as razões para eventuais diferenças.394 50.3.3 Para quê comparar grupos na linha de base em ensaios clínicos aleatorizados? Os P-valores estão relacionados à aleatorização dos participantes em grupos.395 Em ensaios clínicos aleatorizados, a comparação de (co)variáveis na linha de base é usada para avaliar se aleatorização foi ‘bem sucedida’.395 50.3.4 Quais são as razões para diferenças entre grupos de tratamento nas (co)variáveis na linha de base? Acaso.217,394 Viés.217,394 Tamanho da amostra.217,394 Má conduta científica.217 50.3.5 Quais cenários permitem a comparação entre grupos na linha de base em ensaios clínicos aleatorizados? Em ensaios clínicos aleatorizados agregados, os P-valores possuem interpretação diferente de estudos aleatorizados individualmente.395 Em ensaios clínicos com agrupamento, nos quais o recrutamento ocorreu após a aleatorização, os P-valores já não estão inteiramente relacionados ao processo de aleatorização, mas sim ao método de recrutamento, o que pode resultar na comparação de amostras não aleatórias.395 50.3.6 Por que não se deve comparar grupos na linha de base em ensaios clínicos aleatorizados? A interpretação errônea dos P-valores na comparação entre grupos, na linha de base, de um ensaio clínico aleatorizado constitui a ‘falácia da Tabela 1’.218 Quando a aleatorização é bem-sucedida, a hipótese nula de diferença entre grupos na linha de base é verdadeira.396 Testes de significância estatística na linha de base avaliam a probabilidade de que as diferenças observadas possam ter ocorrido por acaso; no entanto, já sabemos - pelo delineamento do experimento - que quaisquer diferenças são causadas pelo acaso.397 50.3.7 Quais estratégias podem ser adotadas para substituir a comparação entre grupos na linha de base em ensaios clínicos aleatorizados? Na fase de projeto: identifique as variáveis prognósticas do desfecho de acordo com a literatura.396 Na fase de análise: inclua as variáveis prognósticas nos modelos para ajuste.396 50.4 Comparação intragrupos 50.4.1 Por que não se deve comparar intragrupos (pré - pós) em ensaios clínicos aleatorizados? Testar por mudanças a partir da linha de base separadamente em cada grupos aleatorizados não permite concluir sobre diferenças entre grupos; não se pode fazer inferências a partir da comparação de P-valores.386 50.5 Comparação entre grupos 50.5.1 O que é comparação entre grupos em ensaios clínicos aleatorizados? A comparação se refere ao teste de hipótese nula de não haver diferença (‘alteração’ ou ‘mudança’) pós-tratamento entre grupos de tratamento.386 50.5.2 O que pode ser comparado entre grupos? Valores pós-tratamento; mudança entre linha de base e pós-tratamento; mudança percentual da linha de base.398 50.5.3 Qual é a comparação entre grupos mais adequada em ensaios clínicos aleatorizados? Análise de covariância (ANCOVA) que analisa o pós-tratamento com a linha de base como covariável é a opção que possui maior poder estatístico.398 Mudança entre linha de base e pós-tratamento tem poder adequado apenas quando a correlação entre linha de base e pós-tratamento é alta.398 Mudança percentual da linha de base é a opção menos eficiente em termos de poder estatístico.398 50.6 Comparação de subgrupos 50.6.1 O que é comparação de subgrupos em ensaios clínicos aleatorizados? Análises de subgrupos podem ser realizadas para avaliar se as diferenças no resultado do tratamento (ou a falta delas) dependem de algumas características na linha de base dos pacientes.393 50.6.2 Como realizar a comparação de subgrupos em ensaios clínicos aleatorizados? Testes estatísticos de interação (que avaliam se um efeito de tratamento difere entre subgrupos) devem ser usados, e não apenas a inspeção dos P-valores do subgrupo. Somente se o teste de interação estatística apoiar um efeito de subgrupo as conclusões poderão ser influenciadas.393,399 50.6.3 Como interpretar a comparação de subgrupos em ensaios clínicos aleatorizados? Análises de subgrupos devem ser consideradas de natureza exploratória e raramente elas afetam as conclusões obtidas a partir do estudo.393,399 A credibilidade das análises de subgrupos é melhor se restrita ao desfecho primário e a alguns subgrupos predefinidos e baseadas em hipóteses biologicamente plausíveis.393 Deve-se verificar se o estudo possui poder estatístico suficiente para detectar tamanhos de efeitos realistas em subgrupos e interpretar com cautela uma diferença de tratamento em um subgrupo quando a comparação global do tratamento não é significativa.393 50.7 Efeito de interação 50.7.1 Por que analisar o efeito de interação? Em ensaios clínicos aleatorizados, o principal problema de pesquisa é se há uma diferença pré - pós maior em um grupo do que em outro(s).386 A comparação de subgrupos por meio de testes de significância de hipótese nula separados é enganosa por não testar (comparar) diretamente os tamanhos dos efeitos dos tratamentos.400 Revisões recentes destacam que a interpretação de interações requer parcimônia (predefinição, plausibilidade biológica e controle do error-rate), e recomendam relatar estimativas e intervalos de confiança por subgrupo junto com o teste formal de interação.278 50.7.2 Quando usar o termo de interação? Análise de efeito de interação pode ser usada para testar se o efeito de um tratamento varia entre dois ou mais subgrupos de indivíduos, ou seja, se um efeito é modificado pelo(s) outros(s) efeito(s).279 A interação entre duas (ou mais) variáveis pode ser utilizada para comparar efeitos do tratamento em subgrupos de ensaios clínicos.401 O poder estatístico para detectar efeitos de interação é limitado.401 50.8 Ajuste de covariáveis 50.8.1 Quais variáveis devem ser utilizadas no ajuste de covariáveis? A escolha das características de linha de base pelas quais uma análise é ajustada deve ser determinada pelo conhecimento prévio de uma possível influência no resultado, em vez da evidência de desequilíbrio entre os grupos de tratamento no estudo.396 50.8.2 Quais os benefícios do ajuste de covariáveis? Ajustar por covariáveis ajuda a estimar os efeitos do tratamento para o indivíduo, assim como aumenta a eficiência dos testes para hipótese nula e a validade externa do estudo.402 Incluir a variável de desfecho medida na linha de base como covariável - independentemente de a análise ser realizada com a medida pós-tratamento da mesma variável ou a diferença para a linha de base - pode aumentar o poder estatístico do estudo.403 Incluir outras variáveis medidas na linha de base, com potencial para serem desbalanceadas entre grupos após a aleatorização, diminui a chance de afetar as estimativas de efeito dos tratamentos.403 50.8.3 Quais os riscos do ajuste de covariáveis? Incluir covariáveis que não são prognósticas do desfecho pode reduzir o poder estatístico do estudo.403 Incluir covariáveis com dados perdidos pode reduzir o tamanho amostral e consequentemente o poder estatístico do estudo (análise de casos completos) ou levar a desvios do plano de análise por exclusão de covariáveis prognósticas.403 50.9 Imputação de dados perdidos 50.9.1 Como lidar com os dados perdidos em desfechos? Em dados longitudinais com um pequeno número de ‘ondas’ (medidas repetidas) e poucas variáveis, para análise com modelos de regressão univariados, a imputação paramétrica via especificação condicional completa - também conhecido como imputação multivariada por equações encadeadas (multivariate imputation by chained equations, MICE) - é eficiente do ponto de vista computacional e possui acurácia e precisão para estimação de parâmetros.174,404 Para dados perdidos em desfechos dicotômicos, o desempenho dos métodos de imputação multivariada por equações encadeadas (multivariate imputation by chained equations, MICE)181 e por correspondência média preditiva (predictive mean matching, PMM)182,183 é similar.180 50.9.2 Como lidar com os dados perdidos em covariáveis? Imputação de dados perdidos de uma covariável pela média dos dados do respectivo grupo permite estimativas não enviesadas dos efeitos do tratamento, preserva o erro tipo I e aumenta o poder estatístico comparado à análise de dados completos.403 Para desfechos ausentes, recomenda-se evitar transportar a última observação e, quando aplicável, preferir modelos lineares mistos ou imputação múltipla consistentes com o estimando de interesse.392 Os pacotes mice181 e miceadds184 fornecem funções mice e mi.anova para imputação multivariada por equações encadeadas, respectivamente, para imputação de dados. 50.10 Diretrizes para redação 50.10.1 Quais são as diretrizes para redação de ensaios experimentais? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. CONSORT 2010 Statement: updated guidelines for reporting parallel group randomised trials:405 https://www.equator-network.org/reporting-guidelines/consort/ O pacote consort406 fornece a função consort_plot para elaboração do fluxograma de ensaios experimentais no formato padrão. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["n-de-1.html", "Capítulo 51 N de 1 51.1 Ensaio N-de-1 51.2 Aspectos metodológicos 51.3 Limitações e cuidados", " Capítulo 51 N de 1 51.1 Ensaio N-de-1 51.1.1 O que são ensaios N-de-1? Ensaios N-de-1 são delineamentos experimentais em que um único paciente recebe, em períodos alternados, duas ou mais intervenções (ex.: tratamento A e tratamento B).407 Cada ciclo é formado por dois períodos (AB ou BA), cuja ordem é randomizada, garantindo controle temporal e redução de vieses.407 O foco está na comparação intraindivíduo, permitindo avaliar diretamente se o paciente em questão responde melhor a uma intervenção.407 51.1.2 Quando usar ensaios N-de-1? Doenças crônicas estáveis, em que o desfecho pode ser observado repetidamente.407 Condições raras ou com grande heterogeneidade de resposta entre pacientes.407 Situações clínicas de incerteza, quando se deseja personalizar o tratamento.407 51.1.3 Qual a relevância dos ensaios N-de-1? Os ensaios N-de-1 permitem decisões clínicas personalizadas e baseadas em evidência direta.407 Quando combinados, podem gerar estimativas comparáveis às de ensaios clínicos convencionais, mantendo o foco centrado no paciente.407 Representam uma alternativa metodológica robusta para cenários de incerteza terapêutica.407 51.2 Aspectos metodológicos 51.2.1 Como é feita a randomização? A ordem dos tratamentos em cada ciclo é definida aleatoriamente (ex.: AB, BA, AB…).407 Essa randomização reduz viés de período e efeito de expectativa.407 51.2.2 Como são feitas as análises? Comparações intraindivíduo (testes pareados ou estimativas de efeito médio por paciente).407 Combinação de múltiplos N-de-1 por meio de meta-análises ou modelos mistos para inferências em nível populacional.407 51.2.3 Quais perguntas de inferência podem ser respondidas? Q1: Há efeito do tratamento dentro dos ciclos de um paciente?407 Q2: Qual é o efeito médio observado nos pacientes estudados?407 Q3: O efeito é homogêneo ou heterogêneo entre pacientes?407 Q4: Qual é o efeito específico em cada paciente individual?407 Q5: Qual é o efeito esperado em populações semelhantes?407 51.3 Limitações e cuidados 51.3.1 Quais são os principais desafios dos ensaios N-de-1? Baixo poder estatístico quando poucos ciclos são realizados.407 Necessidade de períodos de washout para evitar efeito de carry-over.407 Interpretação dependente de pressupostos sobre homogeneidade ou heterogeneidade dos efeitos.407 Em amostras muito pequenas, pode ser necessário usar variâncias externas ou modelos mistos.407 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["revisao-sistematica.html", "Capítulo 52 Revisão sistemática 52.1 Revisão sistemática de literatura 52.2 Diretrizes para redação", " Capítulo 52 Revisão sistemática 52.1 Revisão sistemática de literatura 52.1.1 O que é revisão sistemática? .REF? O pacote easyPubMed408 fornece a função get_pubmed_ids e fetch_pubmed_data para buscar artigos no PubMed. O pacote rcrossref409 fornece a função cr_works para buscar artigos. O pacote roadoi410 fornece a função oadoi_fetch para recuperar dados de acesso aberto do Unpaywall. 52.2 Diretrizes para redação 52.2.1 Quais são as diretrizes para revisão sistemática? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modelling Studies: The CHARMS Checklist.411 https://doi.org/10.1371/journal.pmed.1001744 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["meta-analise.html", "Capítulo 53 Meta-análise 53.1 Características 53.2 Modelos de meta-análise 53.3 Conversão de Medidas em Meta-análises 53.4 Interpretação de efeitos em meta-análise 53.5 Interpretação do Forest Plot 53.6 Viés de publicação em meta-análises 53.7 Diretrizes para redação", " Capítulo 53 Meta-análise 53.1 Características 53.1.1 O que é meta-análise? Meta-análise é um método estatístico que combina quantitativamente os resultados de múltiplos estudos independentes sobre uma mesma questão de pesquisa, aumentando o poder estatístico e a precisão das estimativas de efeito.412 Meta-análise sintetiza evidências considerando o peso de cada estudo (geralmente inversamente proporcional à variância) e permite avaliar a consistência dos resultados, identificar fontes de heterogeneidade e estimar um efeito global.412 53.2 Modelos de meta-análise 53.2.1 Quais são os principais modelos de meta-análise? Modelo de efeitos fixos: assume que todos os estudos avaliam o mesmo efeito verdadeiro, e a variação observada é apenas devido ao erro de amostragem. É adequado quando os estudos são homogêneos e as diferenças entre eles são pequenas.412 Modelo de efeitos aleatórios: assume que os estudos avaliam efeitos verdadeiros diferentes, com uma distribuição normal. É mais apropriado quando há heterogeneidade entre os estudos, pois considera a variação entre eles além do erro de amostragem.412 Modelo de efeitos de rede: estende a meta-análise para comparar múltiplas intervenções simultaneamente, mesmo que não tenham sido comparadas diretamente em estudos. É útil para avaliar a eficácia relativa de várias intervenções.REF? O pacote metafor413 fornece a função forest para criar figuras tipo forest plot. O pacote netmeta414 fornece a função netmeta para realizar meta-análise de rede usando método de grafo. O pacote gemtc415 fornece a função mtc.model para criar modelos de meta-análise de rede. Figura 53.1: Comparação entre modelos de efeito fixo e aleatório com 10 ensaios clínicos simulados. 53.3 Conversão de Medidas em Meta-análises 53.3.1 O que fazer quando os estudos apresentam resultados com diferentes parâmetros? Quando os estudos reportam médias e desvios-padrão, os dados podem ser usados diretamente na metanálise.REF? Quando apresentam mediana e intervalo interquartil (ou mínimo–máximo), existem métodos estatísticos para converter em média e DP.416 Hozo et al. (2005) propuseram fórmulas para estimar a média e o desvio-padrão a partir da mediana, amplitude e tamanho da amostra.416 Wan et al. (2014) aperfeiçoaram essas estimativas, oferecendo métodos mais precisos para converter mediana e IQR em média e DP.417 O pacote metafor413 fornece a função conv.fivenum para converter mínimo/mediana/máximo ou Q1/mediana/Q2 em média e desvio-padrão. 53.4 Interpretação de efeitos em meta-análise 53.4.1 Como avaliar a variação do tamanho do efeito? O intervalo de predição contém informação sobre a variação do tamanho do efeito.418 Se o intervalo de predição não contém a hipótese nula (\\(H_{0}\\)), podemos concluir que (a) o tratamento funciona igualmente bem em todas as populações, ou que ele funciona melhor em algumas populações do que em outras.418 Se o intervalo de predição contém a hipótese nula (\\(H_{0}\\)), podemos concluir que o tratamento pode ser benéfico em algumas populações, mas prejudicial em outras, de modo que a estimativa pontual (geralmente a média) torna-se amplamente irrelevante. Nesse caso, é recomendado investigar em que populações o tratamento seria benéfico e em quais causaria danos.418 53.4.2 Como avaliar a heterogeneidade entre os estudos? A heterogeneidade - variação não-aleatória - no efeito do tratamento entre os estudos incluídos em uma meta-análise pode ser avaliada pelo \\(I^{2}\\).418,419 \\(I^{2}\\) representa qual proporção da variância observada reflete a variância nos efeitos verdadeiros em vez do erro de amostragem.418 \\(I^{2}\\) mede a proporção da variância total que pode ser atribuída à heterogeneidade entre os estudos incluídos.419 \\(I^{2}\\) não depende da quantidade de estudos incluídos na meta-análise. Entretanto, \\(I^{2}\\) aumenta com a quantidade de participantes incluídos nos estudos meta-analisados.419 A heterogeneidade entre estudos é explicada de modo mais confiável utilizando dados de pacientes individuais, uma vez que a direção verdadeira da modificação de efeito não pode ser observada a partir de dados agregados no estudo.420 O pacote psychmeta297 fornece a função ma_d para meta-analisar valores d. O pacote psychmeta297 fornece a função ma_r para meta-analisar correlações. 53.5 Interpretação do Forest Plot 53.5.1 O que é um forest plot? Um forest plot é uma representação gráfica dos achados de uma meta-análise. Ele resume os resultados de estudos individuais e apresenta uma estimativa combinada do efeito, permitindo interpretação visual da magnitude, direção e significância estatística dos resultados.421 Figura 53.2: Forest plot de uma meta-análise de efeito fixo com 10 ensaios clínicos simulados. Figura 53.3: Forest plot de uma meta-análise de efeito aleatório com 10 ensaios clínicos simulados. 53.5.2 2. Quais são as seis colunas básicas que um forest plot geralmente apresenta? As seis colunas básicas incluem: estudos incluídos (e subgrupos, se analisados); dados do grupo de intervenção, dados do grupo controle; peso de cada estudo; medida numérica do efeito; representação gráfica do efeito.421 53.5.3 Como diferenciar um desfecho binário de um contínuo em um forest plot? Em desfechos binários, são mostrados número de eventos e total da amostra, sendo o efeito medido por risk ratio (\\(RR\\)) ou odds ratio (\\(OR\\)).421 Em desfechos contínuos, apresentam-se médias, desvios-padrão e tamanhos amostrais, com o efeito medido pela diferença de médias.421 53.5.4 4. O que representa o ponto central da caixa e o tamanho desta no gráfico? O ponto central indica a estimativa pontual do efeito (melhor estmativa para o efeito real).421 O tamanho da caixa é proporcional ao peso do estudo na meta-análise, geralmente maior para estudos com amostras maiores.421 53.5.5 5. Qual é o significado da linha vertical do “nenhum efeito”? É a linha de referência que indica efeito nulo.421 Para desfechos binários, corresponde ao valor 1 (\\(RR\\) ou \\(OR\\) = 1).421 Para desfechos contínuos, corresponde ao valor 0 (diferença de médias = 0).421 Se o intervalo de confiança de um estudo ou do resultado combinado cruza essa linha, o resultado não é estatisticamente significativo.421 53.5.6 6. Como interpretar o diamante na parte inferior do forest plot? O diamante representa o efeito combinado dos estudos incluídos.421 O ponto central do diamante é a estimativa global.421 A largura do diamante representa o intervalo de confiança de 95% para o efeito combinado.421 53.5.7 Como a heterogeneidade pode ser avaliada no forest plot? A variabilidade nos resultados dos estudos incluídos é avaliada pela sobreposição dos intervalos de confiança dos estudos; pelo teste do qui-quadrado (\\(chi^2\\)) e pelo valor de \\(I^{2}\\).421 53.5.8 Quais são as interpretações usuais para os valores de \\(I^{2}\\)? 0% a 40%: pode não ser importante; 30% a 60%: heterogeneidade moderada; 50% a 90%: heterogeneidade substancial; 75% a 100%: heterogeneidade considerável.421 53.6 Viés de publicação em meta-análises 53.6.1 O que é viés de publicação? O viés de publicação ocorre quando estudos com resultados não significativos ou contrários à hipótese tendem a não ser publicados, afetando a estimativa final da meta-análise e podendo levar a conclusões incorretas.422 53.6.2 Quais métodos podem ser usados para identificar viés de publicação? O método mais simples é o funnel plot, que representa a estimativa de efeito de cada estudo em função de sua precisão (\\(1/SE\\)).423 Na ausência de viés, espera-se uma distribuição simétrica (“forma de funil”). Assimetria pode indicar viés de publicação, heterogeneidade entre estudos ou efeitos de tamanho de estudo (small-study effects).423 Para odds ratios (\\(OR\\)), a correlação entre \\(ln(OR)\\) e seu erro padrão pode gerar assimetria mesmo sem viés, por isso recomenda-se, nesses casos, plotar em função do tamanho amostral.424 53.6.3 O que é um gráfico de funil (funnel plot)? É um gráfico de dispersão que relaciona a estimativa de efeito de cada estudo com uma medida de seu tamanho ou precisão (por exemplo, erro-padrão no eixo vertical, em escala invertida). Em condições ideais (ausência de viés e heterogeneidade), os estudos se distribuem de forma simétrica, formando um “funil invertido”.425 Figura 53.4: Gráfico de funil de meta-análise com 10 ensaios clínicos simulados. 53.6.4 A assimetria do funnel plot indica sempre viés de publicação? Viéses de relato (reporting biases), como viés de publicação, viés de linguagem ou de citação.425 Diferenças metodológicas entre estudos pequenos e grandes.425 Heterogeneidade verdadeira (diferença real no efeito conforme o tamanho ou o contexto do estudo).425 Artefatos estatísticos ou mero acaso.425 53.6.5 O que é trim and fill? O método trim and fill “apara” (trim) os estudos que causam assimetria no funnel plot, estima o número de estudos possivelmente ausentes (não publicados) e “preenche” (fill) o gráfico com esses estudos simulados, recalculando o efeito combinado.426 O método assume que a assimetria é causada unicamente por viés de publicação, podendo levar a conclusões equivocadas quando há outras causas, como heterogeneidade.426 53.6.6 O que é o teste de Egger? É um teste estatístico amplamente utilizado que avalia a relação entre o efeito padronizado (\\(efeito/SE\\)) e a precisão (\\(1/SE\\)).423 No entanto, para meta-análises com \\(OR\\), apresenta taxas de erro tipo I excessivas, especialmente quando o efeito é grande ou há alta heterogeneidade.424 53.6.7 O que é o teste de Peters? Uma regressão linear ponderada com \\(ln(OR)\\) como variável dependente e o inverso do tamanho total da amostra como variável independente (modificação do teste de Macaskill).424 Essa abordagem reduz a correlação entre \\(ln(OR)\\) e seu \\(SE\\), resultando em taxas de erro tipo I mais adequadas (~10%) independentemente do tamanho do efeito, número de estudos ou heterogeneidade.424 O teste de Peters é preferível ao teste de Egger quando o desfecho é expresso como OR, pois mantém taxas de erro tipo I adequadas e ainda apresenta poder comparável para detectar viés em condições de baixa heterogeneidade.424 Em casos de alta heterogeneidade, o teste de Egger pode apresentar maior poder, mas sua alta taxa de falsos positivos compromete a interpretação.424 53.6.8 Quais são as recomendações para testar a assimetria? Evitar testes quando há menos de 10 estudos, devido ao baixo poder estatístico.425 Inspecionar visualmente o funnel plot junto com os resultados dos testes.425 Para desfechos contínuos (diferença de médias), o teste de Egger pode ser usado.425 Para desfechos dicotômicos expressos como odds ratio (\\(OR\\)) com baixa heterogeneidade (\\(\\tau^2 &lt; 0,1\\)), considerar os testes de Harbord, Peters ou Rücker.425 Para desfechos dicotômicos expressos como odds ratio(\\(OR\\)) com alta heterogeneidade (\\(\\tau^2 &gt; 0,1\\)), o teste de Rücker com transformação \\(arcsine\\) é mais indicado.425 53.6.9 Como interpretar os resultados de testes de viés de publicação? Um resultado não significativo não garante ausência de viés.424 Recomenda-se complementar com inspeção visual do funnel plot e considerar métodos adicionais como trim and fill.424,426 Quando há suspeita de viés, discutir as implicações e interpretar o efeito combinado com cautela.424 O pacote psychmeta297 fornece a função plot_funnel para criar figuras tipo funnel plot. 53.7 Diretrizes para redação 53.7.1 Quais são as diretrizes para redação de meta-análises? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. The PRISMA 2020 statement: An updated guideline for reporting systematic reviews:427 https://www.equator-network.org/reporting-guidelines/prisma/ O pacote metagear428 fornece a função plot_PRISMA para gerar o fluxograma de uma revisão sistemática de acordo com o Preferred Reporting Items for Systematic Reviews and Meta-Analyses429. O pacote PRISMA2020430 fornece a função PRISMA_flowdiagram para elaboração do fluxograma de revisões sistemáticas no formato padrão. /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["pesquisa-qualitativa.html", "Capítulo 54 Pesquisa qualitativa 54.1 Pesquisa qualitativa", " Capítulo 54 Pesquisa qualitativa 54.1 Pesquisa qualitativa 54.1.1 O que é pesquisa qualitativa? No contexto de ensaios clínicos randomizados, pesquisa qualitativa é usada para compreender a complexidade das intervenções e dos contextos sociais em que são testadas, contribuindo para gerar evidências de efetividade.431 O valor potencial da pesquisa qualitativa inclui: otimizar a intervenção e procedimentos dos ensaios clínicos randomizados; facilitar a interpretação dos achados; fortalecer a condução ética; ampliar a validade externa ; e economizar recursos ao direcionar futuros ensaios clínicos randomizados para intervenções mais promissoras.431 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["parte-11.html", "PARTE 11: COMUNICAÇÃO E RELATO CIENTÍFICO Transformando resultados em narrativas claras, completas e alinhadas às boas práticas", " PARTE 11: COMUNICAÇÃO E RELATO CIENTÍFICO Transformando resultados em narrativas claras, completas e alinhadas às boas práticas "],["redacao-resultados.html", "Capítulo 55 Redação de resultados 55.1 Resultados da análise estatística 55.2 Diretrizes e Listas", " Capítulo 55 Redação de resultados 55.1 Resultados da análise estatística 55.1.1 Como redigir os resultados da análise estatística? .REF? O pacote report432 fornece a função report para redigir a descrição de diversas análises estatísticas. 55.2 Diretrizes e Listas 55.2.1 Quais diretrizes estão disponíveis para redação estatística? Review of guidance papers on regression modeling in statistical series of medical journals.433 Principles and recommendations for incorporating estimands into clinical study protocol templates.434 How to write statistical analysis section in medical research.253 Recommendations for Statistical Reporting in Cardiovascular Medicine: A Special Report From the American Heart Association.435 Framework for the treatment and reporting of missing data in observational studies: The Treatment And Reporting of Missing data in Observational Studies framework.436 Guidelines for reporting of figures and tables for clinical research in urology.437 Who is in this study, anyway? Guidelines for a useful Table 1.219 Guidelines for Reporting of Statistics for Clinical Research in Urology.438 Reveal, Don’t Conceal: Transforming Data Visualization to Improve Transparency.208 Guidelines for the Content of Statistical Analysis Plans in Clinical Trials.338 Basic statistical reporting for articles published in Biomedical Journals: The ‘’Statistical Analyses and Methods in the Published Literature’’ or the SAMPL Guidelines.439 Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm.440 STRengthening analytical thinking for observational studies: the STRATOS initiative.441 Research methods and reporting.442 How to ensure your paper is rejected by the statistical reviewer.443 55.2.2 Quais listas de verificação estão disponíveis para redação estatística? A CHecklist for statistical Assessment of Medical Papers (the CHAMP statement): explanation and elaboration.444 Checklist for clinical applicability of subgroup analysis.445 Evidence-based statistical analysis and methods in biomedical research (SAMBR) checklists according to design features.252 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["diretrizes-listas.html", "Capítulo 56 Diretrizes e Listas 56.1 Diretrizes 56.2 Listas de verificação", " Capítulo 56 Diretrizes e Listas 56.1 Diretrizes 56.1.1 Quais são as diretrizes para relatórios estatísticos em pesquisas? Visite a rede Enhancing the QUAlity and Transparency Of health Research (EQUATOR Network) para encontrar diretrizes específicas. Guidelines for Reporting Observational Research in Urology: The Importance of Clear Reference to Causality.243 Review of guidance papers on regression modeling in statistical series of medical journals.433 Principles and recommendations for incorporating estimands into clinical study protocol templates.434 How to write statistical analysis section in medical research.253 A Guideline for Reporting Mediation Analyses of Randomized Trials and Observational Studies: The AGReMA Statement.446 Recommendations for Statistical Reporting in Cardiovascular Medicine: A Special Report From the American Heart Association.435 Framework for the treatment and reporting of missing data in observational studies: The Treatment And Reporting of Missing data in Observational Studies framework.436 Guidelines for reporting of figures and tables for clinical research in urology.437 Who is in this study, anyway? Guidelines for a useful Table 1.219 Guidelines for Reporting of Statistics for Clinical Research in Urology.438 Reveal, Don’t Conceal: Transforming Data Visualization to Improve Transparency.208 Guidelines for the Content of Statistical Analysis Plans in Clinical Trials.338 Basic statistical reporting for articles published in Biomedical Journals: The ‘’Statistical Analyses and Methods in the Published Literature’’ or the SAMPL Guidelines.439 Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm.440 STRengthening analytical thinking for observational studies: the STRATOS initiative.441 Research methods and reporting.442 How to ensure your paper is rejected by the statistical reviewer.443 56.2 Listas de verificação 56.2.1 Quais são as listas de verificação para relatórios estatísticos em pesquisas? A CHecklist for statistical Assessment of Medical Papers (the CHAMP statement): explanation and elaboration.444 Checklist for clinical applicability of subgroup analysis.445 Evidence-based statistical analysis and methods in biomedical research (SAMBR) checklists according to design features.252 /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, Referências "],["fontes-externas.html", "Capítulo 57 Fontes externas 57.1 Fontes de informação externas", " Capítulo 57 Fontes externas 57.1 Fontes de informação externas 57.1.1 American Heart Association Statistical Reporting Recommendations - AHA/ASA journals 57.1.2 American Physiological Society Statistics Exploration in Statistics General Statistics Reporting Statistics 57.1.3 American Statistical Association Statistical Inference in the 21st Century: A World Beyond p &lt; 0.05 - The American Statistical Association 57.1.4 British Medicine Journal Statistics - Latest from The BMJ Statistics notes - Latest from The BMJ Statistics and research methods - Latest from The BMJ Statistics at Square One Research methods &amp; reporting 57.1.5 Enhancing the QUality And Transparency Of health Research Network Enhancing the Quality and Transparency of health research EQUATOR Network 57.1.6 Journal of the Amercan Medical Association JAMA Guide to Statistics and Methods - JAMA 57.1.7 Nature Publishing Group Statistics for Biologists - Nature Publising Group 57.1.8 Oxford Reference A Dictionary of Statistics 57.1.9 Royal Statistical Society Best Practices for Data Visualisation - Royal Statistical Society 57.1.10 Statistics in Medicine Tutorials in Biostatistics Papers 57.1.11 BMC Trials Design and analysis of n-of-1 trials 57.1.12 The Journal of Applied Statistics in the Pharmaceutical Industry Tutorial Papers /*____Create and format infobox____*/ .infobox { padding: 1em 1em 1em 4em; margin-bottom: 10px; border: 2px solid orange; border-radius: 10px; background: #F2F2F2 5px center/3em no-repeat; } .BookCover { background-image: url(\"images/Cover_1.png\"); background-size: 2em; background-position: 1em center; } Citar como: Ferreira, Arthur de Sá. Ciência com R: Perguntas e respostas para pesquisadores e analistas de dados. Rio de Janeiro: 1a edição, "],["parte-12.html", "REFERÊNCIAS", " REFERÊNCIAS "],["referencias.html", "Referências", " Referências "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
