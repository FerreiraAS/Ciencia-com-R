```{=openxml}
<w:p>
  <w:r>
    <w:br w:type="page"/>
  </w:r>
</w:p>
```
# **Aprendizado de máquina** {#aprendizado-maquina}

<br>

## Aprendizado de máquina

<br>

### O que é aprendizado de máquina?

-   Treinar um modelo significa resolver um problema matemático no qual um conjunto de observações (dados) é usado para ajustar um modelo. Esse modelo busca capturar tendências gerais dos dados, ignorando particularidades excessivas para evitar sobreajuste (*overfitting*).[@burger2026]

-   O processo deriva do conceito estatístico de regressão e corresponde, em essência, à solução de um problema em que há mais restrições do que graus de liberdade.[@burger2026]

<br>

```{r aprendizado-maquina, include = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Mapa mental de algoritmos de aprendizado de máquina.", out.width = "100%"}

col_root  <- "#E57E25"   # laranja (Aprendizado de Máquina)
col_sup   <- "#CFE9CF"   # verde claro (Supervisionado)
col_uns   <- "#FFD778"   # amarelo (Não Supervisionado)
col_semi  <- "#CFCFD3"   # cinza (Semi-supervisionado)
col_reinf <- "#B9CDF3"   # azul claro (Reforço)
col_text_dark <- "#333333"

dot <- sprintf('
digraph ml {
  graph [
    rankdir=LR
    bgcolor="white"
    nodesep=0.45
    ranksep=0.55
  ]

  node [shape=box style="rounded,filled" fontname="Helvetica" fontsize=11 color="#666666" fontcolor="%1$s"]
  edge [color="#888888" arrowsize=0.6 penwidth=1.1]

  # Raiz
  ML  [label="Aprendizado de Máquina", fillcolor="%2$s", fontcolor="white", penwidth=1.2]

  # Primeira camada
  SUP [label="Supervisionado",         fillcolor="%3$s"]
  UNS [label="Não Supervisionado",     fillcolor="%4$s"]
  SEMI[label="Semi-Supervisionado",    fillcolor="%5$s"]
  REIN[label="Aprendizado por Reforço",fillcolor="%6$s"]

  ML -> {SUP UNS SEMI REIN}

  # ---------------- Supervisionado ----------------
  CLC [label="Classificação", fillcolor="%3$s"]
  RGR [label="Regressão",     fillcolor="%3$s"]
  SUP -> {CLC RGR}

  NB   [label="Naïve Bayes",                               fillcolor="%3$s"]
  LR   [label="Regressão Logística",                       fillcolor="%3$s"]
  KNN  [label="K-Vizinhos Mais Próximos (KNN)",            fillcolor="%3$s"]
  RF   [label="Floresta Aleatória",                        fillcolor="%3$s"]
  SVM  [label="Máquina de Vetores de Suporte (SVM)",       fillcolor="%3$s"]
  DT   [label="Árvore de Decisão",                         fillcolor="%3$s"]
  CLC -> {NB LR KNN RF SVM DT}

  SLR  [label="Regressão Linear Simples",  fillcolor="%3$s"]
  MLR  [label="Regressão Multivariada",    fillcolor="%3$s"]
  LASSO[label="Regressão Lasso",           fillcolor="%3$s"]
  RGR -> {SLR MLR LASSO}

  # ---------------- Não Supervisionado ----------------
  CLU [label="Agrupamento (Clustering)", fillcolor="%4$s"]
  ASC [label="Associação",               fillcolor="%4$s"]
  ANO [label="Detecção de Anomalias",    fillcolor="%4$s"]
  UNS -> {CLU ASC ANO}

  KMEANS [label="K-Means (K-médias)",                                   fillcolor="%4$s"]
  DBSCAN [label="DBSCAN",                                                fillcolor="%4$s"]
  PCA    [label="Análise de Componentes Principais (PCA)",               fillcolor="%4$s"]
  ICA    [label="Análise de Componentes Independentes (ICA)",            fillcolor="%4$s"]
  CLU -> {KMEANS DBSCAN PCA ICA}

  FPG   [label="Crescimento de Padrões Frequentes (FP-Growth)", fillcolor="%4$s"]
  APR   [label="Algoritmo Apriori",                              fillcolor="%4$s"]
  ASC -> {FPG APR}

  ZS    [label="Z-score",                        fillcolor="%4$s"]
  IFOR  [label="Floresta de Isolamento",         fillcolor="%4$s"]
  ANO -> {ZS IFOR}

  # ---------------- Semi-Supervisionado ----------------
  SS_C [label="Classificação", fillcolor="%5$s"]
  SS_R [label="Regressão",     fillcolor="%5$s"]
  SEMI -> {SS_C SS_R}

  ST    [label="Auto-Treinamento (Self-Training)", fillcolor="%5$s"]
  COT   [label="Co-Treinamento (Co-Training)",     fillcolor="%5$s"]
  SS_C -> ST
  SS_R -> COT

  # ---------------- Reforço ----------------
  MF   [label="Sem Modelo (Model-Free)",     fillcolor="%6$s"]
  MB   [label="Baseado em Modelo (Model-Based)", fillcolor="%6$s"]
  REIN -> {MF MB}

  PO   [label="Otimização de Política", fillcolor="%6$s"]
  QL   [label="Q-Learning",            fillcolor="%6$s"]
  MF -> {PO QL}

  LTM  [label="Aprender o Modelo",  fillcolor="%6$s"]
  GTM  [label="Dado o Modelo",      fillcolor="%6$s"]
  MB -> {LTM GTM}

  {rank=same; SUP; UNS; SEMI; REIN}
  {rank=same; CLC; RGR; CLU; ASC; ANO; SS_C; SS_R; MF; MB}
}
', col_text_dark, col_root, col_sup, col_uns, col_semi, col_reinf)

g <- DiagrammeR::grViz(dot)

# Exporta para SVG
svg <- DiagrammeRsvg::export_svg(g)

# Salva em PNG para LaTeX e HTML
latex.path <- file.path(
 getwd(),
  "Ciencia-com-R_files",
  "figure-latex"
)
html.path <- file.path(
 getwd(),
  "Ciencia-com-R_files",
  "figure-html"
)
file.name <- "aprendizado-maquina.png"

dir.create(latex.path, recursive = TRUE, showWarnings = FALSE)
dir.create(html.path, recursive = TRUE, showWarnings = FALSE)

pandoc_to <- knitr::pandoc_to()

# Decide output directory
out_path <- switch(
  pandoc_to,
  "latex"  = latex.path,
  "beamer" = latex.path,
  "pdf"    = latex.path,
  "epub"   = html.path,
  "html"   = html.path,
  "html4"  = html.path,
  "html5"  = html.path,
  "docx"   = html.path,
  "pptx"   = html.path,
  html.path
)

# Render SVG to PNG
png_file <- file.path(out_path, file.name)

rsvg::rsvg_png(
  charToRaw(svg),
  file   = png_file,
  width  = 1200,
  height = 1000
)

# Include graphic (works for all targets above)
knitr::include_graphics(png_file)
```

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *fastml*[@fastml] fornece a função [*train_models*](https://cran.r-project.org/web/packages/fastml/fastml.pdf) para treinar algoritmos de aprendizado de máquina em dados de treinamento pré-processados.
:::

<br>

## Representação de dados e engenharia de atributos

<br>

### Como representar texto como vetores?

-   .[@REF]

<br>

### O que é *one-hot*, *multi-hot* e *count encoding*?

-   *One-hot encoding*: cria uma coluna binária para cada categoria de uma variável categórica, indicando a presença (1) ou ausência (0) da categoria em cada observação.[@REF]

-   *Multi-hot encoding*: semelhante ao one-hot, mas permite que múltiplas categorias sejam representadas simultaneamente em uma única observação, útil para variáveis com múltiplas seleções.[@REF]

-   *Count encoding*: substitui categorias por contagens de sua ocorrência no conjunto de dados, capturando a frequência relativa de cada categoria.[@REF]

<br>

```{r hot-encoding, echo=FALSE, warning=FALSE, message=FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Exemplo de codificação one-hot, count encoding e multi-hot encoding."}
library(dplyr)

# Texto original
texto <- "A equipe planeja o projeto com cuidado, a equipe executa as tarefas do projeto, revisa as tarefas e avalia o projeto final."

# Tokenização simples
tokens <- texto %>%
  stringr::str_to_lower() %>%
  stringr::str_replace_all("[[:punct:]]", "") %>%
  stringr::str_split("\\s+") %>%
  unlist() %>%
  purrr::discard(~ .x == "")

# remove stop words
stop_words <- stopwords::stopwords("pt")
tokens <- tokens[!tokens %in% stop_words]

# Vocabulário
vocab <- sort(unique(tokens))

# One-hot por token (token-level)
token_matrix <- matrix(
  0,
  nrow = length(tokens),
  ncol = length(vocab),
  dimnames = list(NULL, vocab)
)

for (i in seq_along(tokens)) {
  token_matrix[i, tokens[i]] <- 1
}

# Agregações (document-level)
count_encoding     <- colSums(token_matrix)
multi_hot_encoding <- as.numeric(count_encoding > 0)

# One-hot agregado (binário)
one_hot_aggregated <- multi_hot_encoding

# Construir data.frame final
final_df <- data.frame(
  Termo = c(
    tokens,
    "One-hot encoding",
    "Multi-hot encoding",
    "Count encoding"
  ),
  rbind(
    token_matrix,
    one_hot_aggregated,
    multi_hot_encoding,
    count_encoding
  ),
  check.names = FALSE
)

rownames(final_df) <- NULL

# Impressão com kable
knitr::kable(
  final_df,
  align = c("l", rep("c", ncol(final_df) - 1)),
  format = ifelse(knitr::is_html_output(), "html", "latex"),
  booktabs = TRUE,
  linesep = "",
  escape = FALSE,
  caption = "Exemplo de codificação one-hot, multi-hot e count encoding para representação de texto."
) %>%
  kableExtra::kable_styling(
    latex_options = c("basic"),
    bootstrap_options = c("basic", "hover", "condensed", "responsive"),
    full_width = TRUE,
    position = "center"
  ) %>%
  kableExtra::row_spec(
    0,
    bold = TRUE,
    extra_css = "border-top: 1px solid black; border-bottom: 1px solid black;"
  ) %>%
  kableExtra::row_spec(
    nrow(final_df) - 2,
    bold = TRUE,
    background = "#F2F2F2",
    extra_css = "border-top: 1px solid black; border-bottom: 1px solid black;"
  ) %>%
  kableExtra::row_spec(
    nrow(final_df) - 1,
    bold = TRUE,
    background = "#F2F2F2",
    extra_css = "border-top: 1px solid black; border-bottom: 1px solid black;"
  ) %>%
  kableExtra::row_spec(
    nrow(final_df), 
    bold = TRUE,
    background = "#F2F2F2",
    extra_css = "border-top: 1px solid black; border-bottom: 1px solid black;"
  ) %>% 
  kableExtra::footnote(
    general_title = "Frase original:",
    general = texto
  )
```

<br>

## Métricas de distância e similaridade

<br>

### O que é uma métrica?

-   Uma métrica é uma função que quantifica a distância entre dois objetos em um espaço vetorial, obedecendo propriedades como não-negatividade, identidade, simetria e desigualdade triangular.[@REF]

<br>

### Quais são as principais métricas?

-   Distância Manhattan \@ref(eq:manhattan): soma das diferenças absolutas entre as coordenadas dos pontos.[@REF]

<br>

\begin{equation}
(\#eq:manhattan)
d(x, y) = \sum_{i=1}^{n} |x_i - y_i|
\end{equation}

<br>

-   Distância Euclidiana \@ref(eq:euclidiana): raiz quadrada da soma dos quadrados das diferenças entre as coordenadas dos pontos.[@REF]

<br>

\begin{equation}
(\#eq:euclidiana)
d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
\end{equation}

<br>

-   Distância Minkowski: \@ref(eq:minkowski): generalização das distâncias de Manhattan e Euclidiana, onde o parâmetro $p$ determina a ordem da métrica. Para $p=1$, é equivalente à distância de Manhattan; para $p=2$, é equivalente à distância Euclidiana.[@REF]

<br>

\begin{equation}
(\#eq:minkowski)
d(x, y) = \left( \sum_{i=1}^{n} |x_i - y_i|^p \right)^{\frac{1}{p}}
\end{equation}

<br>

-   Distância Chebyshev \@ref(eq:chebyshev): máximum das diferenças absolutas entre as coordenadas dos pontos, representando a distância em um espaço onde o movimento é permitido em todas as direções.[@REF]

<br>

\begin{equation}
(\#eq:chebyshev)
d(x, y) = \max_{i} |x_i - y_i|
\end{equation}

<br>

-   Similaridade cosseno \@ref(eq:cosine): medida de similaridade entre dois vetores que calcula o cosseno do ângulo entre eles, variando de -1 (totalmente opostos) a 1 (totalmente semelhantes).[@REF]

<br>

\begin{equation}
(\#eq:cosine)
\text{similaridade}(x, y) = \frac{x \cdot y}{\|x\| \|y\|}
\end{equation}

<br>

-   Distância de Hamming \@ref(eq:hamming): número de posições em que os símbolos correspondentes de duas sequências de igual comprimento são diferentes, frequentemente usada para medir a diferença entre strings ou códigos binários.[@REF]

<br>

\begin{equation}
(\#eq:hamming)
d(x, y) = \sum_{i=1}^{n} \mathbf{1}(x_i \neq y_i)
\end{equation}

<br>

-   Índice de Jaccard \@ref(eq:jaccard): medida de similaridade entre conjuntos, calculada como a razão entre a interseção e a união dos conjuntos, variando de 0 (sem elementos em comum) a 1 (conjuntos idênticos).[@REF]

<br>

\begin{equation}
(\#eq:jaccard)
\text{similaridade}(A, B) = \frac{|A \cap B|}{|A \cup B|}
\end{equation}

<br>

```{r distances, echo=FALSE, warning=FALSE, message=FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Visualização de diferentes métricas de distância e similaridade."}
library(tidyverse)
library(gridExtra)

# Base points
x <- c(1, 2)
y <- c(4, 6)

# Manhattan Distance
p_manhattan <- ggplot() +
  geom_segment(aes(x=x[1], y=x[2], xend=y[1], yend=x[2]),
               size=1.2, color="orange") +
  geom_segment(aes(x=y[1], y=x[2], xend=y[1], yend=y[2]),
               size=1.2, color="orange") +
  geom_point(aes(x=x[1], y=x[2]), size=4) +
  geom_point(aes(x=y[1], y=y[2]), size=4, color="red") +
  coord_fixed() +
  ggtitle("Manhattan Distance (L1)") +
  theme_minimal()

# Euclidean Distance
p_euclid <- ggplot() +
  geom_segment(aes(x=x[1], y=x[2], xend=y[1], yend=y[2]),
               size=1.2, color="steelblue") +
  geom_point(aes(x=x[1], y=x[2]), size=4) +
  geom_point(aes(x=y[1], y=y[2]), size=4, color="red") +
  coord_fixed() +
  ggtitle("Euclidean Distance") +
  theme_minimal()

#  Chebyshev Distance
p_cheb <- ggplot() +
  geom_segment(aes(x=x[1], y=x[2], xend=y[1], yend=x[2]),
               linetype="dashed") +
  geom_segment(aes(x=y[1], y=x[2], xend=y[1], yend=y[2]),
               linetype="dashed") +
  geom_segment(aes(x=x[1], y=x[2], xend=x[1], yend=y[2]),
               size=1.2, color="purple") +
  geom_point(aes(x=x[1], y=x[2]), size=4) +
  geom_point(aes(x=y[1], y=y[2]), size=4, color="red") +
  coord_fixed() +
  ggtitle("Chebyshev Distance (L∞)") +
  theme_minimal()

# Cosine Distance (Angle)
p_cos <- ggplot() +
  geom_segment(aes(x=0, y=0, xend=x[1], yend=x[2]),
               size=1.2, color="blue") +
  geom_segment(aes(x=0, y=0, xend=y[1], yend=y[2]),
               size=1.2, color="red") +
  coord_fixed() +
  ggtitle("Cosine Similarity (Angle)") +
  theme_minimal()

# Hamming Distance
x_bin <- c(1,0,1,0,1)
y_bin <- c(1,1,0,0,1)

hamming_df <- tibble(
  pos = 1:5,
  x = x_bin,
  y = y_bin,
  diff = x_bin != y_bin
)

p_hamming <- ggplot(hamming_df, aes(x=pos, y=1)) +
  geom_text(aes(label=x), vjust=-1) +
  geom_text(aes(label=y), y=0.8, vjust=1) +
  geom_point(aes(color=diff), size=4) +
  scale_color_manual(values=c("black","red")) +
  ggtitle("Hamming Distance") +
  theme_void()

#  Jaccard Distance
library(ggforce)

p_jaccard <- ggplot() +
  geom_circle(aes(x0=0, y0=0, r=2), fill="orange", alpha=0.4) +
  geom_circle(aes(x0=2, y0=0, r=2), fill="blue", alpha=0.4) +
  coord_fixed() +
  ggtitle("Jaccard Distance (Set Overlap)") +
  theme_void()

# Combine panels
grid.arrange(
  p_manhattan, p_euclid, p_cos,
  p_hamming, p_cheb, p_jaccard,
  ncol=3
)
```

<br>

### Como escolher a métrica adequada?

-   A escolha da métrica depende do tipo de dados (contínuos, categóricos, binários), da escala das variáveis, da presença de outliers e do objetivo da análise (agrupamento, classificação, etc.).[@REF]

<br>

## Tipos de aprendizado

<br>

### O que é aprendizado supervisionado?

-   .[@REF]

<br>

### O que é aprendizado não supervisionado?

-   .[@REF]

<br>

### O que é aprendizado semi-supervisionado?

-   .[@REF]

<br>

### O que é aprendizado por reforço?

-   .[@REF]

<br>

### O que é aprendizado profundo?

-   .[@REF]

<br>

### Quais são os limites do progresso em classificadores supervisionados?

-   Os maiores ganhos de acurácia vêm de modelos simples, como análise discriminante linear; métodos mais sofisticados oferecem apenas ganhos marginais.[@hand2006]

-   O aumento da complexidade do modelo traz retornos decrescentes em termos de redução da taxa de erro.[@hand2006]

<br>

### Quais problemas práticos limitam a generalização de classificadores?

-   *Population drift*: mudanças na distribuição dos dados ao longo do tempo degradam a performance de modelos.[@hand2006]

-   *Sample selectivity bias*: amostras de treino podem não representar a população futura, levando a superestimação de desempenho.[@hand2006]

-   Erros de rótulo e definições arbitrárias de classes comprometem a validade dos modelos.[@hand2006]

<br>

### Por que estudos comparativos entre classificadores podem ser enganosos?

-   Resultados dependem da experiência do pesquisador com cada método, da escolha dos conjuntos de dados e do critério de avaliação usado.[@hand2006]

-   Diferenças pequenas em acurácia frequentemente desaparecem quando se consideram incertezas reais de aplicação.[@hand2006]

<Br>

## Avaliação de modelos de classificação

<br>

### O que é uma matriz de confusão 2x2?

-   A matriz de confusão é uma tabela de contingência 2×2 utilizada para avaliar o desempenho de um classificador binário, comparando as classes verdadeiras observadas com as classes previstas pelo modelo.[@hicks2022]

-   Em aprendizado supervisionado, ela permite decompor os erros de classificação e analisar como o modelo se comporta em relação a cada classe.[@hicks2022]

<br>

### Como interpretar uma matriz de confusão 2x2?

-   Verdadeiro-positivo ($VP$): instância cuja classe verdadeira é positiva e foi corretamente classificada como positiva.[@hicks2022]

-   Falso-negativo ($FN$): instância positiva que foi incorretamente classificada como negativa.[@hicks2022]

-   Verdadeiro-negativo ($VN$): instância negativa corretamente classificada como negativa.[@hicks2022]

-   Falso-positivo ($FP$): instância negativa incorretamente classificada como positiva.[@hicks2022]

<br>

```{r crosstable-2x2-aprendizado, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, tab.cap = "Tabela de confusão 2x2 para análise de desempenho diagnóstico de testes e variáveis dicotômicas."}
library(dplyr)

cross.table <-
  matrix(
    c(
      '$VP$',
      '$FN$',
      '$VP+FN$',
      '$FP$',
      '$VN$',
      '$FP+VN$',
      '$VP+FP$',
      '$FN+VN$',
      '$N=VP+VN+FP+FN$'
    ),
    nrow = 3,
    ncol = 3,
    byrow = FALSE
  )
rownames(cross.table) <-
  c("Classe verdadeira correta", "Classe verdadeira incorreta", "Total")
colnames(cross.table) <-
  c("Classe predita correta", "Classe predita incorreta", "Total")

# exibe a tabela de dados
knitr::kable(
  cross.table,
  align = "c",
  format = ifelse(knitr::is_html_output(), "html", "latex"),
  booktabs = TRUE,
  linesep = "",
  escape = FALSE
) %>%
  kableExtra::kable_styling(
    latex_options = c("basic"),
    bootstrap_options = c("basic", "hover", "condensed", "responsive"),
    full_width = ifelse(knitr::is_html_output(), TRUE, TRUE),
    position = "center"
  ) %>%
  kableExtra::row_spec(0, bold = TRUE, extra_css = "border-top: 1px solid; border-bottom: 1px solid") %>%
  kableExtra::row_spec((dim(cross.table)[1] - 1), bold = TRUE, extra_css = "border-bottom: 1px solid") %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::row_spec(dim(cross.table)[1], extra_css = "border-bottom: 1px solid")
```

<br>

### Quais métricas caracterizam o desempenho de um classificador?

-   Acurácia ($ACU$) \@ref(eq:acu): Proporção de classificações corretas (verdadeiros-positivos e verdadeiros-negativos) em relação ao total de casos.[@hicks2022]

<br>

\begin{equation}
(\#eq:acu)
ACU = \dfrac{VP + VN}{VP + FN + VN + FP}
\end{equation}

-   Precisão ($PRE$) \@ref(eq:pre): Proporção de verdadeiro-positivos dentre aqueles classificados como positivos.[@hicks2022]

<br>

\begin{equation}
(\#eq:pre)
PRE = \dfrac{VP}{VP + FP}
\end{equation}

<br>

-   Revocação ($REV$) \@ref(eq:rev): Proporção de verdadeiro-positivos dentre aqueles com a condição, equivalente à sensibilidade.[@hicks2022]

<br>

\begin{equation}
(\#eq:rev)
REV = \dfrac{VP}{VP + FN}
\end{equation}

<br>

-   F1-score ($F1$) \@ref(eq:f1): Média harmônica entre precisão e revocação, balanceando ambos os aspectos do desempenho.[@hicks2022]

<br>

\begin{equation}
(\#eq:f1)
F1 = 2 \times \dfrac{PRE \times REC}{PRE + REC}
\end{equation}

<br>

## Principais algoritmos

<br>

### Quais são os principais algoritmos de aprendizado de máquina?

-   Modelos de regressão não penalizados, modelos de regressão penalizados, modelos baseados em árvores, modelos baseados em vizinhos, redes neurais, máquinas de vetores de suporte, Naive Bayes e ensembles do tipo Superlearner.[@andaurnavarro2023]

-   Do ponto de vista matemático, redes neurais não contradizem a estatística clássica; elas a estendem, substituindo modelos explícitos por representações aprendidas.[@REF]

<br>

```{r rede-neural-vs-regressao, echo=FALSE, warning=FALSE, message=FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Equivalência conceitual entre modelos de regressão e redes neurais artificiais."}
library(dplyr)

tabela_equivalencia <- data.frame(
  `Modelos de regressão` = c(
    "Variável preditora (x)",
    "Coeficiente (β)",
    "Intercepto (β₀)",
    "Combinação linear (β₀ + Σ βᵢxᵢ)",
    "Função de ligação (link)",
    "Regressão linear",
    "Regressão logística",
    "Log-odds",
    "Predição (ŷ)",
    "Função de perda",
    "Máxima verossimilhança",
    "Gradiente da verossimilhança",
    "Regularização (L1, L2)",
    "Interações explícitas",
    "Modelo interpretável"
  ),
  `Redes neurais artificiais` = c(
    "Neurônio de entrada",
    "Peso (w)",
    "Viés (b)",
    "Soma ponderada (Σ wᵢxᵢ + b)",
    "Função de ativação",
    "Neurônio linear",
    "Perceptron com ativação sigmoide",
    "Entrada da função sigmoide",
    "Saída do neurônio",
    "Função de perda (loss)",
    "Otimização da função de perda",
    "Retropropagação (backpropagation)",
    "Penalização de pesos (weight decay)",
    "Interações aprendidas implicitamente",
    "Modelo geralmente opaco"
  ),
  `Papel conceitual` = c(
    "Informação observada fornecida ao modelo",
    "Intensidade e direção da influência da variável",
    "Deslocamento da fronteira de decisão",
    "Agregação das entradas antes da não linearidade",
    "Introdução de não linearidade",
    "Modelo puramente linear",
    "Classificação binária probabilística",
    "Escala interna antes da probabilidade",
    "Resposta estimada do modelo",
    "Quantificação do erro de predição",
    "Ajuste dos parâmetros do modelo",
    "Direção de atualização dos parâmetros",
    "Controle de complexidade e overfitting",
    "Modelagem de efeitos combinados",
    "Trade-off entre interpretação e flexibilidade"
  )
)

# renomear colunas
colnames(tabela_equivalencia) <- c(
  "Modelos de regressão",
  "Redes neurais artificiais",
  "Papel conceitual"
  )

knitr::kable(
  tabela_equivalencia,
  align = c("l"),
  format = ifelse(knitr::is_html_output(), "html", "latex"),
  booktabs = TRUE,
  linesep = "",
  escape = FALSE
)  %>%
  kableExtra::kable_styling(
    latex_options = c("basic"),
    bootstrap_options = c("basic", "hover", "condensed", "responsive"),
    full_width = ifelse(knitr::is_html_output(), TRUE, TRUE),
    position = "center"
  ) %>%
  kableExtra::row_spec(0,
                       bold = TRUE,
                       extra_css = "border-top: 1px solid; border-bottom: 1px solid") %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::row_spec(dim(tabela_equivalencia)[1],
                       extra_css = "border-bottom: 1px solid")
```

<br>

## Regressão logística

<br>

### O que é regressão logística?

-   Modelos logísticos são casos de regressão linear generalizada em que a resposta $Y$ é binária.[@fernandes2020]

-   A equação \@ref(eq:regressao-logistica) modela a razão de chances (*odds*) em função dos preditores.[@fernandes2020]

<br>

\begin{equation}
(\#eq:regressao-logistica)
\log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1 X + ... + \beta_n X_n
\end{equation}

<br>

-   A ligação (*link*) usada é o logit \@ref(eq:link-logit).[@fernandes2020]

<br>

\begin{equation}
(\#eq:link-logit)
g(p) = \log\left(\frac{p}{1-p}\right)
\end{equation}

<br>

```{r ml-regressao-logistica, include = TRUE, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Regressão logística."}
# simulate X
set.seed(123)
X <- rnorm(100, mean = 50, sd = 10)

# simulate a binary outcome Y based on X
prob <- 1 / (1 + exp(-( -5 + 0.1 * X)))  # logistic function
Y <- rbinom(100, size = 1, prob = prob) # sample Y ~ Bernoulli(prob)

# create a dataframe
data <- data.frame(X, Y)

# create the logistic regression model
model <- glm(Y ~ X, data = data, family = binomial)

# plot the regression line
ggplot2::ggplot(data, ggplot2::aes(x = X, y = Y)) +
  ggplot2::geom_point() +
  ggplot2::geom_smooth(method = "glm", method.args = list(family = "binomial"), color = "blue") +
  ggplot2::labs(title = "Regressão logística",
       x = "Variável Independente (X)",
       y = "Probabilidade de Sucesso (Y)") +
  ggplot2::theme_minimal()
```

<br>

## Máquina de vetores de suporte

<br>

### O que são máquinas de vetores de suporte?

-   .[@REF]

<br>

## *K-nearest neighbours*

<br>

### O que é *K-nearest neighbours*?

-   .[@REF]

<br>

## *K-means Clustering*

<br>

### O que é *K-means clustering*?

-   .[@REF]

<br>

## Árvores de decisão

<br>

### O que são árvores de decisão?

-   São modelos de aprendizado supervisionado que dividem os dados em ramos e folhas, representando regras de decisão de forma hierárquica.[@hozo2023]

-   Podem lidar eficientemente com grandes conjuntos de dados sem pressupor estrutura paramétrica complexa.[@Song2015]

-   São aplicáveis a variáveis contínuas e discretas, tanto como preditoras quanto como desfechos.[@Song2015]

<br>

```{r arvore-decisao, echo=FALSE, warning=FALSE, message=FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Exemplo de árvore de decisão para predizer depressão a partir de idade, tabagismo e sintomas."}
# Dados simulados
set.seed(123)

# Gerar dados
n <- 200
df <- data.frame(
  idade = sample(20:70, n, replace=TRUE),
  tabagismo = sample(c("Sim", "Não"), n, replace=TRUE, prob=c(0.3,0.7)),
  sintomas = sample(0:3, n, replace=TRUE),
  depressao = sample(c("Sim","Não"), n, replace=TRUE, prob=c(0.4,0.6))
)

# Ajuste de árvore de decisão
mod <- rpart::rpart(depressao ~ idade + tabagismo + sintomas, data=df, method="class")

# Visualização
rpart.plot::rpart.plot(mod, type=3, extra=104, fallen.leaves=TRUE)
```

<br>

### Quais são os principais usos de árvores de decisão?

-   Seleção de variáveis relevantes em cenários com muitos preditores, como registros clínicos eletrônicos.[@Song2015]

-   Avaliação da importância relativa das variáveis, com base na redução da pureza dos nós ou da acurácia ao remover variáveis.[@Song2015]

-   Tratamento de valores ausentes, seja classificando-os como categoria própria ou imputando-os por previsão dentro da árvore.[@Song2015]

-   Predição de novos casos a partir de dados históricos.[@Song2015]

-   Manipulação de dados, colapsando categorias muito numerosas ou subdividindo variáveis contínuas assimétricas.[@Song2015]

<br>

### Quais são os componentes básicos de uma árvore de decisão?

-   Nós raiz (ou de decisão): subdividem todos os registros iniciais.[@Song2015]

-   Nós internos (ou de chance): representam subdivisões intermediárias.[@Song2015]

-   Nós folha (ou finais): resultados finais após sucessivas divisões.[@Song2015]

-   Ramos: representam condições “se-então”, ligando nós em sequência até a classificação final.[@Song2015]

<br>

### Como funcionam splitting, stopping e pruning?

-   *Splitting*: divide registros em subconjuntos mais homogêneos com base em métricas como entropia, índice de Gini e ganho de informação.[@Song2015]

-   *Stopping*: evita árvores excessivamente complexas ao definir parâmetros como número mínimo de registros por nó ou profundidade máxima.[@Song2015]

-   *Pruning*: reduz árvores grandes eliminando ramos pouco informativos, usando validação ou métodos como qui-quadrado.[@Song2015]

<br>

### Quais são as vantagens e limitações de árvores de decisão?

-   Vantagens: simplificam relações complexas; são intuitivas e fáceis de interpretar; não exigem pressupostos de distribuição; lidam bem com valores ausentes e dados enviesados; são robustas a *outliers*.[@Song2015]

-   Limitações: podem sofrer *overfitting* ou *underfitting* em amostras pequenas; podem selecionar variáveis correlacionadas sem relação causal real.[@Song2015]

<br>

### Espaço de decisão em árvores de decisão vs. regressão logística

-   A regressão logística assume relações lineares entre variáveis e log-odds.[@hozo2023]

-   Árvores de decisão permitem capturar relações não lineares e interações de forma automática.[@hozo2023]

<br>

```{r logistica-vs-arvore, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.cap = "Comparação entre modelos de regressão logística e árvore de decisão.", fig.width=15, fig.height=8, out.width="100%"}
# Reprodutibilidade
set.seed(42)

# Dados sintéticos
x1 <- rnorm(200)
x2 <- rnorm(200)
y <- ifelse(x1^2 + x2^2 > 1, 1, 0)
df <- data.frame(x1, x2, y = factor(y))

# Ajustar modelos
glm_mod <- glm(y ~ x1 + x2, data=df, family=binomial)
tree_mod <- rpart::rpart(y ~ x1 + x2, data=df)

# Grade para visualizar
grid <- expand.grid(
  x1 = seq(min(x1)-1, max(x1)+1, length=200),
  x2 = seq(min(x2)-1, max(x2)+1, length=200)
)

grid$glm_pred <- predict(glm_mod, newdata=grid, type="response") > 0.5
grid$tree_pred <- predict(tree_mod, newdata=grid, type="class")

lims <- range(c(df$x1, df$x2), na.rm = TRUE)

# Plot lado a lado
p1 <- ggplot2::ggplot() +
  ggplot2::geom_tile(
    data = grid,
    ggplot2::aes(x1, x2, fill = glm_pred),
    alpha = 0.3
  ) +
  ggplot2::geom_point(
    data = df,
    ggplot2::aes(x1, x2, color = y)
  ) +
  ggplot2::scale_x_continuous(limits = lims) +
  ggplot2::scale_y_continuous(limits = lims) +
  ggplot2::coord_equal(expand = FALSE) +
  ggplot2::labs(title = "Logística (linear)") +
  ggplot2::theme_minimal()

p2 <- ggplot2::ggplot() +
  ggplot2::geom_tile(
    data = grid,
    ggplot2::aes(x1, x2, fill = tree_pred),
    alpha = 0.3
  ) +
  ggplot2::geom_point(
    data = df,
    ggplot2::aes(x1, x2, color = y)
  ) +
  ggplot2::scale_x_continuous(limits = lims) +
  ggplot2::scale_y_continuous(limits = lims) +
  ggplot2::coord_equal(expand = FALSE) +
  ggplot2::labs(title = "Árvore (não linear)") +
  ggplot2::theme_minimal()

gridExtra::grid.arrange(p1, p2, ncol=2)
```

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *h2o*[@h2o] fornece funções construir modelos de aprendizado de máquina.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *correctR*[@correctR] fornece as funções [*kfold_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf), [*repkfold_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf) e [*resampled_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf) para calcular estatística para comparação de modelos de aprendizado de máquina em amostras dependentes.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *caret*[@caret](https://cran.r-project.org/web/packages/caret/index.html) fornece um conjunto de funções para pré-processamento, ajuste, avaliação e comparação de modelos de aprendizado de máquina.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *mlr3*[@mlr3](https://cran.r-project.org/web/packages/mlr3/index.html) fornece funções para fluxos de trabalho complexos, incluindo pré-processamento, ajuste de hiperparâmetros e integração com diversos algoritmos.
:::

<br>

## Análise de componentes principais

<br>

### O que é análise de componentes principais?

-   A análise de componentes principais (*Principal Component Analysis*, PCA) é uma técnica estatística amplamente utilizada para redução de dimensionalidade, para representar dados de alta dimensão por um conjunto menor de variáveis, preservando o máximo possível da variabilidade original.[@dyer2023]

-   O primeiro componente principal é definido como a direção, de comprimento unitário, que maximiza a variância dos dados projetados. Ele corresponde ao eixo ao longo do qual os dados apresentam a maior dispersão, concentrando a maior quantidade de informação estatística disponível.[@dyer2023]

-   O segundo componente principal é a direção que maximiza a variância restante, sob a condição de ser ortogonal ao primeiro componente. Essa restrição garante que cada novo componente adicione informação nova, não redundante, à representação dos dados.[@dyer2023]

-   Esse procedimento é repetido para os componentes subsequentes, de forma que cada componente principal seja ortogonal aos anteriores e capture a maior variância possível ainda não explicada, resultando em uma ordenação natural dos componentes por importância.[@dyer2023]

-   Ao final do processo, a PCA produz uma base ortogonal que impõe uma geometria específica à representação dos dados, restringindo a forma como os dados podem ser reconstruídos a partir dos componentes principais.[@dyer2023]

-   Embora os componentes principais descrevam de maneira eficiente a variabilidade dos dados, eles nem sempre correspondem aos fatores geradores subjacentes do fenômeno estudado. A PCA pode ainda introduzir padrões artificiais, criando uma aparência de estrutura que não reflete necessariamente os processos reais de geração dos dados.[@dyer2023]

<br>

```{r pca-facto-mineR, echo=FALSE, warning=FALSE, message=FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Análise de Componentes Principais (PCA). O PC1 maximiza variância total, mas pode não alinhar com o fator latente real (z1)."}
# Reprodutibilidade
set.seed(123)

# Função de rotação 2D
rot2 <- function(theta) {
  matrix(c(cos(theta), -sin(theta),
           sin(theta),  cos(theta)), nrow = 2, byrow = TRUE)
}

# Gerando dados — Cenário 1
n <- 800

# Fatores geradores latentes
z1 <- rnorm(n)
z2 <- rnorm(n)
Z  <- cbind(z1, z2)

# Mistura linear (sinal)
theta <- pi / 5
A <- rot2(theta) %*% diag(c(1.2, 0.6))
X_signal <- Z %*% t(A)

# Ruído anisotrópico
noise_theta <- pi / 10
B <- rot2(noise_theta) %*% diag(c(0.9, 0.15)) %*% t(rot2(noise_theta))
E <- matrix(rnorm(n * 2), n, 2) %*% chol(B)

X <- X_signal + E
colnames(X) <- c("x1", "x2")

df_raw <- data.frame(x1 = X[,1], x2 = X[,2], z1 = z1)

# PCA com FactoMineR
res_pca <- FactoMineR::PCA(
  X,
  scale.unit = FALSE,
  graph = FALSE
)

# Scores (indivíduos)
df_scores <- as.data.frame(res_pca$ind$coord[, 1:2])
colnames(df_scores) <- c("PC1", "PC2")
df_scores$z1 <- z1

# Loadings (variáveis)
df_load <- as.data.frame(res_pca$var$coord[, 1:2])
df_load$var <- rownames(df_load)

# Variância explicada
df_var <- data.frame(
  PC = factor(c("PC1", "PC2"), levels = c("PC1", "PC2")),
  var = res_pca$eig[1:2, 2] / 100
)

# Gráfico 1 — Espaço original
p_raw <- ggplot2::ggplot(df_raw, ggplot2::aes(x1, x2, color = z1)) +
  ggplot2::geom_point(alpha = 0.65, size = 1.6) +
  ggplot2::coord_equal() +
  ggplot2::labs(
    title = "Espaço original",
    subtitle = "Cor indica o fator gerador real (z1)",
    x = "x1", y = "x2", color = "z1"
  ) +
  ggplot2::theme_minimal(base_size = 12)

# Gráfico 2 — Espaço PCA
p_pca <- ggplot2::ggplot(df_scores, ggplot2::aes(PC1, PC2, color = z1)) +
  ggplot2::geom_point(alpha = 0.65, size = 1.6) +
  ggplot2::coord_equal() +
  ggplot2::labs(
    title = "Espaço PCA",
    subtitle = sprintf(
      "Var(PC1)=%.1f%% | Var(PC2)=%.1f%%",
      res_pca$eig[1,2], res_pca$eig[2,2]
    ),
    x = "PC1", y = "PC2", color = "z1"
  ) +
  ggplot2::theme_minimal(base_size = 12)

# Gráfico 3 — Biplot
scale_loading <- 3
df_load$PC1s <- df_load$Dim.1 * scale_loading
df_load$PC2s <- df_load$Dim.2 * scale_loading

p_biplot <- ggplot2::ggplot(df_scores, ggplot2::aes(PC1, PC2)) +
  ggplot2::geom_point(alpha = 0.35, size = 1.4) +
  ggplot2::geom_segment(
    data = df_load,
    ggplot2::aes(x = 0, y = 0, xend = PC1s, yend = PC2s),
    arrow = arrow(length = ggplot2::unit(0.18, "inches")),
    linewidth = 0.9
  ) +
  ggplot2::geom_text(
    data = df_load,
    ggplot2::aes(x = PC1s, y = PC2s, label = var),
    vjust = -0.6,
    size = 4
  ) +
  ggplot2::coord_equal() +
  ggplot2::labs(
    title = "Biplot",
    subtitle = "PCs descrevem variância, não fatores geradores",
    x = "PC1", y = "PC2"
  ) +
  ggplot2::theme_minimal(base_size = 12)

# Gráfico 4 — Variância explicada
p_var <- ggplot2::ggplot(df_var, ggplot2::aes(PC, var)) +
  ggplot2::geom_col() +
  ggplot2::scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  ggplot2::labs(
    title = "Scree plot",
    subtitle = sprintf(
      "Variância total dos dados originais: %.1f%%",
      sum(res_pca$eig[, 2])
    ),
    x = NULL,
    y = "Proporção"
  ) +
  ggplot2::theme_minimal(base_size = 12)

# Painel final 2x2
panel <- (p_raw | p_pca) / (p_biplot | p_var) +
  patchwork::plot_annotation(
    title = "PCA: máxima variância ≠ fator gerador",
  )

print(panel)
```

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *mlr3*[@mlr3](https://cran.r-project.org/web/packages/mlr3/index.html) fornece funções para fluxos de trabalho complexos, incluindo pré-processamento, ajuste de hiperparâmetros e integração com diversos algoritmos.
:::

<br>

## *Random forests*

<br>

### O que são *random forests*?

-   .[@REF]

<br>

## *Ensemble*

<br>

### O que são *ensemble*?

-   .[@REF]

<br>

## Desbalanceamento de classes

<br>

### O que é desbalanceamento de classes (*class imbalance*)?

-   Ocorre quando as classes do desfecho (por exemplo, presença vs. ausência de um evento) não estão igualmente representadas nos dados de treinamento.[@REF]

<br>

### Por que o desbalanceamento é um problema?

-   Modelos podem aprender a priorizar a classe mais frequente, obtendo alta acurácia global, mas baixo desempenho para a classe minoritária.[@REF]

-   Isso pode comprometer métricas como sensibilidade, especificidade e, em alguns casos, a calibração.[@REF]

<br>

### Quais são as abordagens mais comuns para lidar com desbalanceamento de classes?

-   Reamostragem aleatória: superamostragem da classe minoritária; subamostragem da classe majoritária).[@REF]

-   Ajuste de pesos: penaliza mais os erros na classe menos frequente.[@REF]

-   Alteração do limiar de decisão: muda o ponto de corte de probabilidade para otimizar métricas específicas.[@REF]

<br>

### Qual é o impacto do desbalanceamento de classes na calibração de modelos?

-   Corrigir o desbalanceamento de classes nem sempre melhora a calibração e, em alguns casos, pode piorá-la.[@carriero2025]

-   Em simulações computacionais, modelos sem correção tiveram calibração igual ou superior aos corrigidos.[@carriero2025]

-   A piora observada foi caracterizada por superestimação do risco, nem sempre reversível com re-calibração.[@carriero2025]

<br>

```{r, echo=FALSE, warning=FALSE, results='asis', eval=knitr::is_html_output()}
cat(readLines("citation.html"), sep = "\n")
```

<br>
