# **Aprendizado de máquina** {#aprendizado-maquina}

<br>

## Aprendizado de máquina

<br>

### O que é aprendizado de máquina?

-   .[@REF]

<br>

## Tipos de aprendizado

<br>

### O que é aprendizado supervisionado?

-   .[@REF]

<br>

### O que é aprendizado não supervisionado?

-   .[@REF]

<br>

### O que é aprendizado semi-supervisionado?

-   .[@REF]

<br>

### O que é aprendizado por reforço?

-   .[@REF]

<br>

### O que é aprendizado profundo?

-   .[@REF]

<br>

## Principais algoritmos

<br>

### Quais são os principais algoritmos de aprendizado de máquina?

-   Modelos de regressão não penalizados, modelos de regressão penalizados, modelos baseados em árvores, modelos baseados em vizinhos, redes neurais, máquinas de vetores de suporte, Naive Bayes e ensembles do tipo Superlearner.[@andaurnavarro2023]

<br>

```{r logistica-vs-arvore, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Comparação entre modelos de regressão logística e árvore de decisão."}
# Reprodutibilidade
set.seed(42)

# Dados sintéticos
x1 <- rnorm(200)
x2 <- rnorm(200)
y <- ifelse(x1^2 + x2^2 > 1, 1, 0)
df <- data.frame(x1, x2, y = factor(y))

# Ajustar modelos
glm_mod <- glm(y ~ x1 + x2, data=df, family=binomial)
tree_mod <- rpart::rpart(y ~ x1 + x2, data=df)

# Grade para visualizar
grid <- expand.grid(
  x1 = seq(min(x1)-1, max(x1)+1, length=200),
  x2 = seq(min(x2)-1, max(x2)+1, length=200)
)

grid$glm_pred <- predict(glm_mod, newdata=grid, type="response") > 0.5
grid$tree_pred <- predict(tree_mod, newdata=grid, type="class")

# Plot lado a lado
p1 <- ggplot2::ggplot() +
  ggplot2::geom_tile(data=grid, ggplot2::aes(x1, x2, fill=glm_pred), alpha=0.3) +
  ggplot2::geom_point(data=df, ggplot2::aes(x1, x2, color=y)) +
  ggplot2::labs(title="Logística (linear)") + ggplot2::theme_minimal()

p2 <- ggplot2::ggplot() +
  ggplot2::geom_tile(data=grid, ggplot2::aes(x1, x2, fill=tree_pred), alpha=0.3) +
  ggplot2::geom_point(data=df, ggplot2::aes(x1, x2, color=y)) +
  ggplot2::labs(title="Árvore (não linear)") + ggplot2::theme_minimal()

gridExtra::grid.arrange(p1, p2, ncol=2)
```

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *h2o*[\@correctR](https://cran.r-project.org/web/packages/h2o/index.html) fornece funções construir modelos de aprendizado de máquina.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *correctR*[@correctR] fornece as funções [*kfold_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf), [*repkfold_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf) e [*resampled_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf) para calcular estatística para comparação de modelos de aprendizado de máquina em amostras dependentes.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *caret*[\@caret](https://cran.r-project.org/web/packages/caret/index.html) fornece um conjunto de funções para pré-processamento, ajuste, avaliação e comparação de modelos de aprendizado de máquina.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *mlr3*[\@mlr3](https://cran.r-project.org/web/packages/mlr3/index.html) fornece funções para fluxos de trabalho complexos, incluindo pré-processamento, ajuste de hiperparâmetros e integração com diversos algoritmos.
:::

<br>

## Desbalanceamento de classes

<br>

### O que é desbalanceamento de classes (*class imbalance*)?

-   Ocorre quando as classes do desfecho (por exemplo, presença vs. ausência de um evento) não estão igualmente representadas nos dados de treinamento.[@REF]

<br>

### Por que o desbalanceamento é um problema?

-   Modelos podem aprender a priorizar a classe mais frequente, obtendo alta acurácia global, mas baixo desempenho para a classe minoritária.[@REF]

-   Isso pode comprometer métricas como sensibilidade, especificidade e, em alguns casos, a calibração.[@REF]

<br>

### Quais são as abordagens mais comuns para lidar com desbalanceamento de classes?

-   Reamostragem aleatória: superamostragem da classe minoritária; subamostragem da classe majoritária).[@REF]

-   Ajuste de pesos: penaliza mais os erros na classe menos frequente.[@REF]

-   Alteração do limiar de decisão: muda o ponto de corte de probabilidade para otimizar métricas específicas.[@REF]

<br>

### Qual é o impacto do desbalanceamento de classes na calibração de modelos?

-   Corrigir o desbalanceamento de classes nem sempre melhora a calibração e, em alguns casos, pode piorá-la.[@carriero2025]

-   Em simulações computacionais, modelos sem correção tiveram calibração igual ou superior aos corrigidos.[@carriero2025]

-   A piora observada foi caracterizada por superestimação do risco, nem sempre reversível com re-calibração.[@carriero2025]

<br>

```{r, echo=FALSE, warning=FALSE, results='asis', eval=knitr::is_html_output()}
cat(readLines("citation.html"), sep = "\n")
```

<br>
