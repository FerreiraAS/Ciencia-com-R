# **Aprendizado de máquina** {#aprendizado-maquina}

<br>

## Aprendizado de máquina

<br>

### O que é aprendizado de máquina?

-   .[@REF]

<br>

## Tipos de aprendizado

<br>

### O que é aprendizado supervisionado?

-   .[@REF]

<br>

### O que é aprendizado não supervisionado?

-   .[@REF]

<br>

### O que é aprendizado semi-supervisionado?

-   .[@REF]

<br>

### O que é aprendizado por reforço?

-   .[@REF]

<br>

### O que é aprendizado profundo?

-   .[@REF]

<br>

### Quais são os limites do progresso em classificadores supervisionados?

-   Os maiores ganhos de acurácia vêm de modelos simples, como análise discriminante linear; métodos mais sofisticados oferecem apenas ganhos marginais.[@hand2006]

-   O aumento da complexidade do modelo traz retornos decrescentes em termos de redução da taxa de erro.[@hand2006]

<br>

### Quais problemas práticos limitam a generalização de classificadores?

- *Population drift*: mudanças na distribuição dos dados ao longo do tempo degradam a performance de modelos.[@hand2006]

- *Sample selectivity bias*: amostras de treino podem não representar a população futura, levando a superestimação de desempenho.[@hand2006]

- Erros de rótulo e definições arbitrárias de classes comprometem a validade dos modelos.[@hand2006]

<br>

### Por que estudos comparativos entre classificadores podem ser enganosos?

- Resultados dependem da experiência do pesquisador com cada método, da escolha dos conjuntos de dados e do critério de avaliação usado.[@hand2006]

- Diferenças pequenas em acurácia frequentemente desaparecem quando se consideram incertezas reais de aplicação.[@hand2006]

<Br>

## Principais algoritmos

<br>

### Quais são os principais algoritmos de aprendizado de máquina?

-   Modelos de regressão não penalizados, modelos de regressão penalizados, modelos baseados em árvores, modelos baseados em vizinhos, redes neurais, máquinas de vetores de suporte, Naive Bayes e ensembles do tipo Superlearner.[@andaurnavarro2023]

<br>

## Regressão logística

<br>

### O que são é regressão logística?

- .[@REF]

<br>

## Máquina de vetores de suporte

<br>

### O que são máquinas de vetores de suporte?

- .[@REF]

<br>

## *K-nearest neighbours*

<br>

### O que é *K-nearest neighbours*?

- .[@REF]

<br>

## *K-means Clustering*

<br>

### O que é *K-means clustering*?

- .[@REF]

<br>

## Árvores de decisão

<br>

### O que são árvores de decisão?

-   São modelos de aprendizado supervisionado que dividem os dados em ramos e folhas, representando regras de decisão de forma hierárquica.[@hozo2023]

-   Podem lidar eficientemente com grandes conjuntos de dados sem pressupor estrutura paramétrica complexa.[@Song2015]

-   São aplicáveis a variáveis contínuas e discretas, tanto como preditoras quanto como desfechos.[@Song2015]

<br>

```{r arvore-decisao, echo=FALSE, warning=FALSE, message=FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Exemplo de árvore de decisão para predizer depressão a partir de idade, tabagismo e sintomas."}
# Dados simulados
set.seed(123)

# Gerar dados
n <- 200
df <- data.frame(
  idade = sample(20:70, n, replace=TRUE),
  tabagismo = sample(c("Sim", "Não"), n, replace=TRUE, prob=c(0.3,0.7)),
  sintomas = sample(0:3, n, replace=TRUE),
  depressao = sample(c("Sim","Não"), n, replace=TRUE, prob=c(0.4,0.6))
)

# Ajuste de árvore de decisão
mod <- rpart::rpart(depressao ~ idade + tabagismo + sintomas, data=df, method="class")

# Visualização
rpart.plot::rpart.plot(mod, type=3, extra=104, fallen.leaves=TRUE)
```

<br>

### Quais são os principais usos de árvores de decisão?

-   Seleção de variáveis relevantes em cenários com muitos preditores, como registros clínicos eletrônicos.[@Song2015]

-   Avaliação da importância relativa das variáveis, com base na redução da pureza dos nós ou da acurácia ao remover variáveis.[@Song2015]

-   Tratamento de valores ausentes, seja classificando-os como categoria própria ou imputando-os por previsão dentro da árvore.[@Song2015]

-   Predição de novos casos a partir de dados históricos.[@Song2015]

-   Manipulação de dados, colapsando categorias muito numerosas ou subdividindo variáveis contínuas assimétricas.[@Song2015]

<br>

### Quais são os componentes básicos de uma árvore de decisão?

-   Nós raiz (ou de decisão): subdividem todos os registros iniciais.[@Song2015]

-   Nós internos (ou de chance): representam subdivisões intermediárias.[@Song2015]

-   Nós folha (ou finais): resultados finais após sucessivas divisões.[@Song2015]

-   Ramos: representam condições “se-então”, ligando nós em sequência até a classificação final.[@Song2015]

<br>

### Como funcionam splitting, stopping e pruning?

-   *Splitting*: divide registros em subconjuntos mais homogêneos com base em métricas como entropia, índice de Gini e ganho de informação.[@Song2015]

-   *Stopping*: evita árvores excessivamente complexas ao definir parâmetros como número mínimo de registros por nó ou profundidade máxima.[@Song2015]

-   *Pruning*: reduz árvores grandes eliminando ramos pouco informativos, usando validação ou métodos como qui-quadrado.[@Song2015]

<br>

### Quais são as vantagens e limitações de árvores de decisão?

-   Vantagens: simplificam relações complexas; são intuitivas e fáceis de interpretar; não exigem pressupostos de distribuição; lidam bem com valores ausentes e dados enviesados; são robustas a *outliers*.[@Song2015]

-   Limitações: podem sofrer *overfitting* ou *underfitting* em amostras pequenas; podem selecionar variáveis correlacionadas sem relação causal real.[@Song2015]

<br>

### Como se comparam à regressão logística?

-   A regressão logística assume relações lineares entre variáveis e log-odds.[@hozo2023]

-   Árvores de decisão permitem capturar relações não lineares e interações de forma automática.[@hozo2023]

<br>

```{r logistica-vs-arvore, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Comparação entre modelos de regressão logística e árvore de decisão."}
# Reprodutibilidade
set.seed(42)

# Dados sintéticos
x1 <- rnorm(200)
x2 <- rnorm(200)
y <- ifelse(x1^2 + x2^2 > 1, 1, 0)
df <- data.frame(x1, x2, y = factor(y))

# Ajustar modelos
glm_mod <- glm(y ~ x1 + x2, data=df, family=binomial)
tree_mod <- rpart::rpart(y ~ x1 + x2, data=df)

# Grade para visualizar
grid <- expand.grid(
  x1 = seq(min(x1)-1, max(x1)+1, length=200),
  x2 = seq(min(x2)-1, max(x2)+1, length=200)
)

grid$glm_pred <- predict(glm_mod, newdata=grid, type="response") > 0.5
grid$tree_pred <- predict(tree_mod, newdata=grid, type="class")

# Plot lado a lado
p1 <- ggplot2::ggplot() +
  ggplot2::geom_tile(data=grid, ggplot2::aes(x1, x2, fill=glm_pred), alpha=0.3) +
  ggplot2::geom_point(data=df, ggplot2::aes(x1, x2, color=y)) +
  ggplot2::labs(title="Logística (linear)") + ggplot2::theme_minimal()

p2 <- ggplot2::ggplot() +
  ggplot2::geom_tile(data=grid, ggplot2::aes(x1, x2, fill=tree_pred), alpha=0.3) +
  ggplot2::geom_point(data=df, ggplot2::aes(x1, x2, color=y)) +
  ggplot2::labs(title="Árvore (não linear)") + ggplot2::theme_minimal()

gridExtra::grid.arrange(p1, p2, ncol=2)
```

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *h2o*[\@correctR](https://cran.r-project.org/web/packages/h2o/index.html) fornece funções construir modelos de aprendizado de máquina.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *correctR*[@correctR] fornece as funções [*kfold_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf), [*repkfold_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf) e [*resampled_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf) para calcular estatística para comparação de modelos de aprendizado de máquina em amostras dependentes.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *caret*[\@caret](https://cran.r-project.org/web/packages/caret/index.html) fornece um conjunto de funções para pré-processamento, ajuste, avaliação e comparação de modelos de aprendizado de máquina.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *mlr3*[\@mlr3](https://cran.r-project.org/web/packages/mlr3/index.html) fornece funções para fluxos de trabalho complexos, incluindo pré-processamento, ajuste de hiperparâmetros e integração com diversos algoritmos.
:::

<br>

## Análise de componentes principais

<br>

### O que é análise de componentes principais?

- .[@REF]

<br>

## *Random forests*

<br>

### O que são *random forests*?

- .[@REF]

<br>

## *Ensemble*

<br>

### O que são *ensemble*?

- .[@REF]

<br>

## Desbalanceamento de classes

<br>

### O que é desbalanceamento de classes (*class imbalance*)?

-   Ocorre quando as classes do desfecho (por exemplo, presença vs. ausência de um evento) não estão igualmente representadas nos dados de treinamento.[@REF]

<br>

### Por que o desbalanceamento é um problema?

-   Modelos podem aprender a priorizar a classe mais frequente, obtendo alta acurácia global, mas baixo desempenho para a classe minoritária.[@REF]

-   Isso pode comprometer métricas como sensibilidade, especificidade e, em alguns casos, a calibração.[@REF]

<br>

### Quais são as abordagens mais comuns para lidar com desbalanceamento de classes?

-   Reamostragem aleatória: superamostragem da classe minoritária; subamostragem da classe majoritária).[@REF]

-   Ajuste de pesos: penaliza mais os erros na classe menos frequente.[@REF]

-   Alteração do limiar de decisão: muda o ponto de corte de probabilidade para otimizar métricas específicas.[@REF]

<br>

### Qual é o impacto do desbalanceamento de classes na calibração de modelos?

-   Corrigir o desbalanceamento de classes nem sempre melhora a calibração e, em alguns casos, pode piorá-la.[@carriero2025]

-   Em simulações computacionais, modelos sem correção tiveram calibração igual ou superior aos corrigidos.[@carriero2025]

-   A piora observada foi caracterizada por superestimação do risco, nem sempre reversível com re-calibração.[@carriero2025]

<br>

```{r, echo=FALSE, warning=FALSE, results='asis', eval=knitr::is_html_output()}
cat(readLines("citation.html"), sep = "\n")
```

<br>
