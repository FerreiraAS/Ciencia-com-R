```{=openxml}
<w:p>
  <w:r>
    <w:br w:type="page"/>
  </w:r>
</w:p>
```

# **Aprendizado de máquina** {#aprendizado-maquina}

<br>

## Aprendizado de máquina

<br>

### O que é aprendizado de máquina?

-   .[@REF]

<br>

```{r aprendizado-maquina, include = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Mapa mental de algoritmos de aprendizado de máquina.", out.width = "100%"}

col_root  <- "#E57E25"   # laranja (Aprendizado de Máquina)
col_sup   <- "#CFE9CF"   # verde claro (Supervisionado)
col_uns   <- "#FFD778"   # amarelo (Não Supervisionado)
col_semi  <- "#CFCFD3"   # cinza (Semi-supervisionado)
col_reinf <- "#B9CDF3"   # azul claro (Reforço)
col_text_dark <- "#333333"

dot <- sprintf('
digraph ml {
  graph [
    rankdir=LR
    bgcolor="white"
    nodesep=0.45
    ranksep=0.55
  ]

  node [shape=box style="rounded,filled" fontname="Helvetica" fontsize=11 color="#666666" fontcolor="%1$s"]
  edge [color="#888888" arrowsize=0.6 penwidth=1.1]

  # Raiz
  ML  [label="Aprendizado de Máquina", fillcolor="%2$s", fontcolor="white", penwidth=1.2]

  # Primeira camada
  SUP [label="Supervisionado",         fillcolor="%3$s"]
  UNS [label="Não Supervisionado",     fillcolor="%4$s"]
  SEMI[label="Semi-Supervisionado",    fillcolor="%5$s"]
  REIN[label="Aprendizado por Reforço",fillcolor="%6$s"]

  ML -> {SUP UNS SEMI REIN}

  # ---------------- Supervisionado ----------------
  CLC [label="Classificação", fillcolor="%3$s"]
  RGR [label="Regressão",     fillcolor="%3$s"]
  SUP -> {CLC RGR}

  NB   [label="Naïve Bayes",                               fillcolor="%3$s"]
  LR   [label="Regressão Logística",                       fillcolor="%3$s"]
  KNN  [label="K-Vizinhos Mais Próximos (KNN)",            fillcolor="%3$s"]
  RF   [label="Floresta Aleatória",                        fillcolor="%3$s"]
  SVM  [label="Máquina de Vetores de Suporte (SVM)",       fillcolor="%3$s"]
  DT   [label="Árvore de Decisão",                         fillcolor="%3$s"]
  CLC -> {NB LR KNN RF SVM DT}

  SLR  [label="Regressão Linear Simples",  fillcolor="%3$s"]
  MLR  [label="Regressão Multivariada",    fillcolor="%3$s"]
  LASSO[label="Regressão Lasso",           fillcolor="%3$s"]
  RGR -> {SLR MLR LASSO}

  # ---------------- Não Supervisionado ----------------
  CLU [label="Agrupamento (Clustering)", fillcolor="%4$s"]
  ASC [label="Associação",               fillcolor="%4$s"]
  ANO [label="Detecção de Anomalias",    fillcolor="%4$s"]
  UNS -> {CLU ASC ANO}

  KMEANS [label="K-Means (K-médias)",                                   fillcolor="%4$s"]
  DBSCAN [label="DBSCAN",                                                fillcolor="%4$s"]
  PCA    [label="Análise de Componentes Principais (PCA)",               fillcolor="%4$s"]
  ICA    [label="Análise de Componentes Independentes (ICA)",            fillcolor="%4$s"]
  CLU -> {KMEANS DBSCAN PCA ICA}

  FPG   [label="Crescimento de Padrões Frequentes (FP-Growth)", fillcolor="%4$s"]
  APR   [label="Algoritmo Apriori",                              fillcolor="%4$s"]
  ASC -> {FPG APR}

  ZS    [label="Z-score",                        fillcolor="%4$s"]
  IFOR  [label="Floresta de Isolamento",         fillcolor="%4$s"]
  ANO -> {ZS IFOR}

  # ---------------- Semi-Supervisionado ----------------
  SS_C [label="Classificação", fillcolor="%5$s"]
  SS_R [label="Regressão",     fillcolor="%5$s"]
  SEMI -> {SS_C SS_R}

  ST    [label="Auto-Treinamento (Self-Training)", fillcolor="%5$s"]
  COT   [label="Co-Treinamento (Co-Training)",     fillcolor="%5$s"]
  SS_C -> ST
  SS_R -> COT

  # ---------------- Reforço ----------------
  MF   [label="Sem Modelo (Model-Free)",     fillcolor="%6$s"]
  MB   [label="Baseado em Modelo (Model-Based)", fillcolor="%6$s"]
  REIN -> {MF MB}

  PO   [label="Otimização de Política", fillcolor="%6$s"]
  QL   [label="Q-Learning",            fillcolor="%6$s"]
  MF -> {PO QL}

  LTM  [label="Aprender o Modelo",  fillcolor="%6$s"]
  GTM  [label="Dado o Modelo",      fillcolor="%6$s"]
  MB -> {LTM GTM}

  {rank=same; SUP; UNS; SEMI; REIN}
  {rank=same; CLC; RGR; CLU; ASC; ANO; SS_C; SS_R; MF; MB}
}
', col_text_dark, col_root, col_sup, col_uns, col_semi, col_reinf)

g <- DiagrammeR::grViz(dot)

# Exporta para SVG
svg <- DiagrammeRsvg::export_svg(g)

# Converte SVG em PNG (ou PDF se quiser)
rsvg::rsvg_png(charToRaw(svg), file = "images/aprendizado-maquina.png", width = 1200, height = 1000)

# Exibe a imagem
knitr::include_graphics("images/aprendizado-maquina.png")
```

<br>

## Tipos de aprendizado

<br>

### O que é aprendizado supervisionado?

-   .[@REF]

<br>

### O que é aprendizado não supervisionado?

-   .[@REF]

<br>

### O que é aprendizado semi-supervisionado?

-   .[@REF]

<br>

### O que é aprendizado por reforço?

-   .[@REF]

<br>

### O que é aprendizado profundo?

-   .[@REF]

<br>

### Quais são os limites do progresso em classificadores supervisionados?

-   Os maiores ganhos de acurácia vêm de modelos simples, como análise discriminante linear; métodos mais sofisticados oferecem apenas ganhos marginais.[@hand2006]

-   O aumento da complexidade do modelo traz retornos decrescentes em termos de redução da taxa de erro.[@hand2006]

<br>

### Quais problemas práticos limitam a generalização de classificadores?

- *Population drift*: mudanças na distribuição dos dados ao longo do tempo degradam a performance de modelos.[@hand2006]

- *Sample selectivity bias*: amostras de treino podem não representar a população futura, levando a superestimação de desempenho.[@hand2006]

- Erros de rótulo e definições arbitrárias de classes comprometem a validade dos modelos.[@hand2006]

<br>

### Por que estudos comparativos entre classificadores podem ser enganosos?

- Resultados dependem da experiência do pesquisador com cada método, da escolha dos conjuntos de dados e do critério de avaliação usado.[@hand2006]

- Diferenças pequenas em acurácia frequentemente desaparecem quando se consideram incertezas reais de aplicação.[@hand2006]

<Br>

## Principais algoritmos

<br>

### Quais são os principais algoritmos de aprendizado de máquina?

-   Modelos de regressão não penalizados, modelos de regressão penalizados, modelos baseados em árvores, modelos baseados em vizinhos, redes neurais, máquinas de vetores de suporte, Naive Bayes e ensembles do tipo Superlearner.[@andaurnavarro2023]

- Do ponto de vista matemático, redes neurais não contradizem a estatística clássica; elas a estendem, substituindo modelos explícitos por representações aprendidas.[@REF]

<br>

```{r rede-neural-vs-regressao, echo=FALSE, warning=FALSE, message=FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Equivalência conceitual entre modelos de regressão e redes neurais artificiais."}
library(dplyr)

tabela_equivalencia <- data.frame(
  `Modelos de regressão` = c(
    "Variável preditora (x)",
    "Coeficiente (β)",
    "Intercepto (β₀)",
    "Combinação linear (β₀ + Σ βᵢxᵢ)",
    "Função de ligação (link)",
    "Regressão linear",
    "Regressão logística",
    "Log-odds",
    "Predição (ŷ)",
    "Função de perda",
    "Máxima verossimilhança",
    "Gradiente da verossimilhança",
    "Regularização (L1, L2)",
    "Interações explícitas",
    "Modelo interpretável"
  ),
  `Redes neurais artificiais` = c(
    "Neurônio de entrada",
    "Peso (w)",
    "Viés (b)",
    "Soma ponderada (Σ wᵢxᵢ + b)",
    "Função de ativação",
    "Neurônio linear",
    "Perceptron com ativação sigmoide",
    "Entrada da função sigmoide",
    "Saída do neurônio",
    "Função de perda (loss)",
    "Otimização da função de perda",
    "Retropropagação (backpropagation)",
    "Penalização de pesos (weight decay)",
    "Interações aprendidas implicitamente",
    "Modelo geralmente opaco"
  ),
  `Papel conceitual` = c(
    "Informação observada fornecida ao modelo",
    "Intensidade e direção da influência da variável",
    "Deslocamento da fronteira de decisão",
    "Agregação das entradas antes da não linearidade",
    "Introdução de não linearidade",
    "Modelo puramente linear",
    "Classificação binária probabilística",
    "Escala interna antes da probabilidade",
    "Resposta estimada do modelo",
    "Quantificação do erro de predição",
    "Ajuste dos parâmetros do modelo",
    "Direção de atualização dos parâmetros",
    "Controle de complexidade e overfitting",
    "Modelagem de efeitos combinados",
    "Trade-off entre interpretação e flexibilidade"
  )
)

# renomear colunas
colnames(tabela_equivalencia) <- c(
  "Modelos de regressão",
  "Redes neurais artificiais",
  "Papel conceitual"
  )

knitr::kable(
  tabela_equivalencia,
  align = c("l"),
  format = ifelse(knitr::is_html_output(), "html", "latex"),
  booktabs = TRUE,
  linesep = "",
  escape = FALSE
)  %>%
  kableExtra::kable_styling(
    latex_options = c("basic"),
    bootstrap_options = c("basic", "hover", "condensed", "responsive"),
    full_width = ifelse(knitr::is_html_output(), TRUE, TRUE),
    position = "center"
  ) %>%
  kableExtra::row_spec(0,
                       bold = TRUE,
                       extra_css = "border-top: 1px solid; border-bottom: 1px solid") %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::row_spec(dim(tabela_equivalencia)[1],
                       extra_css = "border-bottom: 1px solid")
```

<br>

## Regressão logística

<br>

### O que são é regressão logística?

- .[@REF]

<br>

## Máquina de vetores de suporte

<br>

### O que são máquinas de vetores de suporte?

- .[@REF]

<br>

## *K-nearest neighbours*

<br>

### O que é *K-nearest neighbours*?

- .[@REF]

<br>

## *K-means Clustering*

<br>

### O que é *K-means clustering*?

- .[@REF]

<br>

## Árvores de decisão

<br>

### O que são árvores de decisão?

-   São modelos de aprendizado supervisionado que dividem os dados em ramos e folhas, representando regras de decisão de forma hierárquica.[@hozo2023]

-   Podem lidar eficientemente com grandes conjuntos de dados sem pressupor estrutura paramétrica complexa.[@Song2015]

-   São aplicáveis a variáveis contínuas e discretas, tanto como preditoras quanto como desfechos.[@Song2015]

<br>

```{r arvore-decisao, echo=FALSE, warning=FALSE, message=FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Exemplo de árvore de decisão para predizer depressão a partir de idade, tabagismo e sintomas."}
# Dados simulados
set.seed(123)

# Gerar dados
n <- 200
df <- data.frame(
  idade = sample(20:70, n, replace=TRUE),
  tabagismo = sample(c("Sim", "Não"), n, replace=TRUE, prob=c(0.3,0.7)),
  sintomas = sample(0:3, n, replace=TRUE),
  depressao = sample(c("Sim","Não"), n, replace=TRUE, prob=c(0.4,0.6))
)

# Ajuste de árvore de decisão
mod <- rpart::rpart(depressao ~ idade + tabagismo + sintomas, data=df, method="class")

# Visualização
rpart.plot::rpart.plot(mod, type=3, extra=104, fallen.leaves=TRUE)
```

<br>

### Quais são os principais usos de árvores de decisão?

-   Seleção de variáveis relevantes em cenários com muitos preditores, como registros clínicos eletrônicos.[@Song2015]

-   Avaliação da importância relativa das variáveis, com base na redução da pureza dos nós ou da acurácia ao remover variáveis.[@Song2015]

-   Tratamento de valores ausentes, seja classificando-os como categoria própria ou imputando-os por previsão dentro da árvore.[@Song2015]

-   Predição de novos casos a partir de dados históricos.[@Song2015]

-   Manipulação de dados, colapsando categorias muito numerosas ou subdividindo variáveis contínuas assimétricas.[@Song2015]

<br>

### Quais são os componentes básicos de uma árvore de decisão?

-   Nós raiz (ou de decisão): subdividem todos os registros iniciais.[@Song2015]

-   Nós internos (ou de chance): representam subdivisões intermediárias.[@Song2015]

-   Nós folha (ou finais): resultados finais após sucessivas divisões.[@Song2015]

-   Ramos: representam condições “se-então”, ligando nós em sequência até a classificação final.[@Song2015]

<br>

### Como funcionam splitting, stopping e pruning?

-   *Splitting*: divide registros em subconjuntos mais homogêneos com base em métricas como entropia, índice de Gini e ganho de informação.[@Song2015]

-   *Stopping*: evita árvores excessivamente complexas ao definir parâmetros como número mínimo de registros por nó ou profundidade máxima.[@Song2015]

-   *Pruning*: reduz árvores grandes eliminando ramos pouco informativos, usando validação ou métodos como qui-quadrado.[@Song2015]

<br>

### Quais são as vantagens e limitações de árvores de decisão?

-   Vantagens: simplificam relações complexas; são intuitivas e fáceis de interpretar; não exigem pressupostos de distribuição; lidam bem com valores ausentes e dados enviesados; são robustas a *outliers*.[@Song2015]

-   Limitações: podem sofrer *overfitting* ou *underfitting* em amostras pequenas; podem selecionar variáveis correlacionadas sem relação causal real.[@Song2015]

<br>

### Espaço de decisão em árvores de decisão vs. regressão logística

-   A regressão logística assume relações lineares entre variáveis e log-odds.[@hozo2023]

-   Árvores de decisão permitem capturar relações não lineares e interações de forma automática.[@hozo2023]

<br>

```{r logistica-vs-arvore, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Comparação entre modelos de regressão logística e árvore de decisão."}
# Reprodutibilidade
set.seed(42)

# Dados sintéticos
x1 <- rnorm(200)
x2 <- rnorm(200)
y <- ifelse(x1^2 + x2^2 > 1, 1, 0)
df <- data.frame(x1, x2, y = factor(y))

# Ajustar modelos
glm_mod <- glm(y ~ x1 + x2, data=df, family=binomial)
tree_mod <- rpart::rpart(y ~ x1 + x2, data=df)

# Grade para visualizar
grid <- expand.grid(
  x1 = seq(min(x1)-1, max(x1)+1, length=200),
  x2 = seq(min(x2)-1, max(x2)+1, length=200)
)

grid$glm_pred <- predict(glm_mod, newdata=grid, type="response") > 0.5
grid$tree_pred <- predict(tree_mod, newdata=grid, type="class")

# Plot lado a lado
p1 <- ggplot2::ggplot() +
  ggplot2::geom_tile(data=grid, ggplot2::aes(x1, x2, fill=glm_pred), alpha=0.3) +
  ggplot2::geom_point(data=df, ggplot2::aes(x1, x2, color=y)) +
  ggplot2::labs(title="Logística (linear)") + ggplot2::theme_minimal()

p2 <- ggplot2::ggplot() +
  ggplot2::geom_tile(data=grid, ggplot2::aes(x1, x2, fill=tree_pred), alpha=0.3) +
  ggplot2::geom_point(data=df, ggplot2::aes(x1, x2, color=y)) +
  ggplot2::labs(title="Árvore (não linear)") + ggplot2::theme_minimal()

gridExtra::grid.arrange(p1, p2, ncol=2)
```

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *h2o*[\@correctR](https://cran.r-project.org/web/packages/h2o/index.html) fornece funções construir modelos de aprendizado de máquina.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *correctR*[@correctR] fornece as funções [*kfold_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf), [*repkfold_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf) e [*resampled_ttest*](https://cloud.r-project.org/web/packages/correctR/correctR.pdf) para calcular estatística para comparação de modelos de aprendizado de máquina em amostras dependentes.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *caret*[\@caret](https://cran.r-project.org/web/packages/caret/index.html) fornece um conjunto de funções para pré-processamento, ajuste, avaliação e comparação de modelos de aprendizado de máquina.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *mlr3*[\@mlr3](https://cran.r-project.org/web/packages/mlr3/index.html) fornece funções para fluxos de trabalho complexos, incluindo pré-processamento, ajuste de hiperparâmetros e integração com diversos algoritmos.
:::

<br>

## Análise de componentes principais

<br>

### O que é análise de componentes principais?

- .[@REF]

<br>

## *Random forests*

<br>

### O que são *random forests*?

- .[@REF]

<br>

## *Ensemble*

<br>

### O que são *ensemble*?

- .[@REF]

<br>

## Desbalanceamento de classes

<br>

### O que é desbalanceamento de classes (*class imbalance*)?

-   Ocorre quando as classes do desfecho (por exemplo, presença vs. ausência de um evento) não estão igualmente representadas nos dados de treinamento.[@REF]

<br>

### Por que o desbalanceamento é um problema?

-   Modelos podem aprender a priorizar a classe mais frequente, obtendo alta acurácia global, mas baixo desempenho para a classe minoritária.[@REF]

-   Isso pode comprometer métricas como sensibilidade, especificidade e, em alguns casos, a calibração.[@REF]

<br>

### Quais são as abordagens mais comuns para lidar com desbalanceamento de classes?

-   Reamostragem aleatória: superamostragem da classe minoritária; subamostragem da classe majoritária).[@REF]

-   Ajuste de pesos: penaliza mais os erros na classe menos frequente.[@REF]

-   Alteração do limiar de decisão: muda o ponto de corte de probabilidade para otimizar métricas específicas.[@REF]

<br>

### Qual é o impacto do desbalanceamento de classes na calibração de modelos?

-   Corrigir o desbalanceamento de classes nem sempre melhora a calibração e, em alguns casos, pode piorá-la.[@carriero2025]

-   Em simulações computacionais, modelos sem correção tiveram calibração igual ou superior aos corrigidos.[@carriero2025]

-   A piora observada foi caracterizada por superestimação do risco, nem sempre reversível com re-calibração.[@carriero2025]

<br>

```{r, echo=FALSE, warning=FALSE, results='asis', eval=knitr::is_html_output()}
cat(readLines("citation.html"), sep = "\n")
```

<br>
