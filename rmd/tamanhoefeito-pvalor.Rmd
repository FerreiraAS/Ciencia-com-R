```{=openxml}
<w:p>
  <w:r>
    <w:br w:type="page"/>
  </w:r>
</w:p>
```

# **Tamanho do efeito e P-valor** {#tamanhoefeito-pvalor}

<br>

## Tamanho do efeito

<br>

### O que é o tamanho do efeito?

-   Tamanho do efeito quantifica a magnitude de um efeito real da análise, expressando uma importância descritiva dos resultados.[@Kim2015]

<br>

## Tipos de tamanho do efeito

-   Diferenças padronizadas entre grupos:[@Sullivan2012; @Kim2015]

    -   Cohen's $d$

    -   Glass's $\Delta$

    -   Razão de chances ($RC$ ou $OR$)

    -   Risco relativo ou razão de risco ($RR$)

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *epitools*[@epitools] fornece a função [*oddsratio.wald*](https://www.rdocumentation.org/packages/epitools/versions/0.09/topics/odds.ratio) para calcular a razão de chances.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *epitools*[@epitools] fornece a função [*riskratio.wald*](https://www.rdocumentation.org/packages/epitools/versions/0.09/topics/riskratio.wald) para calcular a razão de risco.
:::

<br>

-   Medidas de associação:[@Sullivan2012; @Kim2015]

    -   Coeficiente de correlação de Pearson ($r$), ponto-bisserial ($r_{s}$), Spearman ($\rho$), Kendall ($\tau$), Cramér ($V$) e $\phi$.

    -   Coeficiente de determinação ($R^2$)

<br>

### Como interpretar um tamanho do efeito?

-   Tamanhos de efeito podem ser comparadores entre diferentes estudos.[@Sullivan2012]

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *effectsize*[@effectsize] fornece a função [*rules*](https://www.rdocumentation.org/packages/effectsize/versions/0.8.3/topics/rules) para criar regras de interpretação de tamanhos de efeito.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *effectsize*[@effectsize] fornece a função [*interpret*](https://www.rdocumentation.org/packages/effectsize/versions/0.8.3/topics/interpret) para interpretar os tamanhos de efeito com base em uma lista de regras pré-definidas.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *pwr*[@pwr] fornece a função [*cohen.ES*](https://www.rdocumentation.org/packages/pwr/versions/1.3-0/topics/cohen.ES) para obter os tamanhos de efeito "pequeno", "médio" e "grande" para diversos testes de hipóteses.
:::

<br>

### O que é a diferença de média bruta?

- A diferença de média bruta representa a diferença absoluta entre as médias de dois grupos, expressa na unidade original da variável.[@REF]

- Trata-se de uma medida não padronizada, sendo particularmente útil quando a escala possui interpretação clínica ou substantiva direta (por exemplo, mmHg, pontos de escore).[@REF]

- Por depender da unidade de medida, não permite comparações diretas entre estudos com métricas diferentes.[@REF]

<br>

### Correlações podem ser consideradas tamanhos de efeito?

- Sim. Coeficientes de correlação podem ser interpretados diretamente como tamanhos de efeito, pois expressam a força e a direção da associação entre variáveis.[@REF]

- O coeficiente de Spearman ($\rho$) mede associações monotônicas e é robusto a violações de normalidade.[@REF]

- Kendall ($\tau$) é especialmente indicado para amostras pequenas ou dados com empates.[@REF]

- Esses coeficientes são frequentemente utilizados como tamanhos de efeito em testes não paramétricos.[@REF]

<br>

### O que é o $q$ de Cohen?

- O tamanho de efeito $q$ quantifica a diferença entre dois coeficientes de correlação, após transformação de Fisher ($z$).[@REF]

- É utilizado principalmente para comparar associações observadas em grupos independentes.[@REF]

- Cohen propôs valores de referência para interpretação (pequeno, médio e grande), reforçando seu caráter descritivo.[@REF]

<br>

### O que o $g$ no teste do sinal?

- O coeficiente $g$ é utilizado como tamanho de efeito no teste do sinal.[@REF]

- Representa a diferença padronizada entre a proporção de observações positivas e negativas.[@REF]

- Aplica-se a delineamentos pareados em que apenas a direção do efeito é considerada.[@REF]

- É uma medida robusta, porém menos informativa do que medidas baseadas em magnitude contínua.[@REF]

<br>

### O que é o $h$ de Cohen?

- O tamanho de efeito $h$ mede a diferença entre duas proporções, após transformação angular para estabilizar a variância.[@REF]

- É indicado para comparações entre desfechos binários.[@REF]

- Por ser padronizado, permite comparações entre estudos com diferentes proporções absolutas.[@REF]

<br>

### O que representa o tamanho de efeito $w$?

- O coeficiente $w$ é utilizado como tamanho de efeito em testes do qui-quadrado, tanto de aderência quanto de independência.[@REF]

- Quantifica o grau global de discrepância entre frequências observadas e esperadas.[@REF]

- Sua interpretação depende do número de categorias e do tamanho da amostra, devendo ser feita com cautela.[@REF]

<br>

### O que é o tamanho de efeito $f$ em ANOVA?

- O coeficiente $f$ é utilizado como tamanho de efeito em análises de variância (ANOVA).[@REF]

- Está relacionado à proporção da variância explicada pelo fator em relação à variância residual.[@REF]

- É amplamente empregado em cálculos de poder estatístico e no planejamento amostral.[@REF]

<br>

### O que é o tamanho de efeito $f^2$ em regressão?

- O coeficiente $f^2$ mede o impacto incremental de um conjunto de preditores em modelos de regressão.[@REF]

- É definido como a razão entre a variância explicada adicional e a variância não explicada.[@REF]

- É particularmente útil para avaliar contribuições locais em modelos hierárquicos ou multivariados.[@REF]

<br>

### O que é a estatística $\Lambda$ de Wilks na MANOVA?

- O Lambda de Wilks ($\Lambda$) é utilizado como estatística global em análises multivariadas de variância (MANOVA).[@REF]

- Representa a proporção da variância multivariada não explicada pelo modelo.[@REF]

- Embora menos intuitivo como medida de magnitude, é amplamente utilizado e pode ser convertido em outras estatísticas.[@REF]

<br>

### Como escolher o tamanho de efeito adequado?

- Não existe um tamanho de efeito universalmente superior; a escolha depende da pergunta científica, do delineamento, do tipo de variável e do modelo estatístico.[@REF]

- A boa prática estatística recomenda reportar estimativa pontual, intervalo de confiança e tamanho de efeito, evitando decisões baseadas exclusivamente em significância estatística.[@REF]

- Sempre que possível, a interpretação deve considerar relevância prática, contexto científico e incerteza associada.[@REF]

<br>

## Conversão entre tamanhos do efeito

<br>

### Como converter um tamanho de efeito em outro?

-   .[@Kim2015]

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *effectsize*[@effectsize] fornece diversas funções para conversão de diferentes estimativas de tamanhos de efeito.
:::

<br>

## Efeitos bruto e padronizado

<br>

### O que é efeito bruto?

-   .[@greenland1986]

-   .[@greenland1991]

<br>

### O que é efeito padronizado?

-   .[@greenland1986]

-   .[@greenland1991]

<br>

## P-valor

<br>

### O que é significância estatística?

-   A expressão "significância estatística"[@latter1902] ou "evidência estatística de significância" sugere apenas que um experimento merece ser repetido, uma vez que um baixo P-valor (calculado a partir dos dados, modelos e demais suposições do estudo) sugere ser improvável que os dados coletados sejam coletados no contexto de que a hipótese nula ($H_{0}$) assumida é verdadeira.[@aylmerfisher1926]

<br>

### Como justificar o nível de significância estatística de um teste?

-   .[@REF]

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *Superpower*[@Superpower] fornece a função [*optimal_alpha*](https://www.rdocumentation.org/packages/Superpower/versions/0.2.0/topics/optimal_alpha) para calcular e justificar o nível de significância $\alpha$ por balanço dos erros tipo I e II.
:::

<br>

::: {.infobox .Rlogo data-latex="{images/Rlogo}"}
O pacote *Superpower*[@Superpower] fornece a função [*ANOVA_compromise*](https://www.rdocumentation.org/packages/Superpower/versions/0.2.0/topics/ANOVA_compromise) para calcular e justificar o nível de significância $\alpha$ por balanço dos erros tipo I e II em análise de variância (ANOVA).
:::

<br>

### O que é o P-valor?

-   P-valor é a probabilidade, assumindo-se um dado modelo estatístico, de que um efeito calculado a partir dos dados seria igual ou mais extremo do que o seu valor observado.[@wasserstein2016]

-   P-valor é uma variável aleatória que possui distribuição uniforme quando a hipótese nula ($H_{0}$) é verdadeira.[@altman2017]

<br>

### Como interpretar o P-valor?

-   P-valores abaixo de um nível de significância estatística pré-especificado representam que um experimento merece ser repetido, com a rejeição da hipótese nula ($H_{0}$) justificada apenas quando experimentos adicionais frequentemente reportem igualmente resultados positivos (rejeição da hipótese nula ($H_{0}$).[@goodman2016]

-   P-valor resulta da coleta e análise de dados, e assim quantifica a plausibilidade dos dados observados sob a hipótese nula ($H_{0}$).[@heinze2016]

-   P-valores podem indicar quantitativamente a incompatibilidade entre os dados obtidos e o modelo estatístico especificado a priori (geralmente constituído pela hipótese nula ($H_{0}$).[@wasserstein2016]

-   P-valores menores/maiores do que o nível de significância estatístico pré-estabelecido não devem ser utilizados como única fonte de informação para tomada de decisão em ciência.[@wasserstein2016]

<br>

### O que o P-valor não é?

-   P-valor não representa a probabilidade de que a hipótese nula ($H_{0}$) seja verdadeira, nem a probabilidade de que os dados tenham sido produzidos pelo acaso.[@wasserstein2016]

-   P-valor não mede o tamanho do efeito ou a relevância da sua observação.[@wasserstein2016]

-   P-valor sozinho não provê informação suficiente sobre a evidência sobre um modelo teórico. A sua interpretação correta requer uma descrição ampla sobre o delineamento, métodos e análises estatísticas aplicados no estudo.[@wasserstein2016]

-   Evidência estatística de significância não provê informação sobre a magnitude do efeito observado e não necessariamente implica que o efeito é robusto.[@Landis2012; @altman2017]

<br>

### Qual a origem do 'P\<0,05'?

-   A origem do P\<0,05 remonta aos trabalhos de R. A. Fisher nas décadas de 1920 e 1930. Fisher introduziu o conceito de P-valor dentro de uma abordagem frequentista de inferência estatística.[@goodman2016]

-   O P\<0,05 foi sugerido por Ronald A. Fisher como um limiar prático para indicar que um resultado era “estatisticamente significativo”.[@goodman2016]

-   Para Ronald A. Fisher, a significância estatística não era prova definitiva, mas um sinal de que o resultado merecia investigação adicional. A rejeição da hipótese nula só deveria ocorrer após repetidas observações significativas, e não com base em um único teste.[@goodman2016]

<br>

```{r p-valores, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Visualização espacial de p < 0,05 (5 quadrados aleatórios em 100)."}
# Criar grid 10x10 (100 quadrados)
set.seed(42)  # Para reprodutibilidade
grid <- expand.grid(x = 1:10, y = 1:10)

# Criar vetor de cor com todos brancos
grid$cor <- "branco"

# Selecionar aleatoriamente 5 índices para serem cinza escuro
cinzas <- sample(1:100, 5)
grid$cor[cinzas] <- "cinza escuro"

# Criar o gráfico
ggplot2::ggplot(grid, ggplot2::aes(x = x, y = y, fill = cor)) +
  ggplot2::geom_tile(color = "black") +
  ggplot2::scale_fill_manual(values = c("cinza escuro" = "gray30", "branco" = "white")) +
  ggplot2::coord_fixed() +
  ggplot2::theme_minimal() +
  ggplot2::theme(axis.title = ggplot2::element_blank(),
        axis.text = ggplot2::element_blank(),
        axis.ticks = ggplot2::element_blank(),
        legend.position = "none")
```

<br>

### Quais são os complementos ou alternativas ao P-valor?

-   Intervalos de confiança, credibilidade ou predição.[@wasserstein2016]

-   Razão de verossimilhança.[@wasserstein2016]

-   Métodos Bayesianos, fator Bayes.[@wasserstein2016]

<br>

## P-valor de 2ª geração

<br>

### O que é o P-valor de 2ª geração?

-   O P-valor de 2ª geração (SGPV) resume a fração das hipóteses apoiadas pelos dados que também pertencem à hipótese nula intervalar (intervalo de equivalência previamente especificado). Quantifica quanto do intervalo de estimativa (p.ex., IC95%) recai dentro da zona de indiferença científica/clinicamente irrelevante.[@blume2018]

-   Essa abordagem exige declarar a hipótese nula como intervalo (e não um ponto), incorporando o que é considerado “efeito sem relevância prática” segundo o contexto científico (precisão de medida, relevância clínica etc.).[@blume2018]

<br>

### Como definir a hipótese nula intervalar e $\delta$?

-   Especifique $H_0$ como um intervalo de equivalência $[H_0^{-}, H_0^{+}]$ que contém efeitos considerados praticamente nulos. Defina $\delta$ como a meia-largura do intervalo de equivalência ($\delta = (H_0^{+} - H_0^{-})/2$).[@blume2018]

-   A escolha deve ser a priori e justificada por critérios científicos (p.ex., MCID, precisão de medida).[@blume2018]

<br>

### Como calcular o SGPV?

-   Seja $I=[a,b]$ o intervalo apoiado pelos dados (p.ex., IC 95%) e $H_0$ o intervalo nulo. O SGPV é \@ref(eq:sgpv), onde $|I|$ é a largura do intervalo de estimativa, $|H_0|$ é a largura do intervalo nulo e $|I \cap H_0|$ é a largura da sobreposição entre os dois intervalos. O SGPV é restrito ao intervalo $[0,1]$.[@blume2018]

\begin{equation}
(\#eq:sgpv)
p_{\delta} = \frac{|\,I \cap H_0\,|}{|\,I\,|} \times \max\!\left\{ \frac{|\,I\,|}{2|\,H_0\,|}, \, 1 \right\}
\end{equation}

<br>

-   Quando $|I|<2|H_0|$, $p_{\delta}$ é apenas a fração de sobreposição $|I\cap H_0|/|I|$.[@blume2018]

-   Quando $|I|>2|H_0|$, o SGPV reduz-se a $\tfrac{1}{2}\times \dfrac{|,I\cap H_0,|}{|,H_0,|}\le \tfrac{1}{2}$, sinalizando inconclusão por imprecisão.[@blume2018]

<br>

```{r sgpv, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, tab.cap = "Comparação entre p-valor (bicaudal, inferido do IC95\\%) e SGPV ($p_{\\delta}$) nos cenários simulados."}
# --- Função SGPV ---
sgpv <- function(I, H0) {
  stopifnot(length(I) == 2, length(H0) == 2, I[1] < I[2], H0[1] < H0[2])
  a <- I[1]; b <- I[2]
  hmin <- H0[1]; hmax <- H0[2]
  len_I  <- b - a
  len_H0 <- hmax - hmin
  # sobreposição
  left  <- max(a, hmin)
  right <- min(b, hmax)
  overlap <- max(0, right - left)
  prop_overlap <- if (len_I > 0) overlap / len_I else 0
  # correção para amostra pequena (|I| > 2|H0| => <= 0.5)
  small_sample_corr <- max(len_I / (2 * len_H0), 1)
  p_delta <- prop_overlap * small_sample_corr
  p_delta <- max(0, min(1, p_delta)) # restringe a [0,1]
  list(p_delta = p_delta,
       overlap = overlap,
       prop_overlap = prop_overlap,
       small_sample_corr = small_sample_corr,
       len_I = len_I, len_H0 = len_H0)
}

# --- p-valor (bicaudal) a partir de um IC 95% simétrico ---
p_from_ci <- function(I, level = 0.95, null = 0) {
  a <- I[1]; b <- I[2]
  z <- qnorm(1 - (1 - level)/2)
  half_width <- (b - a) / 2
  se <- half_width / z
  est <- (a + b) / 2
  z_obs <- abs((est - null) / se)
  p <- 2 * (1 - pnorm(z_obs))
  c(est = est, se = se, p_value = p)
}

# --- Cenários ---
H0 <- c(-0.10, 0.10)
cenarios <- list(
  `1` = c(0.35, 0.55),
  `2` = c(-0.05, 0.08),
  `3` = c(-0.50, 0.70),
  `4` = c(0.05, 0.25),
  `5` = c(-0.25, -0.05),
  `6` = c(0.15, 0.55),
  `7` = c(-0.55, -0.15)
)

# --- Monta data.frame (com check.names = FALSE para preservar nomes) ---
dados <- do.call(rbind, lapply(names(cenarios), function(id) {
  I <- cenarios[[id]]
  pd <- sgpv(I, H0)$p_delta
  pv <- p_from_ci(I)
  concl <- if (pd == 0) {
    "Apoia alternativas (SGPV=0)"
  } else if (pd == 1) {
    "Equivalência (SGPV=1)"
  } else {
    "Inconclusivo (0<pδ<1)"
  }
  data.frame(
    Cenário = as.integer(id),
    a = I[1],
    b = I[2],
    H0_min = H0[1],
    H0_max = H0[2],
    theta_hat = pv["est"],
    SE = pv["se"],
    "p-valor (bicaudal)" = pv["p_value"],
    "SGPV (pδ)" = pd,
    Conclusão = concl,
    check.names = FALSE
  )
}))

# --- Formatação numérica ---
fmt <- function(x, k = 3) formatC(x, digits = k, format = "f")
dados$a <- fmt(dados$a)
dados$b <- fmt(dados$b)
dados$H0_min <- fmt(dados$H0_min)
dados$H0_max <- fmt(dados$H0_max)
dados$theta_hat <- fmt(dados$theta_hat)
dados$SE <- fmt(dados$SE, 4)
dados$`p-valor (bicaudal)` <- fmt(as.numeric(dados$`p-valor (bicaudal)`), 3)
# if P<0,001 show this
dados$`p-valor (bicaudal)`[as.numeric(dados$`p-valor (bicaudal)`) < 0.001] <- "<0,001"
dados$`SGPV (pδ)` <- fmt(as.numeric(dados$`SGPV (pδ)`), 3)

# --- Cabeçalhos finais com LaTeX/HTML ---
colnames(dados) <- c(
  "Cenário",
  "$a$",
  "$b$",
  "$H_0^{-}$",
  "$H_0^{+}$",
  "$\\hat\\theta$",
  "$SE$",
  "p-valor (bicaudal)",
  "$p_{\\delta}$",
  "Conclusão (SGPV)"
)

# remove row names
rownames(dados) <- NULL

# --- Tabela kableExtra ---
knitr::kable(
  dados,
  align = c("c","c","c","c","c","c","c","c","c","c"),
  format = ifelse(knitr::is_html_output(), "html", "latex"),
  booktabs = TRUE,
  linesep = "",
  escape = FALSE
) %>%
  kableExtra::kable_styling(
    latex_options = c("basic"),
    bootstrap_options = c("condensed", "hover", "responsive"),
    full_width = TRUE,
    position = "center"
  ) %>%
  kableExtra::row_spec(0, bold = TRUE,
           extra_css = "border-top: 1px solid; border-bottom: 1px solid") %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::row_spec(nrow(dados), extra_css = "border-bottom: 1px solid")
```

<br>

### Como interpretar o SGPV?

-   $p_{\delta}=0$: dados apoiam apenas hipóteses alternativas relevantes (IC totalmente fora da equivalência).[@blume2018]

-   $p_{\delta}=1$: dados apoiam apenas hipóteses nulas (equivalentes) (IC totalmente dentro da equivalência).[@blume2018] $0<p_{\delta}<1$: inconclusivo; o valor expressa o grau de inconclusão. Em particular, $p_{\delta}=\tfrac{1}{2}$ indica inconclusão estrita.[@blume2018]

-   O SGPV é descritivo (não é probabilidade posterior de $H_0$).[@blume2018]

<br>

### Relação com testes de equivalência (TOST)

-   Tanto SGPV quanto TOST comparam o IC com os limites de equivalência. Se o IC $(1-2\alpha)$ (p.ex., 90% quando $\alpha=0{,}05$) cai inteiro dentro dos limites, TOST conclui equivalência — situação análoga a $p_{\delta}=1$.[@lakens2020]

-   Com ICs simétricos, há pontos de ancoragem em que as estatísticas coincidem: quando $p_{\text{TOST}}=0{,}5$, então $\mathrm{SGPV}=0{,}5$; quando o IC toca o limite mas fica inteiramente dentro (fronteira), $p_{\text{TOST}}=0{,}025$ e $\mathrm{SGPV}=1$; quando o IC fica inteiramente fora tocando o limite, $p_{\text{TOST}}=0{,}975$ e $\mathrm{SGPV}=0$.[@lakens2020]

-   Em ICs assimétricos ou quando $|I|>2|H_0|$, o SGPV fica difícil de interpretar quando $0<p_{\delta}<1$; nesses cenários, o TOST costuma diferenciar melhor os resultados.[@lakens2020]

<br>

### Propriedades frequenciais e múltiplas comparações

-   Usando ICs $100(1-\alpha)%$, sob qualquer hipótese em $H_0$, $\Pr(p_{\delta}=0)\le \alpha$ e $\to 0$ com o aumento de $n$; fora de $H_0$, $\Pr(p_{\delta}=0)\to 1$ quando $n$ cresce.[@blume2018]

-   O SGPV mitiga naturalmente inflação de erro Tipo I em muitas comparações e prioriza relevância científica (não requer ajustes ad hoc).[@blume2018]

<br>

## Distribuição de confiança

### O que é distribuição de confiança?

- Distribuição de confiança é uma representação contínua da evidência inferencial sobre um parâmetro de interesse. Ela mostra, para cada valor possível do tamanho do efeito, o nível de confiança associado, sendo uma generalização visual do intervalo de confiança e do P-valor.[@REF]

```{r confidence-distribution, echo = FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.align = 'center', layout='Blank', ph=officer::ph_location_fullsize(), results = "asis", fig.fullwidth = TRUE, fig.cap = "Distribuição de confiança para o tamanho do efeito estimado."}
# reprodutibilidade
set.seed(123)

# Tamanho amostral
n <- 60

# Parâmetros verdadeiros
mu_control <- 0
mu_treat   <- -35
sd_common  <- 80

# Dados simulados
control <- rnorm(n, mean = mu_control, sd = sd_common)
treat   <- rnorm(n, mean = mu_treat,   sd = sd_common)

# Estimativa do efeito (diferença de médias)
theta_hat <- mean(treat) - mean(control)

# Erro padrão
se <- sqrt(var(treat)/n + var(control)/n)

# Hipótese nula
theta0 <- 0

# Grade de efeitos plausíveis
theta <- seq(theta_hat - 5*se, theta_hat + 5*se, length.out = 500)

# Confidence distribution
z <- abs((theta - theta_hat) / se)
confidence <- 100 * (1 - 2 * (1 - pnorm(z)))

df <- data.frame(theta, confidence)

# P-valor (derivado da mesma estrutura)
z0 <- abs((theta_hat - theta0) / se)
p_value <- 2 * (1 - pnorm(z0))

# Plot
ggplot2::ggplot(df, ggplot2::aes(x = theta, y = confidence)) +
  ggplot2::geom_line(linewidth = 1) +
  ggplot2::geom_vline(xintercept = theta_hat,
                      color = "red", linewidth = 0.8) +
  ggplot2::geom_vline(xintercept = theta0,
                      color = "blue", linetype = "dashed") +
  ggplot2::geom_hline(yintercept = 95,
                      color = "red", linetype = "dotted") +
  ggplot2::geom_hline(yintercept = 100 * (1 - p_value),
                      color = "blue", linetype = "dashed") +
  ggplot2::annotate("text",
                    x = theta_hat, y = 5,
                    label = "Estimativa",
                    hjust = -0.1) +
  ggplot2::annotate("text",
                    x = theta0, y = 5,
                    label = "Hipótese nula",
                    hjust = -0.1) +
  ggplot2::annotate("text",
                    x = min(theta),
                    y = 100 * (1 - p_value) + 3,
                    label = paste0("P-valor = ", round(p_value, 3)),
                    hjust = 0) +
  ggplot2::labs(
    title = "Distribuição de confiança para o tamanho de efeito observado",
    x = "Efeito estimado",
    y = "Confiança (%)"
  ) +
  ggplot2::theme_minimal(base_size = 13)
```

<br>

## Boas práticas

-   Defina $H_0$ intervalar e $\delta$ a priori com justificativa científica.[@blume2018; @lakens2020]

-   Reporte: estimativa pontual, IC, limites de equivalência e $p_{\delta}$; interprete $p_{\delta}\in{0,1}$ de forma dicotômica e $0<p_{\delta}<1$ como inconclusivo; quando necessário, complemente com TOST.[@blume2018; @lakens2020]

<br>

```{r, echo=FALSE, warning=FALSE, results='asis', eval=knitr::is_html_output()}
cat(readLines("citation.html"), sep = "\n")
```

<br>
